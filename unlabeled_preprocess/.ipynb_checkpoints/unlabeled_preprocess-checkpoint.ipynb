{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**readme**: <br>\n",
    "scripts below are used to sample unlabeled data (5000) and tokenized text; <br>\n",
    "output tokenized unlabeled data is stored under res/tokenized_sampled_unlabeled_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "import glob\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from tokenization import Tokenization\n",
    "from unlabeled_preprocess import unlabeled_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反馈数据 in total has 24233 reviews\n",
      "反馈数据举3例： ['今天的CZ3539航班的毛毯质量很差，下来发现裤子上掉落很多毛。', '最近经常出现提前很久打电话预留前排靠过道位置，到机场就没有，一直道歉，作为高端客户，感觉很不好。', '最近航班服务经常出问题，提前很久打电话预留前排靠过道位置，到机场就没有物流，作为高端客户，对这样的服务很不满意。']\n"
     ]
    }
   ],
   "source": [
    "pu = unlabeled_preprocess()\n",
    "fk_reviews = pu.load_unlabeled_data()\n",
    "sampled_unlabeled_reviews = pu.sample_unlabeled(5000,'../res/sampled_unlabeled_reviews.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see the first 10 unlabeled reviews ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['定了3月17日的行程，却在APP上找不不到3月17日乘坐南航的行程',\n",
       " ' 飞行中一直很热，跟没有开空调一样，没有任何舒适度',\n",
       " '身份证号码还是一代身份证，不能与银行所留信息匹配，完成不了身份认证。怎么办？',\n",
       " '打了客服电话了，积分还是没有计入。我现在对南航有点失望了，还好我还是凤凰金卡。',\n",
       " '我们6.2日凌晨到的白云机场，安排在新都商务酒店中转住宿。孩子把一个孙悟空造型的随手听丢在了酒店。希望能给予帮忙，因为我们现在人在泰国，不太方便电话联系。我们6.9日还要搭乘南航飞机从清迈于晚上10点多到达白云机场，因为预定的中转酒店不是新都，如果找到的话，希望能在中转地方取到孩子的随手听，万分感谢。',\n",
       " '九月十三日购南方航空的票，收据己打，丢了，现需要报销能否补打一个收据',\n",
       " '为什么不能提前选座值机了，很不方便，时间也不好控制…搞得人匆匆忙忙…新注册会员以后以前坐过的航班次数也不显示',\n",
       " '買了你們的11.11禮包，卻一直沒有到帳，也沒有說明如何使用，客服又爛，真的對南航很失望！！',\n",
       " '订单分享功能有问题，分享过去后打开的不是我的订单，只是给登录页面',\n",
       " '手机号，银行卡，身份证第一次注册南航，提示银行预留手机号已绑定其他会员']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('see the first 10 unlabeled reviews ...')\n",
    "sampled_unlabeled_reviews[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/_d/b3chzbkx5vgg1wtjm942qj4m0000gn/T/jieba.cache\n",
      "Loading model cost 0.931 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "stopwords = [line.strip() for line in open('../Source_Data/stopwords.txt', 'r', encoding='utf-8').readlines()]   \n",
    "tok = Tokenization('../res/sampled_unlabeled_reviews.txt','../res/tokenized_sampled_unlabeled_reviews', stopwords)\n",
    "input_data = tok.load_input_data()\n",
    "tokenized_sents = tok.get_tokenized_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of input data: 5316\n",
      "after removing non-Chinese reviews ...\n",
      "number of valid unlabeled data: 4765\n"
     ]
    }
   ],
   "source": [
    "print('total number of input data: %d'%len(input_data))\n",
    "print('after removing non-Chinese reviews ...')\n",
    "print('number of valid unlabeled data: %d'%len(tokenized_sents)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take a look at the first 10 tokenized unlabeled data ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['机票 报销 凭证 没收',\n",
       " '南航 月 日 航班 取消 成行 取消 订单',\n",
       " '服务 位置 舒服',\n",
       " '原坐 航班号 日 时间 起飞 上海 沈阳 更换 时间 三次 最终 延误 日 起飞 太 不靠 谱 航班 差劲 坐 南航 航空',\n",
       " '明珠 卡 密码 记不住',\n",
       " '月 号 买 南航 航班 上海 虹桥 广州 沒有 里程',\n",
       " '我要 退票 打电话 没人接 玩意',\n",
       " '出行 原因 改为 泰国 菲律宾 票 退 显示 审核 打款',\n",
       " '全程 小时 边上 两个 人用 全 飞机 听 声音 讲 小时 全程 空乘 人员 提醒 真的 很烦 没什么 人去 提醒',\n",
       " '超级 慢 页面 显示']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('take a look at the first 10 tokenized unlabeled data ...')\n",
    "tokenized_sents[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
