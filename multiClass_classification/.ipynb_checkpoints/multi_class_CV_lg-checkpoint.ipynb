{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readme: \n",
    "- for building 10 classifiers\n",
    "- implement cross validation for each label class + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from modeling_main import ReviewClassify\n",
    "from tokenization import Tokenization\n",
    "from help import get_tokenized_sent, get_stopwords\n",
    "\n",
    "from prepare_data import PrepareData\n",
    "from modeling import Modeling\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model,X_train,y_train):\n",
    "    ''' predict label for each review, by picking the class with highest probability'''\n",
    "    multi_class_clf = OneVsRestClassifier(model, n_jobs=-1)\n",
    "    multi_class_clf.fit(X_train, y_train)\n",
    "    # each review has proba for 10 classes\n",
    "    scores = multi_class_clf.predict_proba(X_test)\n",
    "    return scores\n",
    "\n",
    "def get_class_label_name(scores,idx):\n",
    "    ''' input a review index, and get the predicted label \n",
    "    (the one with highest probability) for this review'''\n",
    "    label_encoded = np.argmax(scores[idx])\n",
    "    return [key for key in labels_index if labels_index[key] ==label_encoded ].pop()\n",
    "\n",
    "def add_pred_to_df(scores, df):\n",
    "    '''add predicted labels to original df'''\n",
    "    predicted_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        label_pred = get_class_label_name(scores,i)\n",
    "        predicted_labels.append(label_pred)\n",
    "    # add predicted labels to original test df\n",
    "    df['pred_label'] = predicted_labels\n",
    "    return df\n",
    "\n",
    "def get_confusion_matrix(y_test,y_pred):\n",
    "    '''get confusion matrix (tp,tn,fp,fn) for each class'''\n",
    "    cm = ConfusionMatrix(y_test, y_pred)\n",
    "    cm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # updated: drop na values\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def split_data(data):\n",
    "    train, test = train_test_split(data, test_size = 0.33, random_state=42)\n",
    "#     print('training data has %d examples' %len(train))\n",
    "#     print('test data has %d examples' %len(test))\n",
    "    return train, test\n",
    "\n",
    "def preprocess_data(data, train, test):\n",
    "    '''use countvectorizer and tf-idf transformer to get valid one-hot encoding for reviews'''\n",
    "    # use countVectorizer for one-hot encoding\n",
    "    count_v0= CountVectorizer()\n",
    "    counts_all = count_v0.fit_transform(data['review_tokens'])\n",
    "    count_v1= CountVectorizer(vocabulary=count_v0.vocabulary_)  \n",
    "    counts_train = count_v1.fit_transform(train.review_tokens)\n",
    "\n",
    "    count_v2 = CountVectorizer(vocabulary=count_v0.vocabulary_)\n",
    "    counts_test = count_v2.fit_transform(test.review_tokens)\n",
    "\n",
    "    # implement tf-idf\n",
    "    tfidftransformer = TfidfTransformer()\n",
    "    train_data = tfidftransformer.fit(counts_train).transform(counts_train)\n",
    "    test_data = tfidftransformer.fit(counts_test).transform(counts_test)\n",
    "\n",
    "    X_train = train_data\n",
    "    # y_train = train.label_encoded\n",
    "    y_train = train.label_or_not.values\n",
    "    X_test = test_data\n",
    "    # y_test = test.label_encoded\n",
    "    y_test = test.label_or_not.values\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# multi-class modeling\n",
    "def multi_class_preprocess(data,label):\n",
    "    '''data preprocess for multi-class'''\n",
    "    data.loc[data.label == label, 'label_or_not'] = 1\n",
    "    data.loc[data.label != label, 'label_or_not'] = 0\n",
    "    return data\n",
    "\n",
    "def get_class_prior(data, label):\n",
    "    '''get class prior\n",
    "    class_prior = class_size / data_size'''\n",
    "    class_prior = len(data[data['label']== label]) / len(data)\n",
    "    return class_prior\n",
    "\n",
    "def get_class_threshold(class_prob, class_prior):\n",
    "    '''use class_priors are percentile for each class label '''\n",
    "    # there are 10 class in total\n",
    "    # col = 1 represent 'positive'\n",
    "    # first index represents the class, e.g., prob_scores[0][:,1] -> prob. when labeled as class 0 for each review\n",
    "    # class_prob = prob_scores[:,1] \n",
    "    # get the higher bound percentile\n",
    "    percentile = (1 - class_prior)*100\n",
    "    threshold = np.percentile(class_prob, percentile) \n",
    "    return threshold\n",
    "\n",
    "def get_label(idx, labels, positive_review_dct):\n",
    "    '''input an index and output a list of predicted labels'''\n",
    "    label_pred = []\n",
    "    for label in labels:\n",
    "        if idx in positive_review_dct[label]:\n",
    "            label_pred.append(label)\n",
    "    return label_pred\n",
    "\n",
    "def get_prob(data, model, parameters, label):\n",
    "    '''get probability predicted for one label class'''\n",
    "    label_data = multi_class_preprocess(data,label)\n",
    "    # split data\n",
    "    train, test = split_data(label_data)\n",
    "    # vectorize reviews\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(label_data, train, test)\n",
    "    # implement gridSearch CV\n",
    "    model = GridSearchCV(model, parameters, cv=5)\n",
    "\n",
    "    # modeling\n",
    "    model.fit(X_train,y_train)\n",
    "    print('best params found:',model.best_params_)\n",
    "    \n",
    "    # get the proba score for one class (using the best model from gridSearch to predict)\n",
    "    class_prob = model.predict_proba(X_test)[:,1] \n",
    "    # e.g., class_proba: [0.15,0.3,...] => 512 records in total\n",
    "    class_prob_values = class_prob.reshape(-1,1)\n",
    "    return class_prob_values\n",
    "\n",
    "\n",
    "def manual_classify(data, label, class_prob):\n",
    "    '''classify by setting manual threshold of probability (for one class)'''\n",
    "    # get class_prior\n",
    "    class_prior = get_class_prior(data, label)\n",
    "    # set manual threshol\n",
    "    threshold = get_class_threshold(class_prob, class_prior)\n",
    "    class_labels = []\n",
    "    proba_dct = {}\n",
    "    for score in class_prob:\n",
    "        if score > threshold:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        class_labels.append(label)\n",
    "    positive_reviews = [ idx for idx in range(len(class_labels)) if class_labels[idx] == 1  ]\n",
    "    return positive_reviews\n",
    "\n",
    "# get label_picked for review with multiple labels predicted\n",
    "def pick_label(review_idx):\n",
    "    '''compare proba of each label_pred, and pick the one with higher proba'''\n",
    "    # get label_idx\n",
    "    label_idx_dct = {}\n",
    "    for idx,label in enumerate(labels):\n",
    "        label_idx_dct[label] = idx\n",
    "  \n",
    "    # pick label\n",
    "    label_proba_dct = {}\n",
    "    for i,label_pred in enumerate(test_label_pred[review_idx]):\n",
    "        label_index = label_idx_dct.get(label_pred)\n",
    "        label_proba_dct[label_pred] = prob_matrix[review_idx,label_index]\n",
    "    label_picked = [key for key in label_proba_dct if label_proba_dct[key] == max(label_proba_dct.values())]\n",
    "    return label_picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['计划', '机上', '中转', '售后', '预订', '设计', '出发', '性能', '行程', '到达']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params found: {'C': 0.01, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params found: {'C': 10, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params found: {'C': 1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params found: {'C': 10, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params found: {'C': 10, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params found: {'C': 0.01, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params found: {'C': 1, 'penalty': 'l1'}\n",
      "best params found: {'C': 1, 'penalty': 'l1'}\n",
      "best params found: {'C': 10, 'penalty': 'l1'}\n",
      "best params found: {'C': 1, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.76461040e-01, 5.69066798e-02, 9.82388804e-02, ...,\n",
       "        7.41508040e-02, 2.29307082e-03, 2.95773704e-01],\n",
       "       [1.75897424e-01, 8.28058236e-01, 6.72926093e-02, ...,\n",
       "        5.18911942e-02, 2.29307082e-03, 1.05647343e-01],\n",
       "       [1.73395659e-01, 1.31735488e-02, 2.55955189e-01, ...,\n",
       "        3.66121050e-02, 4.66482959e-04, 2.97907045e-02],\n",
       "       ...,\n",
       "       [1.74248764e-01, 3.84016062e-01, 6.11475894e-02, ...,\n",
       "        5.65024294e-02, 2.29307082e-03, 4.57244283e-02],\n",
       "       [1.74221198e-01, 2.53081498e-02, 4.94079387e-02, ...,\n",
       "        5.69838923e-02, 2.29773015e-04, 4.37475599e-02],\n",
       "       [1.73091334e-01, 1.60688752e-01, 1.45786216e-01, ...,\n",
       "        4.86758406e-02, 1.35078951e-03, 4.09583673e-02]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data('../res/labeled_data_with_without_tk.csv')\n",
    "# train, test data that include all label classes\n",
    "train, test = split_data(data)\n",
    "\n",
    "class_prob_values_dct = {}\n",
    "labels = data.label.unique().tolist()\n",
    "print(labels)\n",
    "\n",
    "for label in labels:\n",
    "    model = LogisticRegression()\n",
    "    parameters = {'penalty':('l2', 'l1'), 'C':[0.01,0.1,1,10]}\n",
    "    class_prob_values = get_prob(data, model, parameters, label)\n",
    "    class_prob_values_dct[label] = class_prob_values\n",
    "    \n",
    "prob_matrix = np.hstack((list(class_prob_values_dct.values())))\n",
    "prob_matrix\n",
    "\n",
    "# get a dictionary: {0:[0.13,0.25,...], 1:[..], 2:[..],.. 511:[..]} that list the probability \n",
    "# of each user review across all 10 classes (each list within the values of the dictionary has 10 proba values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_performance(prob_matrix, labels, test):\n",
    "    '''convert prediction result in proba_matrix to acutal df, and compute confusion matrix'''\n",
    "    # add prediction results into a dictionary\n",
    "    positive_review_dct = {}\n",
    "    for i,label in enumerate(labels):\n",
    "        positive_reviews = manual_classify(data, label, prob_matrix[:,i])\n",
    "        positive_review_dct[label] = positive_reviews\n",
    "    \n",
    "    # get reversed dictionary: key is the index of user review, value is the labels predicted\n",
    "    test_label_pred = {}\n",
    "    for idx in range(len(test)):\n",
    "        label_pred = get_label(idx,labels,positive_review_dct)\n",
    "        test_label_pred[idx] = label_pred\n",
    "\n",
    "    for i in range(len(test)):\n",
    "    # handle review with multiple labels\n",
    "        if len(test_label_pred[i]) > 1: \n",
    "            label_picked = pick_label(i)\n",
    "            test_label_pred[i] = label_picked\n",
    "\n",
    "    # reput prediction into original dataframe\n",
    "    test_ = test.copy()\n",
    "    test_['predicted_labels'] = list(test_label_pred.values())\n",
    "    def formatting(row):\n",
    "        '''remove [] in the prediction result'''\n",
    "        if len(row) > 0:\n",
    "            return row[0]\n",
    "        else:\n",
    "            # np.nan is float, not supported for confusion matrix calculation, so change it to 'N/A'\n",
    "            return 'N/A'\n",
    "    test_['predicted_labels'] = test_['predicted_labels'].apply(formatting)\n",
    "    test_.head()\n",
    "    \n",
    "    # get confusion matrix\n",
    "    get_confusion_matrix(test_.label,test_.predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  N/A  中转  出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                         \n",
      "N/A          0   0   0   0   0   0   0   0   0   0   0        0\n",
      "中转          12  22   9   1   2   0   6   0   1   0   1       54\n",
      "出发          11   6  55  14  10   0   9   1   1   0   5      112\n",
      "到达          11   1   0  27   0   0   8   0   0   0   0       47\n",
      "售后          10   0   7   0  25   0   0   1   0   2   3       48\n",
      "性能           6   0   5   0   4  17   3   3   0   2  15       55\n",
      "机上          17   2   7   2   0   0  58   0   0   3   4       93\n",
      "行程           4   0   1   0   1   0   0  10   0   0   2       18\n",
      "计划           2   0   0   0   0   1   0   0   2   0   2        7\n",
      "设计           3   0   0   0   0   4   1   0   0   1   3       12\n",
      "预订          18   0   2   0   2   6   1   0   0   1  36       66\n",
      "__all__     94  31  86  44  44  28  86  15   4   9  71      512\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.494140625\n",
      "95% CI: (0.44999926338345436, 0.5383499963338143)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 5.15013462742094e-57\n",
      "Kappa: 0.42848276932094403\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                     N/A         中转        出发  \\\n",
      "Population                                  512        512       512   \n",
      "P: Condition positive                         0         54       112   \n",
      "N: Condition negative                       512        458       400   \n",
      "Test outcome positive                        94         31        86   \n",
      "Test outcome negative                       418        481       426   \n",
      "TP: True Positive                             0         22        55   \n",
      "TN: True Negative                           418        449       369   \n",
      "FP: False Positive                           94          9        31   \n",
      "FN: False Negative                            0         32        57   \n",
      "TPR: (Sensitivity, hit rate, recall)        NaN   0.407407  0.491071   \n",
      "TNR=SPC: (Specificity)                 0.816406   0.980349    0.9225   \n",
      "PPV: Pos Pred Value (Precision)               0   0.709677  0.639535   \n",
      "NPV: Neg Pred Value                           1   0.933472  0.866197   \n",
      "FPR: False-out                         0.183594  0.0196507    0.0775   \n",
      "FDR: False Discovery Rate                     1   0.290323  0.360465   \n",
      "FNR: Miss Rate                              NaN   0.592593  0.508929   \n",
      "ACC: Accuracy                          0.816406   0.919922  0.828125   \n",
      "F1 score                                      0   0.517647  0.555556   \n",
      "MCC: Matthews correlation coefficient       NaN   0.499385  0.457336   \n",
      "Informedness                                NaN   0.387757  0.413571   \n",
      "Markedness                                    0   0.643149  0.505732   \n",
      "Prevalence                                    0   0.105469   0.21875   \n",
      "LR+: Positive likelihood ratio              NaN    20.7325   6.33641   \n",
      "LR-: Negative likelihood ratio              NaN   0.604471  0.551684   \n",
      "DOR: Diagnostic odds ratio                  NaN    34.2986   11.4856   \n",
      "FOR: False omission rate                      0  0.0665281  0.133803   \n",
      "\n",
      "Classes                                       到达         售后         性能  \\\n",
      "Population                                   512        512        512   \n",
      "P: Condition positive                         47         48         55   \n",
      "N: Condition negative                        465        464        457   \n",
      "Test outcome positive                         44         44         28   \n",
      "Test outcome negative                        468        468        484   \n",
      "TP: True Positive                             27         25         17   \n",
      "TN: True Negative                            448        445        446   \n",
      "FP: False Positive                            17         19         11   \n",
      "FN: False Negative                            20         23         38   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.574468   0.520833   0.309091   \n",
      "TNR=SPC: (Specificity)                  0.963441   0.959052    0.97593   \n",
      "PPV: Pos Pred Value (Precision)         0.613636   0.568182   0.607143   \n",
      "NPV: Neg Pred Value                     0.957265   0.950855   0.921488   \n",
      "FPR: False-out                         0.0365591  0.0409483    0.02407   \n",
      "FDR: False Discovery Rate               0.386364   0.431818   0.392857   \n",
      "FNR: Miss Rate                          0.425532   0.479167   0.690909   \n",
      "ACC: Accuracy                           0.927734   0.917969   0.904297   \n",
      "F1 score                                0.593407   0.543478   0.409639   \n",
      "MCC: Matthews correlation coefficient    0.55416   0.499077   0.388163   \n",
      "Informedness                            0.537909   0.479885   0.285021   \n",
      "Markedness                              0.570901   0.519037    0.52863   \n",
      "Prevalence                             0.0917969    0.09375   0.107422   \n",
      "LR+: Positive likelihood ratio           15.7134    12.7193    12.8413   \n",
      "LR-: Negative likelihood ratio          0.441679   0.499625   0.707949   \n",
      "DOR: Diagnostic odds ratio               35.5765    25.4577    18.1388   \n",
      "FOR: False omission rate                0.042735  0.0491453  0.0785124   \n",
      "\n",
      "Classes                                       机上         行程          计划  \\\n",
      "Population                                   512        512         512   \n",
      "P: Condition positive                         93         18           7   \n",
      "N: Condition negative                        419        494         505   \n",
      "Test outcome positive                         86         15           4   \n",
      "Test outcome negative                        426        497         508   \n",
      "TP: True Positive                             58         10           2   \n",
      "TN: True Negative                            391        489         503   \n",
      "FP: False Positive                            28          5           2   \n",
      "FN: False Negative                            35          8           5   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.623656   0.555556    0.285714   \n",
      "TNR=SPC: (Specificity)                  0.933174   0.989879     0.99604   \n",
      "PPV: Pos Pred Value (Precision)         0.674419   0.666667         0.5   \n",
      "NPV: Neg Pred Value                      0.91784   0.983903    0.990157   \n",
      "FPR: False-out                         0.0668258  0.0101215   0.0039604   \n",
      "FDR: False Discovery Rate               0.325581   0.333333         0.5   \n",
      "FNR: Miss Rate                          0.376344   0.444444    0.714286   \n",
      "ACC: Accuracy                           0.876953   0.974609    0.986328   \n",
      "F1 score                                0.648045   0.606061    0.363636   \n",
      "MCC: Matthews correlation coefficient   0.574271   0.595687    0.371623   \n",
      "Informedness                             0.55683   0.545434    0.281754   \n",
      "Markedness                              0.592259    0.65057    0.490157   \n",
      "Prevalence                              0.181641  0.0351562   0.0136719   \n",
      "LR+: Positive likelihood ratio           9.33257    54.8889     72.1429   \n",
      "LR-: Negative likelihood ratio          0.403295   0.448989    0.717126   \n",
      "DOR: Diagnostic odds ratio               23.1408     122.25       100.6   \n",
      "FOR: False omission rate               0.0821596  0.0160966  0.00984252   \n",
      "\n",
      "Classes                                       设计         预订  \n",
      "Population                                   512        512  \n",
      "P: Condition positive                         12         66  \n",
      "N: Condition negative                        500        446  \n",
      "Test outcome positive                          9         71  \n",
      "Test outcome negative                        503        441  \n",
      "TP: True Positive                              1         36  \n",
      "TN: True Negative                            492        411  \n",
      "FP: False Positive                             8         35  \n",
      "FN: False Negative                            11         30  \n",
      "TPR: (Sensitivity, hit rate, recall)   0.0833333   0.545455  \n",
      "TNR=SPC: (Specificity)                     0.984   0.921525  \n",
      "PPV: Pos Pred Value (Precision)         0.111111   0.507042  \n",
      "NPV: Neg Pred Value                     0.978131   0.931973  \n",
      "FPR: False-out                             0.016  0.0784753  \n",
      "FDR: False Discovery Rate               0.888889   0.492958  \n",
      "FNR: Miss Rate                          0.916667   0.454545  \n",
      "ACC: Accuracy                           0.962891   0.873047  \n",
      "F1 score                               0.0952381   0.525547  \n",
      "MCC: Matthews correlation coefficient  0.0775176   0.452781  \n",
      "Informedness                           0.0673333   0.466979  \n",
      "Markedness                             0.0892423   0.439015  \n",
      "Prevalence                             0.0234375   0.128906  \n",
      "LR+: Positive likelihood ratio           5.20833    6.95065  \n",
      "LR-: Negative likelihood ratio          0.931572   0.493254  \n",
      "DOR: Diagnostic odds ratio               5.59091    14.0914  \n",
      "FOR: False omission rate               0.0218688  0.0680272  \n"
     ]
    }
   ],
   "source": [
    "get_pred_performance(prob_matrix, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
