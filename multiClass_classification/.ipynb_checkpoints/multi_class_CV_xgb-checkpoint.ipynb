{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readme: \n",
    "- for building 10 classifiers\n",
    "- implement cross validation for each label class + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from modeling_main import ReviewClassify\n",
    "from tokenization import Tokenization\n",
    "from help import get_tokenized_sent, get_stopwords\n",
    "\n",
    "from prepare_data import PrepareData\n",
    "from modeling import Modeling\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model,X_train,y_train):\n",
    "    ''' predict label for each review, by picking the class with highest probability'''\n",
    "    multi_class_clf = OneVsRestClassifier(model, n_jobs=-1)\n",
    "    multi_class_clf.fit(X_train, y_train)\n",
    "    # each review has proba for 10 classes\n",
    "    scores = multi_class_clf.predict_proba(X_test)\n",
    "    return scores\n",
    "\n",
    "def get_class_label_name(scores,idx):\n",
    "    ''' input a review index, and get the predicted label \n",
    "    (the one with highest probability) for this review'''\n",
    "    label_encoded = np.argmax(scores[idx])\n",
    "    return [key for key in labels_index if labels_index[key] ==label_encoded ].pop()\n",
    "\n",
    "def add_pred_to_df(scores, df):\n",
    "    '''add predicted labels to original df'''\n",
    "    predicted_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        label_pred = get_class_label_name(scores,i)\n",
    "        predicted_labels.append(label_pred)\n",
    "    # add predicted labels to original test df\n",
    "    df['pred_label'] = predicted_labels\n",
    "    return df\n",
    "\n",
    "def get_confusion_matrix(y_test,y_pred):\n",
    "    '''get confusion matrix (tp,tn,fp,fn) for each class'''\n",
    "    cm = ConfusionMatrix(y_test, y_pred)\n",
    "    cm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # updated: drop na values\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def split_data(data):\n",
    "    train, test = train_test_split(data, test_size = 0.33, random_state=42)\n",
    "#     print('training data has %d examples' %len(train))\n",
    "#     print('test data has %d examples' %len(test))\n",
    "    return train, test\n",
    "\n",
    "def preprocess_data(data, train, test):\n",
    "    '''use countvectorizer and tf-idf transformer to get valid one-hot encoding for reviews'''\n",
    "    # use countVectorizer for one-hot encoding\n",
    "    count_v0= CountVectorizer()\n",
    "    counts_all = count_v0.fit_transform(data['review_tokens'])\n",
    "    count_v1= CountVectorizer(vocabulary=count_v0.vocabulary_)  \n",
    "    counts_train = count_v1.fit_transform(train.review_tokens)\n",
    "\n",
    "    count_v2 = CountVectorizer(vocabulary=count_v0.vocabulary_)\n",
    "    counts_test = count_v2.fit_transform(test.review_tokens)\n",
    "\n",
    "    # implement tf-idf\n",
    "    tfidftransformer = TfidfTransformer()\n",
    "    train_data = tfidftransformer.fit(counts_train).transform(counts_train)\n",
    "    test_data = tfidftransformer.fit(counts_test).transform(counts_test)\n",
    "\n",
    "    X_train = train_data\n",
    "    # y_train = train.label_encoded\n",
    "    y_train = train.label_or_not.values\n",
    "    X_test = test_data\n",
    "    # y_test = test.label_encoded\n",
    "    y_test = test.label_or_not.values\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# multi-class modeling\n",
    "def multi_class_preprocess(data,label):\n",
    "    '''data preprocess for multi-class'''\n",
    "    data.loc[data.label == label, 'label_or_not'] = 1\n",
    "    data.loc[data.label != label, 'label_or_not'] = 0\n",
    "    return data\n",
    "\n",
    "def get_class_prior(data, label):\n",
    "    '''get class prior\n",
    "    class_prior = class_size / data_size'''\n",
    "    class_prior = len(data[data['label']== label]) / len(data)\n",
    "    return class_prior\n",
    "\n",
    "def get_class_threshold(class_prob, class_prior):\n",
    "    '''use class_priors are percentile for each class label '''\n",
    "    # there are 10 class in total\n",
    "    # col = 1 represent 'positive'\n",
    "    # first index represents the class, e.g., prob_scores[0][:,1] -> prob. when labeled as class 0 for each review\n",
    "    # class_prob = prob_scores[:,1] \n",
    "    # get the higher bound percentile\n",
    "    percentile = (1 - class_prior)*100\n",
    "    threshold = np.percentile(class_prob, percentile) \n",
    "    return threshold\n",
    "\n",
    "def get_label(idx, labels, positive_review_dct):\n",
    "    '''input an index and output a list of predicted labels'''\n",
    "    label_pred = []\n",
    "    for label in labels:\n",
    "        if idx in positive_review_dct[label]:\n",
    "            label_pred.append(label)\n",
    "    return label_pred\n",
    "\n",
    "def get_prob(data, model, parameters, label):\n",
    "    '''get probability predicted for one label class'''\n",
    "    label_data = multi_class_preprocess(data,label)\n",
    "    # split data\n",
    "    train, test = split_data(label_data)\n",
    "    # vectorize reviews\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(label_data, train, test)\n",
    "    # implement gridSearch CV\n",
    "    model = GridSearchCV(model, parameters, cv=5)\n",
    "\n",
    "    # modeling\n",
    "    model.fit(X_train,y_train)\n",
    "    print('best params found:',model.best_params_)\n",
    "    \n",
    "    # get the proba score for one class (using the best model from gridSearch to predict)\n",
    "    class_prob = model.predict_proba(X_test)[:,1] \n",
    "    # e.g., class_proba: [0.15,0.3,...] => 512 records in total\n",
    "    class_prob_values = class_prob.reshape(-1,1)\n",
    "    return class_prob_values\n",
    "\n",
    "\n",
    "def manual_classify(data, label, class_prob):\n",
    "    '''classify by setting manual threshold of probability (for one class)'''\n",
    "    # get class_prior\n",
    "    class_prior = get_class_prior(data, label)\n",
    "    # set manual threshol\n",
    "    threshold = get_class_threshold(class_prob, class_prior)\n",
    "    class_labels = []\n",
    "    proba_dct = {}\n",
    "    for score in class_prob:\n",
    "        if score > threshold:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        class_labels.append(label)\n",
    "    positive_reviews = [ idx for idx in range(len(class_labels)) if class_labels[idx] == 1  ]\n",
    "    return positive_reviews\n",
    "\n",
    "# get label_picked for review with multiple labels predicted\n",
    "def pick_label(review_idx, label_pred):\n",
    "    '''compare proba of each label_pred, and pick the one with higher proba'''\n",
    "    # get label_idx\n",
    "    label_idx_dct = {}\n",
    "    for idx,label in enumerate(labels):\n",
    "        label_idx_dct[label] = idx\n",
    "  \n",
    "    # pick label\n",
    "    label_proba_dct = {}\n",
    "    for i,label_pred in enumerate(label_pred[review_idx]):\n",
    "        label_index = label_idx_dct.get(label_pred)\n",
    "        label_proba_dct[label_pred] = prob_matrix[review_idx,label_index]\n",
    "    label_picked = [key for key in label_proba_dct if label_proba_dct[key] == max(label_proba_dct.values())]\n",
    "    return label_picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['计划', '机上', '中转', '售后', '预订', '设计', '出发', '性能', '行程', '到达']\n",
      "best params found: {'alpha': 0.01, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 5}\n",
      "best params found: {'alpha': 0.01, 'learning_rate': 1, 'max_depth': 5, 'n_estimators': 5}\n",
      "best params found: {'alpha': 0.01, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10}\n",
      "best params found: {'alpha': 0.01, 'learning_rate': 1, 'max_depth': 3, 'n_estimators': 10}\n",
      "best params found: {'alpha': 0.01, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 5}\n",
      "best params found: {'alpha': 0.01, 'learning_rate': 10, 'max_depth': 3, 'n_estimators': 5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = load_data('../res/labeled_data_with_without_tk.csv')\n",
    "# train, test data that include all label classes\n",
    "train, test = split_data(data)\n",
    "class_prob_values_dct = {}\n",
    "labels = data.label.unique().tolist()\n",
    "print(labels)\n",
    "for label in labels:\n",
    "    model = xgb.XGBClassifier()\n",
    "    parameters = {'max_depth':[3,5,10], 'learning_rate':[0.01,0.1,1,10],'alpha':[0.01,0.1,1,10], 'n_estimators' :[5,10,15]}\n",
    "    class_prob_values = get_prob(data, model, parameters, label)\n",
    "    class_prob_values_dct[label] = class_prob_values\n",
    "    \n",
    "prob_matrix = np.hstack((list(class_prob_values_dct.values())))\n",
    "prob_matrix\n",
    "\n",
    "# get a dictionary: {0:[0.13,0.25,...], 1:[..], 2:[..],.. 511:[..]} that list the probability \n",
    "# of each user review across all 10 classes (each list within the values of the dictionary has 10 proba values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_performance(prob_matrix, labels, test):\n",
    "    '''convert prediction result in proba_matrix to acutal df, and compute confusion matrix'''\n",
    "    # add prediction results into a dictionary\n",
    "    positive_review_dct = {}\n",
    "    for i,label in enumerate(labels):\n",
    "        positive_reviews = manual_classify(data, label, prob_matrix[:,i])\n",
    "        positive_review_dct[label] = positive_reviews\n",
    "    \n",
    "    # get reversed dictionary: key is the index of user review, value is the labels predicted\n",
    "    test_label_pred = {}\n",
    "    for idx in range(len(test)):\n",
    "        label_pred = get_label(idx,labels,positive_review_dct)\n",
    "        test_label_pred[idx] = label_pred\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "    # handle review with multiple labels\n",
    "        if len(test_label_pred[i]) > 1: \n",
    "            label_picked = pick_label(i,test_label_pred)\n",
    "            test_label_pred[i] = label_picked\n",
    "\n",
    "    # reput prediction into original dataframe\n",
    "    test_ = test.copy()\n",
    "    test_['predicted_labels'] = list(test_label_pred.values())\n",
    "    def formatting(row):\n",
    "        '''remove [] in the prediction result'''\n",
    "        if len(row) > 0:\n",
    "            return row[0]\n",
    "        else:\n",
    "            # np.nan is float, not supported for confusion matrix calculation, so change it to 'N/A'\n",
    "            return 'N/A'\n",
    "    test_['predicted_labels'] = test_['predicted_labels'].apply(formatting)\n",
    "    test_.head()\n",
    "    \n",
    "    # get confusion matrix\n",
    "    get_confusion_matrix(test_.label,test_.predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  N/A  中转  出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                         \n",
      "N/A          0   0   0   0   0   0   0   0   0   0   0        0\n",
      "中转          16  18   6   1   1   0  11   0   0   0   1       54\n",
      "出发          19   7  45  15  10   0  11   3   0   0   2      112\n",
      "到达          15   1   1  20   0   0   9   0   1   0   0       47\n",
      "售后          12   1   4   1  24   0   0   1   2   0   3       48\n",
      "性能          35   0   2   0   3   0   2   3   2   0   8       55\n",
      "机上          26   5   3   2   0   0  52   0   0   0   5       93\n",
      "行程           5   0   0   0   0   0   1  10   2   0   0       18\n",
      "计划           3   0   0   0   0   0   0   0   2   0   2        7\n",
      "设计          10   1   0   0   0   0   0   0   0   0   1       12\n",
      "预订          18   0   1   2   4   0   2   0   0   0  39       66\n",
      "__all__    159  33  62  41  42   0  88  17   9   0  61      512\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.41015625\n",
      "95% CI: (0.3672010335798694, 0.4541547668518726)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.2201737000952885e-06\n",
      "Kappa: 0.34729163852492234\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                     N/A         中转        出发  \\\n",
      "Population                                  512        512       512   \n",
      "P: Condition positive                         0         54       112   \n",
      "N: Condition negative                       512        458       400   \n",
      "Test outcome positive                       159         33        62   \n",
      "Test outcome negative                       353        479       450   \n",
      "TP: True Positive                             0         18        45   \n",
      "TN: True Negative                           353        443       383   \n",
      "FP: False Positive                          159         15        17   \n",
      "FN: False Negative                            0         36        67   \n",
      "TPR: (Sensitivity, hit rate, recall)        NaN   0.333333  0.401786   \n",
      "TNR=SPC: (Specificity)                 0.689453   0.967249    0.9575   \n",
      "PPV: Pos Pred Value (Precision)               0   0.545455  0.725806   \n",
      "NPV: Neg Pred Value                           1   0.924843  0.851111   \n",
      "FPR: False-out                         0.310547  0.0327511    0.0425   \n",
      "FDR: False Discovery Rate                     1   0.454545  0.274194   \n",
      "FNR: Miss Rate                              NaN   0.666667  0.598214   \n",
      "ACC: Accuracy                          0.689453   0.900391  0.835938   \n",
      "F1 score                                      0   0.413793  0.517241   \n",
      "MCC: Matthews correlation coefficient       NaN   0.375983  0.455278   \n",
      "Informedness                                NaN   0.300582  0.359286   \n",
      "Markedness                                    0   0.470298  0.576918   \n",
      "Prevalence                                    0   0.105469   0.21875   \n",
      "LR+: Positive likelihood ratio              NaN    10.1778   9.45378   \n",
      "LR-: Negative likelihood ratio              NaN    0.68924  0.624767   \n",
      "DOR: Diagnostic odds ratio                  NaN    14.7667   15.1317   \n",
      "FOR: False omission rate                      0  0.0751566  0.148889   \n",
      "\n",
      "Classes                                       到达         售后        性能  \\\n",
      "Population                                   512        512       512   \n",
      "P: Condition positive                         47         48        55   \n",
      "N: Condition negative                        465        464       457   \n",
      "Test outcome positive                         41         42         0   \n",
      "Test outcome negative                        471        470       512   \n",
      "TP: True Positive                             20         24         0   \n",
      "TN: True Negative                            444        446       457   \n",
      "FP: False Positive                            21         18         0   \n",
      "FN: False Negative                            27         24        55   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.425532        0.5         0   \n",
      "TNR=SPC: (Specificity)                  0.954839   0.961207         1   \n",
      "PPV: Pos Pred Value (Precision)         0.487805   0.571429       NaN   \n",
      "NPV: Neg Pred Value                     0.942675   0.948936  0.892578   \n",
      "FPR: False-out                         0.0451613  0.0387931         0   \n",
      "FDR: False Discovery Rate               0.512195   0.428571       NaN   \n",
      "FNR: Miss Rate                          0.574468        0.5         1   \n",
      "ACC: Accuracy                            0.90625   0.917969  0.892578   \n",
      "F1 score                                0.454545   0.533333         0   \n",
      "MCC: Matthews correlation coefficient    0.40465   0.489894       NaN   \n",
      "Informedness                            0.380371   0.461207         0   \n",
      "Markedness                               0.43048   0.520365       NaN   \n",
      "Prevalence                             0.0917969    0.09375  0.107422   \n",
      "LR+: Positive likelihood ratio           9.42249    12.8889       NaN   \n",
      "LR-: Negative likelihood ratio          0.601639   0.520179         1   \n",
      "DOR: Diagnostic odds ratio               15.6614    24.7778       NaN   \n",
      "FOR: False omission rate               0.0573248  0.0510638  0.107422   \n",
      "\n",
      "Classes                                       机上         行程          计划  \\\n",
      "Population                                   512        512         512   \n",
      "P: Condition positive                         93         18           7   \n",
      "N: Condition negative                        419        494         505   \n",
      "Test outcome positive                         88         17           9   \n",
      "Test outcome negative                        424        495         503   \n",
      "TP: True Positive                             52         10           2   \n",
      "TN: True Negative                            383        487         498   \n",
      "FP: False Positive                            36          7           7   \n",
      "FN: False Negative                            41          8           5   \n",
      "TPR: (Sensitivity, hit rate, recall)     0.55914   0.555556    0.285714   \n",
      "TNR=SPC: (Specificity)                  0.914081    0.98583    0.986139   \n",
      "PPV: Pos Pred Value (Precision)         0.590909   0.588235    0.222222   \n",
      "NPV: Neg Pred Value                     0.903302   0.983838     0.99006   \n",
      "FPR: False-out                         0.0859189    0.01417   0.0138614   \n",
      "FDR: False Discovery Rate               0.409091   0.411765    0.777778   \n",
      "FNR: Miss Rate                           0.44086   0.444444    0.714286   \n",
      "ACC: Accuracy                           0.849609   0.970703    0.976562   \n",
      "F1 score                                0.574586   0.571429        0.25   \n",
      "MCC: Matthews correlation coefficient   0.483602   0.556518    0.240228   \n",
      "Informedness                            0.473221   0.541386    0.271853   \n",
      "Markedness                              0.494211   0.572074    0.212282   \n",
      "Prevalence                              0.181641  0.0351562   0.0136719   \n",
      "LR+: Positive likelihood ratio           6.50777    39.2063     20.6122   \n",
      "LR-: Negative likelihood ratio          0.482299   0.450833    0.724326   \n",
      "DOR: Diagnostic odds ratio               13.4932    86.9643     28.4571   \n",
      "FOR: False omission rate               0.0966981  0.0161616  0.00994036   \n",
      "\n",
      "Classes                                       设计         预订  \n",
      "Population                                   512        512  \n",
      "P: Condition positive                         12         66  \n",
      "N: Condition negative                        500        446  \n",
      "Test outcome positive                          0         61  \n",
      "Test outcome negative                        512        451  \n",
      "TP: True Positive                              0         39  \n",
      "TN: True Negative                            500        424  \n",
      "FP: False Positive                             0         22  \n",
      "FN: False Negative                            12         27  \n",
      "TPR: (Sensitivity, hit rate, recall)           0   0.590909  \n",
      "TNR=SPC: (Specificity)                         1   0.950673  \n",
      "PPV: Pos Pred Value (Precision)              NaN   0.639344  \n",
      "NPV: Neg Pred Value                     0.976562   0.940133  \n",
      "FPR: False-out                                 0  0.0493274  \n",
      "FDR: False Discovery Rate                    NaN   0.360656  \n",
      "FNR: Miss Rate                                 1   0.409091  \n",
      "ACC: Accuracy                           0.976562   0.904297  \n",
      "F1 score                                       0   0.614173  \n",
      "MCC: Matthews correlation coefficient        NaN   0.560209  \n",
      "Informedness                                   0   0.541582  \n",
      "Markedness                                   NaN   0.579477  \n",
      "Prevalence                             0.0234375   0.128906  \n",
      "LR+: Positive likelihood ratio               NaN    11.9793  \n",
      "LR-: Negative likelihood ratio                 1   0.430317  \n",
      "DOR: Diagnostic odds ratio                   NaN    27.8384  \n",
      "FOR: False omission rate               0.0234375   0.059867  \n"
     ]
    }
   ],
   "source": [
    "get_pred_performance(prob_matrix, labels, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
