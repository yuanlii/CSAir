{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readme: \n",
    "- for building 10 classifiers\n",
    "- implement cross validation for each label class + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from modeling_main import ReviewClassify\n",
    "from tokenization import Tokenization\n",
    "from help import get_tokenized_sent, get_stopwords\n",
    "\n",
    "from prepare_data import PrepareData\n",
    "from modeling import Modeling\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model,X_train,y_train):\n",
    "    ''' predict label for each review, by picking the class with highest probability'''\n",
    "    multi_class_clf = OneVsRestClassifier(model, n_jobs=-1)\n",
    "    multi_class_clf.fit(X_train, y_train)\n",
    "    # each review has proba for 10 classes\n",
    "    scores = multi_class_clf.predict_proba(X_test)\n",
    "    return scores\n",
    "\n",
    "def get_class_label_name(scores,idx):\n",
    "    ''' input a review index, and get the predicted label \n",
    "    (the one with highest probability) for this review'''\n",
    "    label_encoded = np.argmax(scores[idx])\n",
    "    return [key for key in labels_index if labels_index[key] ==label_encoded ].pop()\n",
    "\n",
    "def add_pred_to_df(scores, df):\n",
    "    '''add predicted labels to original df'''\n",
    "    predicted_labels = []\n",
    "    for i in range(len(scores)):\n",
    "        label_pred = get_class_label_name(scores,i)\n",
    "        predicted_labels.append(label_pred)\n",
    "    # add predicted labels to original test df\n",
    "    df['pred_label'] = predicted_labels\n",
    "    return df\n",
    "\n",
    "def get_confusion_matrix(y_test,y_pred):\n",
    "    '''get confusion matrix (tp,tn,fp,fn) for each class'''\n",
    "    cm = ConfusionMatrix(y_test, y_pred)\n",
    "    cm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    # updated: drop na values\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def split_data(data):\n",
    "    train, test = train_test_split(data, test_size = 0.33, random_state=42)\n",
    "#     print('training data has %d examples' %len(train))\n",
    "#     print('test data has %d examples' %len(test))\n",
    "    return train, test\n",
    "\n",
    "def preprocess_data(data, train, test):\n",
    "    '''use countvectorizer and tf-idf transformer to get valid one-hot encoding for reviews'''\n",
    "    # use countVectorizer for one-hot encoding\n",
    "    count_v0= CountVectorizer()\n",
    "    counts_all = count_v0.fit_transform(data['review_tokens'])\n",
    "    count_v1= CountVectorizer(vocabulary=count_v0.vocabulary_)  \n",
    "    counts_train = count_v1.fit_transform(train.review_tokens)\n",
    "\n",
    "    count_v2 = CountVectorizer(vocabulary=count_v0.vocabulary_)\n",
    "    counts_test = count_v2.fit_transform(test.review_tokens)\n",
    "\n",
    "    # implement tf-idf\n",
    "    tfidftransformer = TfidfTransformer()\n",
    "    train_data = tfidftransformer.fit(counts_train).transform(counts_train)\n",
    "    test_data = tfidftransformer.fit(counts_test).transform(counts_test)\n",
    "\n",
    "    X_train = train_data\n",
    "    # y_train = train.label_encoded\n",
    "    y_train = train.label_or_not.values\n",
    "    X_test = test_data\n",
    "    # y_test = test.label_encoded\n",
    "    y_test = test.label_or_not.values\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# multi-class modeling\n",
    "def multi_class_preprocess(data,label):\n",
    "    '''data preprocess for multi-class'''\n",
    "    data.loc[data.label == label, 'label_or_not'] = 1\n",
    "    data.loc[data.label != label, 'label_or_not'] = 0\n",
    "    return data\n",
    "\n",
    "def get_class_prior(data, label):\n",
    "    '''get class prior\n",
    "    class_prior = class_size / data_size'''\n",
    "    class_prior = len(data[data['label']== label]) / len(data)\n",
    "    return class_prior\n",
    "\n",
    "def get_class_threshold(class_prob, class_prior):\n",
    "    '''use class_priors are percentile for each class label '''\n",
    "    # there are 10 class in total\n",
    "    # col = 1 represent 'positive'\n",
    "    # first index represents the class, e.g., prob_scores[0][:,1] -> prob. when labeled as class 0 for each review\n",
    "    # class_prob = prob_scores[:,1] \n",
    "    # get the higher bound percentile\n",
    "    percentile = (1 - class_prior)*100\n",
    "    threshold = np.percentile(class_prob, percentile) \n",
    "    return threshold\n",
    "\n",
    "def get_label(idx, labels, positive_review_dct):\n",
    "    '''input an index and output a list of predicted labels'''\n",
    "    label_pred = []\n",
    "    for label in labels:\n",
    "        if idx in positive_review_dct[label]:\n",
    "            label_pred.append(label)\n",
    "    return label_pred\n",
    "\n",
    "def get_prob(data, model, parameters, label):\n",
    "    '''get probability predicted for one label class'''\n",
    "    label_data = multi_class_preprocess(data,label)\n",
    "    # split data\n",
    "    train, test = split_data(label_data)\n",
    "    # vectorize reviews\n",
    "    X_train, y_train, X_test, y_test = preprocess_data(label_data, train, test)\n",
    "    # implement gridSearch CV\n",
    "    model = GridSearchCV(model, parameters, cv=5)\n",
    "\n",
    "    # modeling\n",
    "    model.fit(X_train,y_train)\n",
    "    print('best params found:',model.best_params_)\n",
    "    \n",
    "    # get the proba score for one class (using the best model from gridSearch to predict)\n",
    "    class_prob = model.predict_proba(X_test)[:,1] \n",
    "    # e.g., class_proba: [0.15,0.3,...] => 512 records in total\n",
    "    class_prob_values = class_prob.reshape(-1,1)\n",
    "    return class_prob_values\n",
    "\n",
    "\n",
    "def manual_classify(data, label, class_prob):\n",
    "    '''classify by setting manual threshold of probability (for one class)'''\n",
    "    # get class_prior\n",
    "    class_prior = get_class_prior(data, label)\n",
    "    # set manual threshol\n",
    "    threshold = get_class_threshold(class_prob, class_prior)\n",
    "    class_labels = []\n",
    "    proba_dct = {}\n",
    "    for score in class_prob:\n",
    "        if score > threshold:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        class_labels.append(label)\n",
    "    positive_reviews = [ idx for idx in range(len(class_labels)) if class_labels[idx] == 1  ]\n",
    "    return positive_reviews\n",
    "\n",
    "# get label_picked for review with multiple labels predicted\n",
    "def pick_label(review_idx, label_pred):\n",
    "    '''compare proba of each label_pred, and pick the one with higher proba'''\n",
    "    # get label_idx\n",
    "    label_idx_dct = {}\n",
    "    for idx,label in enumerate(labels):\n",
    "        label_idx_dct[label] = idx\n",
    "  \n",
    "    # pick label\n",
    "    label_proba_dct = {}\n",
    "    for i,label_pred in enumerate(label_pred[review_idx]):\n",
    "        label_index = label_idx_dct.get(label_pred)\n",
    "        label_proba_dct[label_pred] = prob_matrix[review_idx,label_index]\n",
    "    label_picked = [key for key in label_proba_dct if label_proba_dct[key] == max(label_proba_dct.values())]\n",
    "    return label_picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['计划', '机上', '中转', '售后', '预订', '设计', '出发', '性能', '行程', '到达']\n",
      "best params found: {'C': 0.01, 'kernel': 'rbf'}\n",
      "best params found: {'C': 1, 'kernel': 'linear'}\n",
      "best params found: {'C': 0.01, 'kernel': 'rbf'}\n",
      "best params found: {'C': 1, 'kernel': 'linear'}\n",
      "best params found: {'C': 1, 'kernel': 'linear'}\n",
      "best params found: {'C': 0.01, 'kernel': 'rbf'}\n",
      "best params found: {'C': 1, 'kernel': 'linear'}\n",
      "best params found: {'C': 0.01, 'kernel': 'rbf'}\n",
      "best params found: {'C': 1, 'kernel': 'linear'}\n",
      "best params found: {'C': 1, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03375467, 0.05454271, 0.15538254, ..., 0.06944827, 0.01280634,\n",
       "        0.05841491],\n",
       "       [0.02844296, 0.97270841, 0.09694068, ..., 0.05976733, 0.01947459,\n",
       "        0.05530187],\n",
       "       [0.02067183, 0.00778895, 0.15588202, ..., 0.06336329, 0.0105126 ,\n",
       "        0.01583252],\n",
       "       ...,\n",
       "       [0.02314134, 0.44724948, 0.04617427, ..., 0.07676526, 0.02377081,\n",
       "        0.02293054],\n",
       "       [0.02290937, 0.04143466, 0.07170886, ..., 0.04852478, 0.0038417 ,\n",
       "        0.04418133],\n",
       "       [0.02498404, 0.15700019, 0.11438638, ..., 0.06054675, 0.01319073,\n",
       "        0.09520624]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_data('../res/labeled_data_with_without_tk.csv')\n",
    "# train, test data that include all label classes\n",
    "train, test = split_data(data)\n",
    "class_prob_values_dct = {}\n",
    "labels = data.label.unique().tolist()\n",
    "print(labels)\n",
    "for label in labels:\n",
    "    # SVC need to set 'probability=True'\n",
    "    model = SVC(probability=True)\n",
    "    parameters = {'kernel':('rbf', 'sigmoid','linear','poly'), 'C':[0.01,0.1,1,10]}\n",
    "    class_prob_values = get_prob(data, model, parameters, label)\n",
    "    class_prob_values_dct[label] = class_prob_values\n",
    "    \n",
    "prob_matrix = np.hstack((list(class_prob_values_dct.values())))\n",
    "prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_performance(prob_matrix, labels, test):\n",
    "    '''convert prediction result in proba_matrix to acutal df, and compute confusion matrix'''\n",
    "    # add prediction results into a dictionary\n",
    "    positive_review_dct = {}\n",
    "    for i,label in enumerate(labels):\n",
    "        positive_reviews = manual_classify(data, label, prob_matrix[:,i])\n",
    "        positive_review_dct[label] = positive_reviews\n",
    "    \n",
    "    # get reversed dictionary: key is the index of user review, value is the labels predicted\n",
    "    test_label_pred = {}\n",
    "    for idx in range(len(test)):\n",
    "        label_pred = get_label(idx,labels,positive_review_dct)\n",
    "        test_label_pred[idx] = label_pred\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "    # handle review with multiple labels\n",
    "        if len(test_label_pred[i]) > 1: \n",
    "            label_picked = pick_label(i,test_label_pred)\n",
    "            test_label_pred[i] = label_picked\n",
    "\n",
    "    # reput prediction into original dataframe\n",
    "    test_ = test.copy()\n",
    "    test_['predicted_labels'] = list(test_label_pred.values())\n",
    "    def formatting(row):\n",
    "        '''remove [] in the prediction result'''\n",
    "        if len(row) > 0:\n",
    "            return row[0]\n",
    "        else:\n",
    "            # np.nan is float, not supported for confusion matrix calculation, so change it to 'N/A'\n",
    "            return 'N/A'\n",
    "    test_['predicted_labels'] = test_['predicted_labels'].apply(formatting)\n",
    "    test_.head()\n",
    "    \n",
    "    # get confusion matrix\n",
    "    get_confusion_matrix(test_.label,test_.predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  N/A  中转  出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                         \n",
      "N/A          0   0   0   0   0   0   0   0   0   0   0        0\n",
      "中转          11  24  10   1   1   0   6   0   0   0   1       54\n",
      "出发           8  10  52  15   8   1  13   2   0   0   3      112\n",
      "到达           9   2   3  26   0   0   6   0   1   0   0       47\n",
      "售后           5   0  11   0  27   0   0   1   0   2   2       48\n",
      "性能           7   0   4   0   4  20   3   3   0   2  12       55\n",
      "机上          10   3   8   3   0   1  62   2   1   1   2       93\n",
      "行程           1   0   4   0   0   1   0   9   0   1   2       18\n",
      "计划           0   0   0   0   0   2   0   0   3   0   2        7\n",
      "设计           3   0   0   0   0   4   1   0   0   2   2       12\n",
      "预订          10   1   2   0   3   6   1   0   1   0  42       66\n",
      "__all__     64  40  94  45  43  35  92  17   6   8  68      512\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.521484375\n",
      "95% CI: (0.47722116615798144, 0.565498208856438)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 2.73116453205178e-66\n",
      "Kappa: 0.45428601259875406\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                  N/A         中转        出发         到达  \\\n",
      "Population                               512        512       512        512   \n",
      "P: Condition positive                      0         54       112         47   \n",
      "N: Condition negative                    512        458       400        465   \n",
      "Test outcome positive                     64         40        94         45   \n",
      "Test outcome negative                    448        472       418        467   \n",
      "TP: True Positive                          0         24        52         26   \n",
      "TN: True Negative                        448        442       358        446   \n",
      "FP: False Positive                        64         16        42         19   \n",
      "FN: False Negative                         0         30        60         21   \n",
      "TPR: (Sensitivity, hit rate, recall)     NaN   0.444444  0.464286   0.553191   \n",
      "TNR=SPC: (Specificity)                 0.875   0.965066     0.895    0.95914   \n",
      "PPV: Pos Pred Value (Precision)            0        0.6  0.553191   0.577778   \n",
      "NPV: Neg Pred Value                        1   0.936441  0.856459   0.955032   \n",
      "FPR: False-out                         0.125  0.0349345     0.105  0.0408602   \n",
      "FDR: False Discovery Rate                  1        0.4  0.446809   0.422222   \n",
      "FNR: Miss Rate                           NaN   0.555556  0.535714   0.446809   \n",
      "ACC: Accuracy                          0.875   0.910156  0.800781   0.921875   \n",
      "F1 score                                   0   0.510638  0.504854   0.565217   \n",
      "MCC: Matthews correlation coefficient    NaN   0.468698  0.383643    0.52247   \n",
      "Informedness                             NaN    0.40951  0.359286   0.512331   \n",
      "Markedness                                 0   0.536441  0.409651    0.53281   \n",
      "Prevalence                                 0   0.105469   0.21875  0.0917969   \n",
      "LR+: Positive likelihood ratio           NaN    12.7222   4.42177    13.5386   \n",
      "LR-: Negative likelihood ratio           NaN   0.575666  0.598563   0.465843   \n",
      "DOR: Diagnostic odds ratio               NaN       22.1    7.3873    29.0627   \n",
      "FOR: False omission rate                   0  0.0635593  0.143541  0.0449679   \n",
      "\n",
      "Classes                                       售后         性能         机上  \\\n",
      "Population                                   512        512        512   \n",
      "P: Condition positive                         48         55         93   \n",
      "N: Condition negative                        464        457        419   \n",
      "Test outcome positive                         43         35         92   \n",
      "Test outcome negative                        469        477        420   \n",
      "TP: True Positive                             27         20         62   \n",
      "TN: True Negative                            448        442        389   \n",
      "FP: False Positive                            16         15         30   \n",
      "FN: False Negative                            21         35         31   \n",
      "TPR: (Sensitivity, hit rate, recall)      0.5625   0.363636   0.666667   \n",
      "TNR=SPC: (Specificity)                  0.965517   0.967177   0.928401   \n",
      "PPV: Pos Pred Value (Precision)         0.627907   0.571429   0.673913   \n",
      "NPV: Neg Pred Value                     0.955224   0.926625    0.92619   \n",
      "FPR: False-out                         0.0344828  0.0328228   0.071599   \n",
      "FDR: False Discovery Rate               0.372093   0.428571   0.326087   \n",
      "FNR: Miss Rate                            0.4375   0.636364   0.333333   \n",
      "ACC: Accuracy                           0.927734   0.902344   0.880859   \n",
      "F1 score                                0.593407   0.444444    0.67027   \n",
      "MCC: Matthews correlation coefficient    0.55489    0.40591    0.59758   \n",
      "Informedness                            0.528017   0.330814   0.595068   \n",
      "Markedness                              0.583131   0.498053   0.600104   \n",
      "Prevalence                               0.09375   0.107422   0.181641   \n",
      "LR+: Positive likelihood ratio           16.3125    11.0788    9.31111   \n",
      "LR-: Negative likelihood ratio          0.453125    0.65796    0.35904   \n",
      "DOR: Diagnostic odds ratio                    36    16.8381    25.9333   \n",
      "FOR: False omission rate               0.0447761  0.0733753  0.0738095   \n",
      "\n",
      "Classes                                       行程          计划         设计  \\\n",
      "Population                                   512         512        512   \n",
      "P: Condition positive                         18           7         12   \n",
      "N: Condition negative                        494         505        500   \n",
      "Test outcome positive                         17           6          8   \n",
      "Test outcome negative                        495         506        504   \n",
      "TP: True Positive                              9           3          2   \n",
      "TN: True Negative                            486         502        494   \n",
      "FP: False Positive                             8           3          6   \n",
      "FN: False Negative                             9           4         10   \n",
      "TPR: (Sensitivity, hit rate, recall)         0.5    0.428571   0.166667   \n",
      "TNR=SPC: (Specificity)                  0.983806    0.994059      0.988   \n",
      "PPV: Pos Pred Value (Precision)         0.529412         0.5       0.25   \n",
      "NPV: Neg Pred Value                     0.981818    0.992095   0.980159   \n",
      "FPR: False-out                         0.0161943  0.00594059      0.012   \n",
      "FDR: False Discovery Rate               0.470588         0.5       0.75   \n",
      "FNR: Miss Rate                               0.5    0.571429   0.833333   \n",
      "ACC: Accuracy                           0.966797    0.986328    0.96875   \n",
      "F1 score                                0.514286    0.461538        0.2   \n",
      "MCC: Matthews correlation coefficient   0.497329    0.456042   0.188674   \n",
      "Informedness                            0.483806    0.422631   0.154667   \n",
      "Markedness                               0.51123    0.492095   0.230159   \n",
      "Prevalence                             0.0351562   0.0136719  0.0234375   \n",
      "LR+: Positive likelihood ratio            30.875     72.1429    13.8889   \n",
      "LR-: Negative likelihood ratio           0.50823    0.574843   0.843455   \n",
      "DOR: Diagnostic odds ratio                 60.75       125.5    16.4667   \n",
      "FOR: False omission rate               0.0181818  0.00790514  0.0198413   \n",
      "\n",
      "Classes                                       预订  \n",
      "Population                                   512  \n",
      "P: Condition positive                         66  \n",
      "N: Condition negative                        446  \n",
      "Test outcome positive                         68  \n",
      "Test outcome negative                        444  \n",
      "TP: True Positive                             42  \n",
      "TN: True Negative                            420  \n",
      "FP: False Positive                            26  \n",
      "FN: False Negative                            24  \n",
      "TPR: (Sensitivity, hit rate, recall)    0.636364  \n",
      "TNR=SPC: (Specificity)                  0.941704  \n",
      "PPV: Pos Pred Value (Precision)         0.617647  \n",
      "NPV: Neg Pred Value                     0.945946  \n",
      "FPR: False-out                          0.058296  \n",
      "FDR: False Discovery Rate               0.382353  \n",
      "FNR: Miss Rate                          0.363636  \n",
      "ACC: Accuracy                           0.902344  \n",
      "F1 score                                0.626866  \n",
      "MCC: Matthews correlation coefficient   0.570784  \n",
      "Informedness                            0.578068  \n",
      "Markedness                              0.563593  \n",
      "Prevalence                              0.128906  \n",
      "LR+: Positive likelihood ratio           10.9161  \n",
      "LR-: Negative likelihood ratio          0.386147  \n",
      "DOR: Diagnostic odds ratio               28.2692  \n",
      "FOR: False omission rate               0.0540541  \n"
     ]
    }
   ],
   "source": [
    "get_pred_performance(prob_matrix, labels, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
