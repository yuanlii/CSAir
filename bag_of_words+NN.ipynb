{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Readme:**\n",
    "This functions include two steps: <br>\n",
    " -- Step one is to implement bag-of-words to convert user reviews into word vectors <br>\n",
    " -- Step two is to implement a simple Neural Network to train a classifier based on word vectors created using bag-of-words in the previous stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the whole dataset include 1623 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>沿途 停靠 理解 延误 小时</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>飞机 无故 延误 小时 脸</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>行李 延误   重大损失</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>确认 航班 延误   订 票   显示 确认</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_tokens label\n",
       "0   11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...    出发\n",
       "1               航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解     出发\n",
       "2                重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班     出发\n",
       "3                                    沿途 停靠 理解 延误 小时     出发\n",
       "4                                     飞机 无故 延误 小时 脸     出发\n",
       "5  延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...    出发\n",
       "6  cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...    出发\n",
       "7  南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...    出发\n",
       "8                                      行李 延误   重大损失     出发\n",
       "9                            确认 航班 延误   订 票   显示 确认     出发"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "combine dataset (multiple categories) into one single category;\n",
    "add a column called 'label'\n",
    "'''\n",
    "\n",
    "files= glob.glob('../output_data/*.txt')\n",
    "\n",
    "df_lst = []\n",
    "for f in files:\n",
    "    label = f.split('/')[-1][:2]\n",
    "    df = pd.read_csv(f,header=None)\n",
    "    df['label'] = label\n",
    "    df_lst.append(df)\n",
    "\n",
    "all_df = pd.concat(df_lst)\n",
    "print('the whole dataset include %d reviews'%len(all_df))\n",
    "all_df = all_df.rename(columns = {0:'review_tokens'})\n",
    "all_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below implement a Neural Network based on word vectors after 'bag-of-words' approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set has 1623 training examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>沿途 停靠 理解 延误 小时</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>飞机 无故 延误 小时 脸</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_tokens label\n",
       "0   11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...    出发\n",
       "1               航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解     出发\n",
       "2                重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班     出发\n",
       "3                                    沿途 停靠 理解 延误 小时     出发\n",
       "4                                     飞机 无故 延误 小时 脸     出发"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('data set has %d training examples'%len(all_df))\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = all_df.label.unique().tolist()\n",
    "# create our training data\n",
    "training = []\n",
    "output = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bag-of-Words\n",
    "'''\n",
    "below using bag-of-words to convert reviews into word vectors\n",
    "'''\n",
    "\n",
    "import re\n",
    "\n",
    "all_reviews = ''\n",
    "for review in all_df['review_tokens'].values:\n",
    "    all_reviews+=review\n",
    "    all_reviews = re.sub(r'\\d+','',all_reviews)  # remove digits\n",
    "    \n",
    "# a list of all unique words ever appear in user reviews\n",
    "word_lst = list(set(all_reviews.split()))\n",
    "\n",
    "for idx in range(len(all_df)):\n",
    "    label = all_df.iloc[idx]['label']\n",
    "    review = all_df.iloc[idx]['review_tokens']\n",
    "    review = re.sub(r'\\d+','',review)\n",
    "    tokens = review.split()\n",
    "    \n",
    "    bag = [0]*len(word_lst)  \n",
    "    for token in tokens:\n",
    "        bag[word_lst.index(token)] = 1\n",
    "    training.append(np.array(bag))\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(label)] = 1 \n",
    "    output.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1623"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(training))\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3983 航班 做好 相关 会议 安排 11 月 17 日 收到 航班 延误 推迟 下午 13 40 CZ6408 航班 只好 解释 调整 会议 时间 12 点 飞机场 通知 时间 调整 下午 四点 二十 晚上 六点 起飞 飞机场 整整 六个 小时 一整天 做 事 一再 失信 生意 伙伴 信任 失望 \n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "print(all_df['review_tokens'].iloc[0]) # the first review\n",
    "print(training[0]) # the first traning example\n",
    "output[0]  # the first output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        np.random.seed(1)\n",
    "        self.synaptic_weights = 2 * np.random.random((4871, 10)) - 1   #random starting synaptic weights --> fit the shape of input data\n",
    "        self.output = []\n",
    "        \n",
    "    def __sigmoid(self,x):\n",
    "        return  1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self,x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in iter(range(number_of_training_iterations)):\n",
    "            output = self.think(training_set_inputs)\n",
    "            self.output.append(output)\n",
    "            error = training_set_outputs - output\n",
    "            adjustment = np.dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "            \n",
    "            self.synaptic_weights += adjustment\n",
    "            if (iteration % 100 == 0):           # here we calculate every 1000 iterations \n",
    "                print (\"error after %s iterations: %s\" % (iteration, str(np.mean(np.abs(error)))))\n",
    "                \n",
    "    def think(self, inputs):\n",
    "        return self.__sigmoid(np.dot(inputs, self.synaptic_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error after 0 iterations: 0.5051054383454322\n",
      "error after 100 iterations: 0.05794935703699803\n",
      "error after 200 iterations: 0.053463185762920196\n",
      "error after 300 iterations: 0.05086073545902663\n",
      "error after 400 iterations: 0.0485279970818316\n",
      "error after 500 iterations: 0.047803951285920916\n",
      "error after 600 iterations: 0.04652002000814068\n",
      "error after 700 iterations: 0.04617310898706783\n",
      "error after 800 iterations: 0.04562254886502111\n",
      "error after 900 iterations: 0.04462926201024846\n",
      "New synaptic weights after training: \n",
      "[[-0.69383858  0.33430924 -0.9998525  ... -0.31390752 -0.24052333\n",
      "   0.07744929]\n",
      " [-1.69443484  0.17171839 -0.70445646 ... -0.04693435 -1.00860108\n",
      "  -0.85799909]\n",
      " [ 2.45629673  0.80992955 -0.52975671 ... -1.2356938  -0.92297394\n",
      "   0.72247602]\n",
      " ...\n",
      " [-0.30099736 -0.75848004  0.53118438 ...  0.06455959 -0.65520357\n",
      "  -0.72378409]\n",
      " [-0.56536272 -0.34975075 -0.55708374 ... -0.52093481 -0.13449763\n",
      "  -1.02603128]\n",
      " [-0.23088864 -0.81449824 -0.59503592 ... -0.43183004 -0.4014115\n",
      "   0.1673847 ]]\n"
     ]
    }
   ],
   "source": [
    "neural_network = NeuralNetwork()\n",
    "\n",
    "training_set_inputs = np.array(training)\n",
    "training_set_outputs = np.array(output) \n",
    "\n",
    "neural_network.train(training_set_inputs, training_set_outputs, 1000)\n",
    "\n",
    "print (\"New synaptic weights after training: \")\n",
    "print (neural_network.synaptic_weights)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: implementation of Neural Network (https://github.com/ugik/notebooks/blob/master/Simple_Neural_Network.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.74985244e-01, 1.49937953e-45, 4.54781476e-43, ...,\n",
       "        6.33191557e-21, 2.87027266e-16, 1.10113033e-52],\n",
       "       [9.93001269e-01, 3.84562412e-20, 9.80287832e-19, ...,\n",
       "        3.21484003e-12, 2.47643941e-06, 6.43823921e-22],\n",
       "       [9.90022435e-01, 5.09659571e-30, 3.48220677e-26, ...,\n",
       "        3.55115887e-11, 7.40254746e-09, 1.53464486e-30],\n",
       "       ...,\n",
       "       [4.56632051e-12, 1.53511120e-14, 7.32727246e-07, ...,\n",
       "        7.26383317e-10, 2.40901445e-13, 1.03094790e-14],\n",
       "       [1.27359358e-11, 3.00595823e-84, 7.67401854e-70, ...,\n",
       "        1.79270355e-35, 7.19254826e-63, 2.10817550e-75],\n",
       "       [2.73093888e-04, 6.33731406e-07, 5.53600216e-01, ...,\n",
       "        8.30622326e-07, 4.12208825e-07, 4.30062604e-08]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the output of the last iteration\n",
    "neural_network.output[-1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
