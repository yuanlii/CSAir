{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "README: The scripts below used to build the basic pipeline of classification modeling. More to try include: <br>\n",
    " - embedding: try pretrained models\n",
    " - add: tf-idf processing\n",
    " - modeling: try other modeling methods except for naive bayes; hyperparameter tuning\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "os.chdir('/Users/liyuan/desktop/CSAir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the whole dataset include 1623 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>沿途 停靠 理解 延误 小时</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>飞机 无故 延误 小时 脸</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>行李 延误   重大损失</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>确认 航班 延误   订 票   显示 确认</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_tokens label\n",
       "0   11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...    出发\n",
       "1               航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解     出发\n",
       "2                重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班     出发\n",
       "3                                    沿途 停靠 理解 延误 小时     出发\n",
       "4                                     飞机 无故 延误 小时 脸     出发\n",
       "5  延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...    出发\n",
       "6  cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...    出发\n",
       "7  南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...    出发\n",
       "8                                      行李 延误   重大损失     出发\n",
       "9                            确认 航班 延误   订 票   显示 确认     出发"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "combine dataset (multiple categories) into one single category;\n",
    "add a column called 'label'\n",
    "'''\n",
    "\n",
    "files= glob.glob('./output_data/*.txt')\n",
    "\n",
    "df_lst = []\n",
    "for f in files:\n",
    "    label = f.split('/')[-1][:2]\n",
    "    df = pd.read_csv(f,header=None)\n",
    "    df['label'] = label\n",
    "    df_lst.append(df)\n",
    "\n",
    "all_df = pd.concat(df_lst)\n",
    "print('the whole dataset include %d reviews'%len(all_df))\n",
    "all_df = all_df.rename(columns = {0:'review_tokens'})\n",
    "all_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>沿途 停靠 理解 延误 小时</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>飞机 无故 延误 小时 脸</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_tokens label  label_encoded\n",
       "0   11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...    出发              1\n",
       "1               航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解     出发              1\n",
       "2                重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班     出发              1\n",
       "3                                    沿途 停靠 理解 延误 小时     出发              1\n",
       "4                                     飞机 无故 延误 小时 脸     出发              1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode text label into numbers\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(all_df.label)\n",
    "all_df['label_encoded'] = targets\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df.to_csv('res/all_labeled_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('res/all_labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'出发': 352, '到达': 147, '性能': 148, '售后': 166, '设计': 47, '计划': 38, '机上': 299, '预订': 218, '中转': 147, '行程': 61}\n"
     ]
    }
   ],
   "source": [
    "# get the data size for each label\n",
    "labels = all_df.label.unique().tolist()\n",
    "label_size = {}\n",
    "for label in labels:\n",
    "    label_size[label] = len(all_df[all_df.label == label])\n",
    "\n",
    "print(label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data has 1087 examples\n",
      "test data has 536 examples\n"
     ]
    }
   ],
   "source": [
    "### train test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(all_df, test_size=0.33, random_state=42)\n",
    "print('training data has %d examples' %len(train))\n",
    "print('test data has %d examples' %len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train is (1087, 4633)\n",
      "the shape of test is (536, 4633)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "\n",
    "# use countVectorizer for one-hot encoding\n",
    "count_v0= CountVectorizer();  \n",
    "counts_all = count_v0.fit_transform(all_df['review_tokens'])\n",
    "count_v1= CountVectorizer(vocabulary=count_v0.vocabulary_)  \n",
    " \n",
    "counts_train = count_v1.fit_transform(train.review_tokens)\n",
    "print (\"the shape of train is \"+repr(counts_train.shape))\n",
    "\n",
    "count_v2 = CountVectorizer(vocabulary=count_v0.vocabulary_)\n",
    "counts_test = count_v2.fit_transform(test.review_tokens)\n",
    "print (\"the shape of test is \"+repr(counts_test.shape))\n",
    "\n",
    "# implement tf-idf\n",
    "tfidftransformer = TfidfTransformer();    \n",
    "train_data = tfidftransformer.fit(counts_train).transform(counts_train);\n",
    "test_data = tfidftransformer.fit(counts_test).transform(counts_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1087, 4633)\n",
      "(536, 4633)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data\n",
    "y_train = train.label_encoded\n",
    "X_test = test_data\n",
    "y_test = test.label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(y_pred, y_test):\n",
    "    '''this function returns a precision score for the model'''\n",
    "    num = 0\n",
    "    y_pred = y_pred.tolist()\n",
    "    for i,pred in enumerate(y_pred):\n",
    "        if int(pred) == int(y_test.values[i]):\n",
    "            num += 1\n",
    "    precision = float(num) / len(y_pred)\n",
    "    print('precision: '+'{:.2f}'.format(precision))\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance of classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.56      0.48        39\n",
      "           1       0.48      0.50      0.49       116\n",
      "           2       0.50      0.37      0.43        59\n",
      "           3       0.52      0.57      0.54        53\n",
      "           4       0.34      0.27      0.30        56\n",
      "           5       0.64      0.58      0.61        93\n",
      "           6       0.40      0.38      0.39        21\n",
      "           7       0.11      0.12      0.12         8\n",
      "           8       0.26      0.46      0.33        13\n",
      "           9       0.49      0.50      0.50        78\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       536\n",
      "   macro avg       0.42      0.43      0.42       536\n",
      "weighted avg       0.48      0.48      0.48       536\n",
      "\n",
      "scores: [0.47511312 0.47945205 0.48165138 0.48372093 0.48130841]\n",
      "average accuracy score:0.48\n",
      "precision: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# use Naive bayes to build classifier\n",
    "clf = MultinomialNB(alpha = 0.01)   \n",
    "clf.fit(X_train, y_train);\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# get classification report\n",
    "result = classification_report(y_test, y_pred)\n",
    "print('performance of classifier:')\n",
    "print(result)\n",
    "\n",
    "# get average accuracy score across classes\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print('scores:',scores)\n",
    "print('average accuracy score:'+ '{:.2f}'.format(np.average(scores)))\n",
    "\n",
    "# use precision as evaluation metrics\n",
    "precision = get_precision(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1'}\n",
      "performance of classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55        39\n",
      "           1       0.56      0.56      0.56       116\n",
      "           2       0.75      0.46      0.57        59\n",
      "           3       0.68      0.51      0.58        53\n",
      "           4       0.56      0.18      0.27        56\n",
      "           5       0.44      0.87      0.58        93\n",
      "           6       0.76      0.62      0.68        21\n",
      "           7       0.33      0.12      0.18         8\n",
      "           8       0.62      0.38      0.48        13\n",
      "           9       0.66      0.62      0.64        78\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       536\n",
      "   macro avg       0.59      0.49      0.51       536\n",
      "weighted avg       0.59      0.56      0.54       536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# use logistic regression as classifier and use grid search to find best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {'penalty':('l1', 'l2'), 'C':[0.1, 1, 10]}\n",
    "model = LogisticRegression()\n",
    "\n",
    "# use \"f1_weightes\" as evaluation metrics (see below more explanation)\n",
    "clf = GridSearchCV(model, parameters, cv=5, scoring = 'f1_weighted')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance of classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.56      0.48        39\n",
      "           1       0.48      0.50      0.49       116\n",
      "           2       0.50      0.37      0.43        59\n",
      "           3       0.52      0.57      0.54        53\n",
      "           4       0.34      0.27      0.30        56\n",
      "           5       0.64      0.58      0.61        93\n",
      "           6       0.40      0.38      0.39        21\n",
      "           7       0.11      0.12      0.12         8\n",
      "           8       0.26      0.46      0.33        13\n",
      "           9       0.49      0.50      0.50        78\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       536\n",
      "   macro avg       0.42      0.43      0.42       536\n",
      "weighted avg       0.48      0.48      0.48       536\n",
      "\n",
      "precision: 0.48\n"
     ]
    }
   ],
   "source": [
    "# use the best parameter for logistic regression\n",
    "model = LogisticRegression(C=1, penalty='l1')\n",
    "y_pred = clf.predict(X_test)\n",
    "result = classification_report(y_test, y_pred)\n",
    "print('performance of classifier:')\n",
    "print(result)\n",
    "\n",
    "# use precision as evaluation metrics\n",
    "precision = get_precision(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance of classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.56      0.48        39\n",
      "           1       0.48      0.50      0.49       116\n",
      "           2       0.50      0.37      0.43        59\n",
      "           3       0.52      0.57      0.54        53\n",
      "           4       0.34      0.27      0.30        56\n",
      "           5       0.64      0.58      0.61        93\n",
      "           6       0.40      0.38      0.39        21\n",
      "           7       0.11      0.12      0.12         8\n",
      "           8       0.26      0.46      0.33        13\n",
      "           9       0.49      0.50      0.50        78\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       536\n",
      "   macro avg       0.42      0.43      0.42       536\n",
      "weighted avg       0.48      0.48      0.48       536\n",
      "\n",
      "precision: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# implement linearSVC\n",
    "model = SVC(kernel='linear')\n",
    "y_pred = clf.predict(X_test)\n",
    "result = classification_report(y_test, y_pred)\n",
    "print('performance of classifier:')\n",
    "print(result)\n",
    "\n",
    "# use precision as evaluation metrics\n",
    "precision = get_precision(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
