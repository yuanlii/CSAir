{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**readme**: This is used for divide chinese text into tokens, and output a .txt file for each of the category <br>\n",
    "('中转','出发','到达','售后','性能','机上','行程管理','计划','设计','预订'), the output files are stored in 'output_data'folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "\n",
    "import glob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_file(inputs_path,outputs_path):\n",
    "    '''\n",
    "    This function inputs the source data files, \n",
    "    and return the 分词 file as ouput.    \n",
    "    '''\n",
    "    \n",
    "    def stopwordslist(filepath):  \n",
    "        stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]  \n",
    "        return stopwords  \n",
    "\n",
    "    # 对句子进行分词  \n",
    "    def seg_sentence(sentence):  \n",
    "        sentence_seged = jieba.cut(sentence.strip())  \n",
    "        stopwords = stopwordslist('../stopwords.txt')  # 这里加载停用词的路径  \n",
    "        outstr = ''  \n",
    "        for word in sentence_seged:  \n",
    "            if word not in stopwords:  \n",
    "                if word != '\\t':  \n",
    "                    outstr += word  \n",
    "                    outstr += \" \"  \n",
    "        return outstr \n",
    "\n",
    "    # handle tf-idf (Q: tf-idf based on single doc. rather than the whole corpus? 有意义吗？)\n",
    "    def get_topN_tf_idf(content,topK=20):\n",
    "        tags = jieba.analyse.extract_tags(content, topK)\n",
    "        print(\" \".join(tags))\n",
    "    \n",
    "    inputs = open(inputs_path, 'r', encoding='utf-8')  \n",
    "    outputs = open(outputs_path, 'w')  \n",
    "    for line in inputs:  \n",
    "        line_seg = seg_sentence(line)  # 这里的返回值是字符串  \n",
    "#         line_seg = get_topN_tf_idf（line_seg,topK=20)  # 移除低频词\n",
    "        outputs.write(line_seg + '\\n')  \n",
    "    outputs.close()  \n",
    "    inputs.close() \n",
    "\n",
    "\n",
    "categories = ['中转','出发','到达','售后','性能','机上','行程管理','计划','设计','预订']\n",
    "    \n",
    "for cat in categories:\n",
    "    input_path = '../CSV_files/' + cat + '.csv'\n",
    "    output_path = '../output_data/' + cat + 'output.txt'\n",
    "    get_output_file(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
