{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "README: The scripts below used to build the basic pipeline of classification modeling. More to try include: <br>\n",
    " - embedding: try pretrained models\n",
    " - add: tf-idf processing\n",
    " - modeling: try other modeling methods except for naive bayes; hyperparameter tuning\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the whole dataset include 1623 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>沿途 停靠 理解 延误 小时</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>飞机 无故 延误 小时 脸</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>行李 延误   重大损失</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>确认 航班 延误   订 票   显示 确认</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_tokens label\n",
       "0   11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...    出发\n",
       "1               航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解     出发\n",
       "2                重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班     出发\n",
       "3                                    沿途 停靠 理解 延误 小时     出发\n",
       "4                                     飞机 无故 延误 小时 脸     出发\n",
       "5  延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...    出发\n",
       "6  cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...    出发\n",
       "7  南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...    出发\n",
       "8                                      行李 延误   重大损失     出发\n",
       "9                            确认 航班 延误   订 票   显示 确认     出发"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "combine dataset (multiple categories) into one single category;\n",
    "add a column called 'label'\n",
    "'''\n",
    "\n",
    "files= glob.glob('../output_data/*.txt')\n",
    "\n",
    "df_lst = []\n",
    "for f in files:\n",
    "    label = f.split('/')[-1][:2]\n",
    "    df = pd.read_csv(f,header=None)\n",
    "    df['label'] = label\n",
    "    df_lst.append(df)\n",
    "\n",
    "all_df = pd.concat(df_lst)\n",
    "print('the whole dataset include %d reviews'%len(all_df))\n",
    "all_df = all_df.rename(columns = {0:'review_tokens'})\n",
    "all_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'出发': 352, '到达': 147, '性能': 148, '售后': 166, '设计': 47, '计划': 38, '机上': 299, '预订': 218, '中转': 147, '行程': 61}\n"
     ]
    }
   ],
   "source": [
    "# get the data size for each label\n",
    "labels = all_df.label.unique().tolist()\n",
    "label_size = {}\n",
    "for label in labels:\n",
    "    label_size[label] = len(all_df[all_df.label == label])\n",
    "\n",
    "print(label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try bag-of-words for now\n",
    "def get_bag_of_words(training_df):\n",
    "    '''\n",
    "    input: a training set df that contains all data\n",
    "    output: a bag-of-words embedding of training data \n",
    "    '''\n",
    "    training = []\n",
    "    all_reviews = ''\n",
    "    for review in training_df['review_tokens'].values:\n",
    "        all_reviews+=review\n",
    "        all_reviews = re.sub(r'\\d+','',all_reviews)  # remove digits\n",
    "\n",
    "    # a list of all unique words ever appear in user reviews\n",
    "    word_lst = list(set(all_reviews.split()))\n",
    "\n",
    "    for idx in range(len(training_df)):\n",
    "        review = training_df.iloc[idx]['review_tokens']\n",
    "        review = re.sub(r'\\d+','',review)\n",
    "        tokens = review.split()\n",
    "\n",
    "        bag = [0]*len(word_lst)  \n",
    "        for token in tokens:\n",
    "            bag[word_lst.index(token)] = 1\n",
    "        training.append(np.array(bag))    \n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features are the X for all data; \n",
    "# since we cannot separate implementing bag-of-words on train and test, \n",
    "# because it would result in different lenthg of input\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "features = get_bag_of_words(all_df)\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(all_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of features and target\n",
    "X = np.array(features)\n",
    "y = np.array(targets).reshape((1623,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data has 1087 examples\n",
      "test data has 536 examples\n"
     ]
    }
   ],
   "source": [
    "### train test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "print('training data has %d examples' %len(X_train))\n",
    "print('test data has %d examples' %len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
