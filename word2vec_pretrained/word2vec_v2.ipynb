{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### readme: \n",
    "* reference: [在Keras模型中使用预训练的词向量](https://keras-cn-docs.readthedocs.io/zh_CN/latest/blog/word_embedding/)\n",
    "* summary: \n",
    "    - method: use pretrained word2vec 百度百科 + CNN\n",
    "    - performance: not good, based on metrics of [accuracy] and [confusion matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.chdir('/Users/liyuan/desktop/CSAir')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2vec():\n",
    "    def __init__(self):\n",
    "        self.embeddings_index = {}\n",
    "        self.MAX_SEQUENCE_LENGTH = 1000\n",
    "        self.MAX_NUM_WORDS = 20000\n",
    "        self.EMBEDDING_DIM = 300\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "        self.all_labeled_data = pd.DataFrame()\n",
    "        self.labels_index = {}\n",
    "        self.word_index  = {}\n",
    "        self.texts = np.array([])\n",
    "        self.labels = np.array([])\n",
    "        self.data = np.array([])\n",
    "        self.X_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "        self.X_val = np.array([])\n",
    "        self.y_val = np.array([])\n",
    "        self.embedding_matrix = np.array([])\n",
    "\n",
    "    def load_pretrained_vectors(self, file_path):\n",
    "        f = open(file_path)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            self.embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        print('Found %s word vectors.' % len(self.embeddings_index))\n",
    "        return self.embeddings_index \n",
    "\n",
    "    def prepare_data(self,data_file_path):\n",
    "        self.all_labeled_data = pd.read_csv(data_file_path)\n",
    "        self.texts = self.all_labeled_data.review_tokens.astype('str').values\n",
    "        self.labels = self.all_labeled_data.label_encoded.values\n",
    "        \n",
    "        # get a dictionary that map each original label to its encoded label, e.g., {'中转': 0,...}\n",
    "        for label in self.all_labeled_data.label.unique().tolist():\n",
    "            self.labels_index[label] = self.all_labeled_data[self.all_labeled_data['label'] == label]['label_encoded'].unique()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(nb_words=self.MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(self.texts)\n",
    "        sequences = tokenizer.texts_to_sequences(self.texts)\n",
    "\n",
    "        self.word_index = tokenizer.word_index\n",
    "        print('Found %s unique tokens.' % len(self.word_index))\n",
    "\n",
    "        self.data = pad_sequences(sequences, maxlen=self.MAX_SEQUENCE_LENGTH)\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "        \n",
    "        # Converts a class vector (integers) to binary class matrix\n",
    "        self.labels = to_categorical(np.asarray(self.labels))\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "\n",
    "        # split the data into a training set and a validation set\n",
    "        indices = np.arange(self.data.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        self.data = self.data[indices]\n",
    "        self.labels = self.labels[indices]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "\n",
    "        self.X_train = self.data[:-nb_validation_samples]\n",
    "        self.y_train = self.labels[:-nb_validation_samples]\n",
    "        self.X_val = self.data[-nb_validation_samples:]\n",
    "        self.y_val = self.labels[-nb_validation_samples:]\n",
    "        return  self.X_train, self.y_train, self.X_val, self.y_val\n",
    "    \n",
    "    def train_data(self):\n",
    "        # 据得到的字典生成上文所定义的词向量矩阵\n",
    "        self.embedding_matrix = np.zeros((len(self.word_index) + 1, self.EMBEDDING_DIM))\n",
    "        for word, i in self.word_index.items():\n",
    "            embedding_vector = self.embeddings_index.get(word)\n",
    "            # updated:\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                self.embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "        # 将这个词向量矩阵加载到Embedding层\n",
    "        embedding_layer = Embedding(len(self.word_index) + 1,\n",
    "                                    self.EMBEDDING_DIM,\n",
    "                                    weights=[self.embedding_matrix],\n",
    "                                    input_length=self.MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False)\n",
    "        \n",
    "        # 使用一个小型的1D卷积解决分类问题\n",
    "        sequence_input = Input(shape=(self.MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "        embedded_sequences = embedding_layer(sequence_input)\n",
    "        x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(35)(x)  # global max pooling\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        preds = Dense(len(self.labels_index), activation='softmax')(x)\n",
    "\n",
    "        model = Model(sequence_input, preds)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['acc'])\n",
    "        model.fit(self.X_train, self.y_train, validation_data=(self.X_val, self.y_val),\n",
    "                  nb_epoch=2, batch_size=128)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 635922 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/keras_preprocessing/text.py:177: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4747 unique tokens.\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551,)\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:104: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1241 samples, validate on 310 samples\n",
      "Epoch 1/2\n",
      "1241/1241 [==============================] - 31s 25ms/step - loss: 2.1573 - acc: 0.2176 - val_loss: 2.1632 - val_acc: 0.1645\n",
      "Epoch 2/2\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 1.9406 - acc: 0.2853 - val_loss: 1.9603 - val_acc: 0.2774\n"
     ]
    }
   ],
   "source": [
    "w2v = word2vec()\n",
    "embeddings_index = w2v.load_pretrained_vectors('./Source_Data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5')\n",
    "# X_train, y_train, X_val, y_val = w2v.prepare_data('./res/all_labeled_data_v3.csv')\n",
    "X_train, y_train, X_val, y_val = w2v.prepare_data('./res/labeled_data_with_without_tk.csv')\n",
    "model = w2v.train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding dictionary: {'计划': 7, '机上': 5, '中转': 0, '售后': 3, '预订': 9, '设计': 8, '出发': 1, '性能': 4, '行程': 6, '到达': 2}\n"
     ]
    }
   ],
   "source": [
    "# check label index\n",
    "print('label encoding dictionary:', w2v.labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 9, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 5, 9, 5, 5, 5, 5, 0, 5, 1, 5, 5, 5, 5, 5, 1, 0, 5, 1, 5, 5, 9, 1, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 9, 1, 5, 5, 5, 5, 9, 9, 1, 5, 5, 5, 1, 1, 5, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 9, 1, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 5, 1, 9, 5, 1, 5, 5, 9, 5, 1, 5, 5, 5, 5, 5, 5, 1, 1, 5, 5, 9, 5, 1, 9, 5, 5, 5, 1, 1, 5, 9, 9, 0, 5, 1, 0, 5, 0, 5, 1, 5, 1, 5, 5, 5, 5, 5, 9, 1, 5, 5, 5, 9, 5, 1, 5, 0, 9, 5, 5, 1, 5, 5, 5, 5, 5, 5, 9, 1, 5, 5, 1, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 1, 5, 5, 5, 1, 5, 5, 5, 5, 5, 1, 5, 5, 9, 9, 9, 5, 5, 5, 1, 5, 1, 9, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 9, 5, 9, 5, 5, 0, 5, 5, 1, 1, 0, 5, 5, 1, 5, 5, 5, 5, 5, 5, 9, 1, 5, 5, 9, 5, 5, 1, 9, 5, 5, 5, 0, 9, 1, 5, 5, 5, 5, 5, 5, 9, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 1, 5, 1, 5, 5, 5, 9, 5, 5, 1, 5, 5, 1, 1, 5, 1, 5, 5, 5, 5, 5, 5, 5, 9, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 9, 5, 1, 0, 9, 5]\n"
     ]
    }
   ],
   "source": [
    "# get predicted class label\n",
    "output = model.predict(X_val)\n",
    "predicted_label_list = []\n",
    "for i in range(len(output)):\n",
    "    predicted_label = output[i].argmax(axis=-1)\n",
    "    predicted_label_list.append(predicted_label)\n",
    "print(predicted_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 27.74%\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using model.evaluate()\n",
    "scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>一些未按照常规用户流程思路设计，开发者思维而不是使用者思维，使用体验差；补打电子票麻烦；内容...</td>\n",
       "      <td>未 常规 用户 流程 思路 设计 开发者 思维 使用者 思维 体验 差 补打 电子 票 麻烦...</td>\n",
       "      <td>设计</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>App上买机票居然自动分配座位，还是中间位置，不给选座机会，不如第三方软件，体验差！写着有修...</td>\n",
       "      <td>买 机票 自动 分配 座位 位置 选座 机会 第三方 软件 体验 差 写 修改 选座 点 只...</td>\n",
       "      <td>预订</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>明珠会员 每次失败</td>\n",
       "      <td>明珠 会员 每次 失败</td>\n",
       "      <td>性能</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>公务舱空乘服务非常好。</td>\n",
       "      <td>公务舱 空乘 服务</td>\n",
       "      <td>机上</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>航班延误以后，登机口升舱活动仍以原航班起飞时间为准办理，让人不理解</td>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  \\\n",
       "870   一些未按照常规用户流程思路设计，开发者思维而不是使用者思维，使用体验差；补打电子票麻烦；内容...   \n",
       "772   App上买机票居然自动分配座位，还是中间位置，不给选座机会，不如第三方软件，体验差！写着有修...   \n",
       "1301                                          明珠会员 每次失败   \n",
       "103                                         公务舱空乘服务非常好。   \n",
       "919                   航班延误以后，登机口升舱活动仍以原航班起飞时间为准办理，让人不理解   \n",
       "\n",
       "                                          review_tokens label  label_encoded  \n",
       "870   未 常规 用户 流程 思路 设计 开发者 思维 使用者 思维 体验 差 补打 电子 票 麻烦...    设计              8  \n",
       "772   买 机票 自动 分配 座位 位置 选座 机会 第三方 软件 体验 差 写 修改 选座 点 只...    预订              9  \n",
       "1301                                        明珠 会员 每次 失败    性能              4  \n",
       "103                                           公务舱 空乘 服务    机上              5  \n",
       "919                 航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解    出发              1  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# task: return prediction results back to df\n",
    "# -----------------------------------------\n",
    "# indices is a numpy array, need to convert to a list of indices before feed into df to get sub df\n",
    "# recreate df based on the shuffled indices\n",
    "all_labeled_data = w2v.all_labeled_data.iloc[list(indices)]\n",
    "nb_validation_samples = int(w2v.VALIDATION_SPLIT * w2v.data.shape[0])\n",
    "print(nb_validation_samples)\n",
    "# need to get the indices of the validation data\n",
    "train_val_bound = w2v.data.shape[0] - nb_validation_samples\n",
    "# get validation dataset\n",
    "val_df = all_labeled_data[train_val_bound:]\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 9, 5, 1, 1, 5, 5, 5, 5]\n",
      "{'计划': 7, '机上': 5, '中转': 0, '售后': 3, '预订': 9, '设计': 8, '出发': 1, '性能': 4, '行程': 6, '到达': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>一些未按照常规用户流程思路设计，开发者思维而不是使用者思维，使用体验差；补打电子票麻烦；内容...</td>\n",
       "      <td>未 常规 用户 流程 思路 设计 开发者 思维 使用者 思维 体验 差 补打 电子 票 麻烦...</td>\n",
       "      <td>设计</td>\n",
       "      <td>8</td>\n",
       "      <td>机上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>App上买机票居然自动分配座位，还是中间位置，不给选座机会，不如第三方软件，体验差！写着有修...</td>\n",
       "      <td>买 机票 自动 分配 座位 位置 选座 机会 第三方 软件 体验 差 写 修改 选座 点 只...</td>\n",
       "      <td>预订</td>\n",
       "      <td>9</td>\n",
       "      <td>机上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>明珠会员 每次失败</td>\n",
       "      <td>明珠 会员 每次 失败</td>\n",
       "      <td>性能</td>\n",
       "      <td>4</td>\n",
       "      <td>预订</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>公务舱空乘服务非常好。</td>\n",
       "      <td>公务舱 空乘 服务</td>\n",
       "      <td>机上</td>\n",
       "      <td>5</td>\n",
       "      <td>机上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>航班延误以后，登机口升舱活动仍以原航班起飞时间为准办理，让人不理解</td>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  \\\n",
       "870   一些未按照常规用户流程思路设计，开发者思维而不是使用者思维，使用体验差；补打电子票麻烦；内容...   \n",
       "772   App上买机票居然自动分配座位，还是中间位置，不给选座机会，不如第三方软件，体验差！写着有修...   \n",
       "1301                                          明珠会员 每次失败   \n",
       "103                                         公务舱空乘服务非常好。   \n",
       "919                   航班延误以后，登机口升舱活动仍以原航班起飞时间为准办理，让人不理解   \n",
       "\n",
       "                                          review_tokens label  label_encoded  \\\n",
       "870   未 常规 用户 流程 思路 设计 开发者 思维 使用者 思维 体验 差 补打 电子 票 麻烦...    设计              8   \n",
       "772   买 机票 自动 分配 座位 位置 选座 机会 第三方 软件 体验 差 写 修改 选座 点 只...    预订              9   \n",
       "1301                                        明珠 会员 每次 失败    性能              4   \n",
       "103                                           公务舱 空乘 服务    机上              5   \n",
       "919                 航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解    出发              1   \n",
       "\n",
       "     pred_label  \n",
       "870          机上  \n",
       "772          机上  \n",
       "1301         预订  \n",
       "103          机上  \n",
       "919          出发  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map predicted labels to original class\n",
    "print(predicted_label_list[:10])\n",
    "label_dct = w2v.labels_index\n",
    "print(label_dct)\n",
    "\n",
    "# get reversed labels_index dictionary\n",
    "reversed_label_dct = {}\n",
    "for i in range(len(label_dct)):\n",
    "    reversed_label_dct[list(label_dct.values())[i]] = list(label_dct.keys())[i]\n",
    "reversed_label_dct   \n",
    "# map predicted labels\n",
    "pred_label = [reversed_label_dct.get(label) for label in predicted_label_list]\n",
    "val_df['pred_label'] = pred_label\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  中转  出发  到达  售后  性能   机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                     \n",
      "中转          0   7   0   0   0   20   0   0   0   5       32\n",
      "出发          4  17   0   0   0   35   0   0   0   6       62\n",
      "到达          1   4   0   0   0   16   0   0   0   5       26\n",
      "售后          1   4   0   0   0   16   0   0   0   2       23\n",
      "性能          3   5   0   0   0   14   0   0   0   4       26\n",
      "机上          0  11   0   0   0   48   0   0   0   3       62\n",
      "行程          0   0   0   0   0    9   0   0   0   3       12\n",
      "计划          0   2   0   0   0    3   0   0   0   1        6\n",
      "设计          0   2   0   0   0   11   0   0   0   1       14\n",
      "预订          1   4   0   0   0   36   0   0   0   6       47\n",
      "__all__    10  56   0   0   0  208   0   0   0  36      310\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.22903225806451613\n",
      "95% CI: (0.1834298397205966, 0.2798963697544362)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 0.9999999999999999\n",
      "Kappa: 0.046706124549665474\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       中转        出发        到达  \\\n",
      "Population                                   310       310       310   \n",
      "P: Condition positive                         32        62        26   \n",
      "N: Condition negative                        278       248       284   \n",
      "Test outcome positive                         10        56         0   \n",
      "Test outcome negative                        300       254       310   \n",
      "TP: True Positive                              0        17         0   \n",
      "TN: True Negative                            268       209       284   \n",
      "FP: False Positive                            10        39         0   \n",
      "FN: False Negative                            32        45        26   \n",
      "TPR: (Sensitivity, hit rate, recall)           0  0.274194         0   \n",
      "TNR=SPC: (Specificity)                  0.964029  0.842742         1   \n",
      "PPV: Pos Pred Value (Precision)                0  0.303571       NaN   \n",
      "NPV: Neg Pred Value                     0.893333  0.822835  0.916129   \n",
      "FPR: False-out                         0.0359712  0.157258         0   \n",
      "FDR: False Discovery Rate                      1  0.696429       NaN   \n",
      "FNR: Miss Rate                                 1  0.725806         1   \n",
      "ACC: Accuracy                           0.864516  0.729032  0.916129   \n",
      "F1 score                                       0  0.288136         0   \n",
      "MCC: Matthews correlation coefficient  -0.061943  0.121579       NaN   \n",
      "Informedness                          -0.0359712  0.116935         0   \n",
      "Markedness                             -0.106667  0.126406       NaN   \n",
      "Prevalence                              0.103226       0.2  0.083871   \n",
      "LR+: Positive likelihood ratio                 0   1.74359       NaN   \n",
      "LR-: Negative likelihood ratio           1.03731  0.861244         1   \n",
      "DOR: Diagnostic odds ratio                     0    2.0245       NaN   \n",
      "FOR: False omission rate                0.106667  0.177165  0.083871   \n",
      "\n",
      "Classes                                       售后        性能         机上  \\\n",
      "Population                                   310       310        310   \n",
      "P: Condition positive                         23        26         62   \n",
      "N: Condition negative                        287       284        248   \n",
      "Test outcome positive                          0         0        208   \n",
      "Test outcome negative                        310       310        102   \n",
      "TP: True Positive                              0         0         48   \n",
      "TN: True Negative                            287       284         88   \n",
      "FP: False Positive                             0         0        160   \n",
      "FN: False Negative                            23        26         14   \n",
      "TPR: (Sensitivity, hit rate, recall)           0         0   0.774194   \n",
      "TNR=SPC: (Specificity)                         1         1   0.354839   \n",
      "PPV: Pos Pred Value (Precision)              NaN       NaN   0.230769   \n",
      "NPV: Neg Pred Value                     0.925806  0.916129   0.862745   \n",
      "FPR: False-out                                 0         0   0.645161   \n",
      "FDR: False Discovery Rate                    NaN       NaN   0.769231   \n",
      "FNR: Miss Rate                                 1         1   0.225806   \n",
      "ACC: Accuracy                           0.925806  0.916129    0.43871   \n",
      "F1 score                                       0         0   0.355556   \n",
      "MCC: Matthews correlation coefficient        NaN       NaN   0.109847   \n",
      "Informedness                                   0         0   0.129032   \n",
      "Markedness                                   NaN       NaN  0.0935143   \n",
      "Prevalence                             0.0741935  0.083871        0.2   \n",
      "LR+: Positive likelihood ratio               NaN       NaN        1.2   \n",
      "LR-: Negative likelihood ratio                 1         1   0.636364   \n",
      "DOR: Diagnostic odds ratio                   NaN       NaN    1.88571   \n",
      "FOR: False omission rate               0.0741935  0.083871   0.137255   \n",
      "\n",
      "Classes                                       行程         计划         设计  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         12          6         14   \n",
      "N: Condition negative                        298        304        296   \n",
      "Test outcome positive                          0          0          0   \n",
      "Test outcome negative                        310        310        310   \n",
      "TP: True Positive                              0          0          0   \n",
      "TN: True Negative                            298        304        296   \n",
      "FP: False Positive                             0          0          0   \n",
      "FN: False Negative                            12          6         14   \n",
      "TPR: (Sensitivity, hit rate, recall)           0          0          0   \n",
      "TNR=SPC: (Specificity)                         1          1          1   \n",
      "PPV: Pos Pred Value (Precision)              NaN        NaN        NaN   \n",
      "NPV: Neg Pred Value                      0.96129   0.980645   0.954839   \n",
      "FPR: False-out                                 0          0          0   \n",
      "FDR: False Discovery Rate                    NaN        NaN        NaN   \n",
      "FNR: Miss Rate                                 1          1          1   \n",
      "ACC: Accuracy                            0.96129   0.980645   0.954839   \n",
      "F1 score                                       0          0          0   \n",
      "MCC: Matthews correlation coefficient        NaN        NaN        NaN   \n",
      "Informedness                                   0          0          0   \n",
      "Markedness                                   NaN        NaN        NaN   \n",
      "Prevalence                             0.0387097  0.0193548  0.0451613   \n",
      "LR+: Positive likelihood ratio               NaN        NaN        NaN   \n",
      "LR-: Negative likelihood ratio                 1          1          1   \n",
      "DOR: Diagnostic odds ratio                   NaN        NaN        NaN   \n",
      "FOR: False omission rate               0.0387097  0.0193548  0.0451613   \n",
      "\n",
      "Classes                                       预订  \n",
      "Population                                   310  \n",
      "P: Condition positive                         47  \n",
      "N: Condition negative                        263  \n",
      "Test outcome positive                         36  \n",
      "Test outcome negative                        274  \n",
      "TP: True Positive                              6  \n",
      "TN: True Negative                            233  \n",
      "FP: False Positive                            30  \n",
      "FN: False Negative                            41  \n",
      "TPR: (Sensitivity, hit rate, recall)     0.12766  \n",
      "TNR=SPC: (Specificity)                  0.885932  \n",
      "PPV: Pos Pred Value (Precision)         0.166667  \n",
      "NPV: Neg Pred Value                     0.850365  \n",
      "FPR: False-out                          0.114068  \n",
      "FDR: False Discovery Rate               0.833333  \n",
      "FNR: Miss Rate                           0.87234  \n",
      "ACC: Accuracy                           0.770968  \n",
      "F1 score                                0.144578  \n",
      "MCC: Matthews correlation coefficient  0.0152144  \n",
      "Informedness                           0.0135911  \n",
      "Markedness                             0.0170316  \n",
      "Prevalence                              0.151613  \n",
      "LR+: Positive likelihood ratio           1.11915  \n",
      "LR-: Negative likelihood ratio          0.984659  \n",
      "DOR: Diagnostic odds ratio               1.13659  \n",
      "FOR: False omission rate                0.149635  \n"
     ]
    }
   ],
   "source": [
    "# evaluate performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "# get confusion matrix\n",
    "def get_confusion_matrix(y_test,y_pred):\n",
    "    '''get tp,tn,fp,fn for each class'''\n",
    "    cm = ConfusionMatrix(y_test, y_pred)\n",
    "    cm.print_stats()\n",
    "y_val_true = val_df.label.values\n",
    "y_val_pred = val_df.pred_label.values\n",
    "get_confusion_matrix(y_val_true,y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
