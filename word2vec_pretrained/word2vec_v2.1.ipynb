{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### readme: \n",
    "* reference: \n",
    "[在Keras模型中使用预训练的词向量](https://keras-cn-docs.readthedocs.io/zh_CN/latest/blog/word_embedding/)\n",
    "* summary: \n",
    "    - method: use pretrained word2vec 百度百科 + CNN\n",
    "    - TODO: plot **precision and recall curve** \n",
    "        - reference: \n",
    "            - [medium article](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a) + [github code](https://github.com/javaidnabi31/Multi-class-with-imbalanced-dataset-classification/blob/master/20-news-group-classification.ipynb)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from word2vec_v2 import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2vec():\n",
    "    def __init__(self):\n",
    "        self.embeddings_index = {}\n",
    "        self.MAX_SEQUENCE_LENGTH = 1000\n",
    "        self.MAX_NUM_WORDS = 20000\n",
    "        self.EMBEDDING_DIM = 300\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "        self.all_labeled_data = pd.DataFrame()\n",
    "        self.labels_index = {}\n",
    "        self.word_index  = {}\n",
    "        self.texts = np.array([])\n",
    "        self.labels = np.array([])\n",
    "        self.data = np.array([])\n",
    "        self.X_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "        self.X_val = np.array([])\n",
    "        self.y_val = np.array([])\n",
    "        self.embedding_matrix = np.array([])\n",
    "        # output is the vectorized predicted output (one-hot encoding of predicted label)\n",
    "        self.output = np.array([])\n",
    "\n",
    "    def load_pretrained_vectors(self, file_path):\n",
    "        f = open(file_path)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            self.embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        print('Found %s word vectors.' % len(self.embeddings_index))\n",
    "        return self.embeddings_index \n",
    "\n",
    "    def prepare_data(self,data_file_path):\n",
    "        self.all_labeled_data = pd.read_csv(data_file_path)\n",
    "        self.texts = self.all_labeled_data.review_tokens.astype('str').values\n",
    "        self.labels = self.all_labeled_data.label_encoded.values\n",
    "        \n",
    "        # get a dictionary that map each original label to its encoded label, e.g., {'中转': 0,...}\n",
    "        for label in self.all_labeled_data.label.unique().tolist():\n",
    "            self.labels_index[label] = self.all_labeled_data[self.all_labeled_data['label'] == label]['label_encoded'].unique()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(nb_words=self.MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(self.texts)\n",
    "        sequences = tokenizer.texts_to_sequences(self.texts)\n",
    "\n",
    "        self.word_index = tokenizer.word_index\n",
    "        print('Found %s unique tokens.' % len(self.word_index))\n",
    "\n",
    "        self.data = pad_sequences(sequences, maxlen=self.MAX_SEQUENCE_LENGTH)\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "        \n",
    "        # Converts a class vector (integers) to binary class matrix\n",
    "        self.labels = to_categorical(np.asarray(self.labels))\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "\n",
    "        # split the data into a training set and a validation set\n",
    "        self.indices = np.arange(self.data.shape[0])\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.data = self.data[self.indices]\n",
    "        self.labels = self.labels[self.indices]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "\n",
    "        self.X_train = self.data[:-nb_validation_samples]\n",
    "        self.y_train = self.labels[:-nb_validation_samples]\n",
    "        self.X_val = self.data[-nb_validation_samples:]\n",
    "        self.y_val = self.labels[-nb_validation_samples:]\n",
    "        return  self.X_train, self.y_train, self.X_val, self.y_val\n",
    "    \n",
    "    \n",
    "    def get_embedding_matrix(self):\n",
    "        # 据得到的字典生成上文所定义的词向量矩阵\n",
    "        embedding_matrix = np.zeros((len(self.word_index) + 1, self.EMBEDDING_DIM))\n",
    "        for word, i in self.word_index.items():\n",
    "            embedding_vector = self.embeddings_index.get(word)\n",
    "            # updated:\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    \n",
    "    def setup_neural_net(self):\n",
    "        # get word embedding matrix\n",
    "        self.embedding_matrix = self.get_embedding_matrix()\n",
    "\n",
    "        # 将这个词向量矩阵加载到Embedding层\n",
    "        embedding_layer = Embedding(len(self.word_index) + 1,\n",
    "                                    self.EMBEDDING_DIM,\n",
    "                                    weights=[self.embedding_matrix],\n",
    "                                    input_length=self.MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False)\n",
    "        \n",
    "        # 使用一个小型的1D卷积解决分类问题\n",
    "        sequence_input = Input(shape=(self.MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "        embedded_sequences = embedding_layer(sequence_input)\n",
    "        x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(35)(x)  # global max pooling\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        preds = Dense(len(self.labels_index), activation='softmax')(x)\n",
    "        return sequence_input,preds\n",
    "    \n",
    "    \n",
    "    def train_data(self,X_train,y_train,X_val,y_val):\n",
    "        sequence_input,preds = self.setup_neural_net()\n",
    "        model = Model(sequence_input, preds)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['acc'])\n",
    "        # can change the number of epoch accordingly\n",
    "        # 7 generates the best performance\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  nb_epoch=7, batch_size=128)  \n",
    "        \n",
    "        # evaluate model using model.evaluate()\n",
    "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "        # get predicted class label\n",
    "        self.output = model.predict(X_val)\n",
    "        predicted_label_list = self.get_pred_label(self.output)\n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def get_pred_label(self,output):\n",
    "        '''get predicted class label based on prediction output'''\n",
    "        predicted_label_list = []\n",
    "        for i in range(len(output)):\n",
    "            predicted_label = output[i].argmax(axis=-1)\n",
    "            predicted_label_list.append(predicted_label)        \n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def incorporate_pred_label(self):\n",
    "        '''return prediction results back to df'''\n",
    "        # indices is a numpy array, need to convert to a list of indices before feed into df to get sub df \n",
    "        # recreate df based on the shuffled indices\n",
    "        indices = self.indices\n",
    "        all_labeled_data = self.all_labeled_data.iloc[list(self.indices)]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "        print(nb_validation_samples)\n",
    "        # need to get the indices of the validation data\n",
    "        train_val_bound = self.data.shape[0] - nb_validation_samples\n",
    "        # get validation dataset\n",
    "        val_df = all_labeled_data[train_val_bound:]\n",
    "        return val_df\n",
    "\n",
    "    def map_label(self,df,predicted_label_list):\n",
    "        '''map predicted labels to original class'''\n",
    "        # print(predicted_label_list[:10])\n",
    "        label_dct = self.labels_index\n",
    "        df['pred_label_encodes'] = predicted_label_list\n",
    "        # get reversed labels_index dictionary\n",
    "        reversed_label_dct = {}\n",
    "        for i in range(len(label_dct)):\n",
    "            reversed_label_dct[list(label_dct.values())[i]] = list(label_dct.keys())[i]\n",
    "\n",
    "        # map predicted labels\n",
    "        pred_label = [reversed_label_dct.get(label) for label in predicted_label_list]\n",
    "        df['pred_label'] = pred_label\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def evaluate_performance(self,val_df):\n",
    "        # evaluate performance\n",
    "        y_val_true = val_df.label.values\n",
    "        y_val_pred = val_df.pred_label.values\n",
    "        self.get_confusion_matrix(y_val_true,y_val_pred) \n",
    "        \n",
    "    \n",
    "    def get_confusion_matrix(self,y_test,y_pred):\n",
    "        '''get tp,tn,fp,fn for each class'''\n",
    "        cm = ConfusionMatrix(y_test, y_pred)\n",
    "        cm.print_stats()\n",
    "        \n",
    "        \n",
    "    def over_sampling(self):\n",
    "        '''modeling after over sampling'''\n",
    "        smote = SMOTE('minority')\n",
    "        X_train_sm, y_train_sm = smote.fit_sample(self.X_train,self.y_train)\n",
    "        print(X_train_sm.shape, y_train_sm.shape)\n",
    "        \n",
    "        # fit model based on new data set\n",
    "        predicted_label_list = self.train_data(X_train_sm,y_train_sm,X_val,y_val)\n",
    "        return predicted_label_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 635922 word vectors.\n",
      "Found 4747 unique tokens.\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551,)\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/keras_preprocessing/text.py:177: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:118: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1241 samples, validate on 310 samples\n",
      "Epoch 1/7\n",
      "1241/1241 [==============================] - 39s 31ms/step - loss: 2.1804 - acc: 0.1926 - val_loss: 2.0725 - val_acc: 0.2581\n",
      "Epoch 2/7\n",
      "1241/1241 [==============================] - 39s 32ms/step - loss: 1.9744 - acc: 0.3014 - val_loss: 1.8935 - val_acc: 0.2710\n",
      "Epoch 3/7\n",
      "1241/1241 [==============================] - 36s 29ms/step - loss: 1.7466 - acc: 0.3658 - val_loss: 1.7035 - val_acc: 0.3968\n",
      "Epoch 4/7\n",
      "1241/1241 [==============================] - 33s 26ms/step - loss: 1.6265 - acc: 0.4206 - val_loss: 1.5560 - val_acc: 0.4774\n",
      "Epoch 5/7\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 1.4117 - acc: 0.5133 - val_loss: 1.4818 - val_acc: 0.4935\n",
      "Epoch 6/7\n",
      "1241/1241 [==============================] - 27s 22ms/step - loss: 1.3018 - acc: 0.5673 - val_loss: 1.7916 - val_acc: 0.4581\n",
      "Epoch 7/7\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 1.1894 - acc: 0.5898 - val_loss: 1.4860 - val_acc: 0.4968\n",
      "acc: 49.68%\n"
     ]
    }
   ],
   "source": [
    "w2v = word2vec()\n",
    "embeddings_index = w2v.load_pretrained_vectors('../Source_Data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5')\n",
    "# X_train, y_train, X_val, y_val = w2v.prepare_data('./res/all_labeled_data_v3.csv')\n",
    "X_train, y_train, X_val, y_val = w2v.prepare_data('../res/labeled_data_with_without_tk.csv')\n",
    "predicted_label_list = w2v.train_data(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding dictionary: {'计划': 7, '机上': 5, '中转': 0, '售后': 3, '预订': 9, '设计': 8, '出发': 1, '性能': 4, '行程': 6, '到达': 2}\n"
     ]
    }
   ],
   "source": [
    "# check label index\n",
    "print('label encoding dictionary:', w2v.labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>pred_label_encodes</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>垃圾南航，我选的靠走道位置，结果打印登机牌给我搞到中间位置，挤死人，真后悔一直选南航了</td>\n",
       "      <td>垃圾 南航 我选 走 道 位置 打印 登机牌 搞 位置 挤死 真 后悔 选 南航</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1，我购买的2018-11-12从沈阳到南京的机票为什么自动值机失败，今天因为晚到几分钟，误...</td>\n",
       "      <td>购买 沈阳 南京 机票 自动 值机 失败 晚到 几分钟 误 飞机 几次 客户 电话 咨询 机...</td>\n",
       "      <td>性能</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>该登机口也不通知，差评</td>\n",
       "      <td>登机口 通知 差评</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>登机后在地面等待大约二十分钟时间里客舱里极其闷热，温度大概超过三十度，很多旅客感到不适！经旅...</td>\n",
       "      <td>登机 地面 等待 二十分钟 时间 里 客舱 里 闷热 温度 超过 三十度 旅客 感到 不适 ...</td>\n",
       "      <td>机上</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>机上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>从w舱降为Y舱没有任何补偿，换飞机也不作任何解释。</td>\n",
       "      <td>舱降 舱 补偿 换 飞机 不作 解释</td>\n",
       "      <td>中转</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>机上</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  \\\n",
       "971         垃圾南航，我选的靠走道位置，结果打印登机牌给我搞到中间位置，挤死人，真后悔一直选南航了   \n",
       "1215  1，我购买的2018-11-12从沈阳到南京的机票为什么自动值机失败，今天因为晚到几分钟，误...   \n",
       "1158                                        该登机口也不通知，差评   \n",
       "212   登机后在地面等待大约二十分钟时间里客舱里极其闷热，温度大概超过三十度，很多旅客感到不适！经旅...   \n",
       "466                           从w舱降为Y舱没有任何补偿，换飞机也不作任何解释。   \n",
       "\n",
       "                                          review_tokens label  label_encoded  \\\n",
       "971            垃圾 南航 我选 走 道 位置 打印 登机牌 搞 位置 挤死 真 后悔 选 南航    出发              1   \n",
       "1215  购买 沈阳 南京 机票 自动 值机 失败 晚到 几分钟 误 飞机 几次 客户 电话 咨询 机...    性能              4   \n",
       "1158                                          登机口 通知 差评    出发              1   \n",
       "212   登机 地面 等待 二十分钟 时间 里 客舱 里 闷热 温度 超过 三十度 旅客 感到 不适 ...    机上              5   \n",
       "466                                  舱降 舱 补偿 换 飞机 不作 解释    中转              0   \n",
       "\n",
       "      pred_label_encodes pred_label  \n",
       "971                    1         出发  \n",
       "1215                   1         出发  \n",
       "1158                   1         出发  \n",
       "212                    5         机上  \n",
       "466                    5         机上  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = w2v.incorporate_pred_label()\n",
    "val_df = w2v.map_label(val_df,predicted_label_list)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  中转  出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                    \n",
      "中转         17   4   0   0   0   9   0   0   0   0       30\n",
      "出发          7  31   4   4   2  16   0   0   0   2       66\n",
      "到达          1  15   8   0   0   4   0   0   0   0       28\n",
      "售后          0   8   0   8   1   1   0   0   0   8       26\n",
      "性能          1   7   0   1  11   1   0   0   0  12       33\n",
      "机上          2   1   1   0   1  53   0   0   0   0       58\n",
      "行程          0   8   0   0   3   1   0   0   0   3       15\n",
      "计划          0   2   0   0   0   2   0   0   0   3        7\n",
      "设计          0   2   0   0   4   2   0   0   0   1        9\n",
      "预订          0   3   0   0   7   2   0   0   0  26       38\n",
      "__all__    28  81  13  13  29  91   0   0   0  55      310\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.4967741935483871\n",
      "95% CI: (0.4397660648390478, 0.5538445426624075)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 4.835326367628054e-14\n",
      "Kappa: 0.40212889586707373\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       中转        出发         到达  \\\n",
      "Population                                   310       310        310   \n",
      "P: Condition positive                         30        66         28   \n",
      "N: Condition negative                        280       244        282   \n",
      "Test outcome positive                         28        81         13   \n",
      "Test outcome negative                        282       229        297   \n",
      "TP: True Positive                             17        31          8   \n",
      "TN: True Negative                            269       194        277   \n",
      "FP: False Positive                            11        50          5   \n",
      "FN: False Negative                            13        35         20   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.566667  0.469697   0.285714   \n",
      "TNR=SPC: (Specificity)                  0.960714  0.795082    0.98227   \n",
      "PPV: Pos Pred Value (Precision)         0.607143  0.382716   0.615385   \n",
      "NPV: Neg Pred Value                     0.953901  0.847162    0.93266   \n",
      "FPR: False-out                         0.0392857  0.204918  0.0177305   \n",
      "FDR: False Discovery Rate               0.392857  0.617284   0.384615   \n",
      "FNR: Miss Rate                          0.433333  0.530303   0.714286   \n",
      "ACC: Accuracy                           0.922581  0.725806   0.919355   \n",
      "F1 score                                0.586207  0.421769   0.390244   \n",
      "MCC: Matthews correlation coefficient   0.543952  0.246712   0.383232   \n",
      "Informedness                            0.527381  0.264779   0.267984   \n",
      "Markedness                              0.561044  0.229878   0.548045   \n",
      "Prevalence                             0.0967742  0.212903  0.0903226   \n",
      "LR+: Positive likelihood ratio           14.4242   2.29212    16.1143   \n",
      "LR-: Negative likelihood ratio          0.451053  0.666979   0.727179   \n",
      "DOR: Diagnostic odds ratio                31.979   3.43657      22.16   \n",
      "FOR: False omission rate               0.0460993  0.152838  0.0673401   \n",
      "\n",
      "Classes                                       售后         性能         机上  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         26         33         58   \n",
      "N: Condition negative                        284        277        252   \n",
      "Test outcome positive                         13         29         91   \n",
      "Test outcome negative                        297        281        219   \n",
      "TP: True Positive                              8         11         53   \n",
      "TN: True Negative                            279        259        214   \n",
      "FP: False Positive                             5         18         38   \n",
      "FN: False Negative                            18         22          5   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.307692   0.333333   0.913793   \n",
      "TNR=SPC: (Specificity)                  0.982394   0.935018   0.849206   \n",
      "PPV: Pos Pred Value (Precision)         0.615385    0.37931   0.582418   \n",
      "NPV: Neg Pred Value                     0.939394   0.921708   0.977169   \n",
      "FPR: False-out                         0.0176056  0.0649819   0.150794   \n",
      "FDR: False Discovery Rate               0.384615    0.62069   0.417582   \n",
      "FNR: Miss Rate                          0.692308   0.666667  0.0862069   \n",
      "ACC: Accuracy                           0.925806   0.870968    0.86129   \n",
      "F1 score                                0.410256   0.354839   0.711409   \n",
      "MCC: Matthews correlation coefficient   0.401166   0.284216   0.653425   \n",
      "Informedness                            0.290087   0.268351   0.762999   \n",
      "Markedness                              0.554779   0.301019   0.559587   \n",
      "Prevalence                              0.083871   0.106452   0.187097   \n",
      "LR+: Positive likelihood ratio           17.4769    5.12963    6.05989   \n",
      "LR-: Negative likelihood ratio          0.704715   0.712999   0.101515   \n",
      "DOR: Diagnostic odds ratio                  24.8    7.19444    59.6947   \n",
      "FOR: False omission rate               0.0606061  0.0782918  0.0228311   \n",
      "\n",
      "Classes                                       行程         计划         设计  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         15          7          9   \n",
      "N: Condition negative                        295        303        301   \n",
      "Test outcome positive                          0          0          0   \n",
      "Test outcome negative                        310        310        310   \n",
      "TP: True Positive                              0          0          0   \n",
      "TN: True Negative                            295        303        301   \n",
      "FP: False Positive                             0          0          0   \n",
      "FN: False Negative                            15          7          9   \n",
      "TPR: (Sensitivity, hit rate, recall)           0          0          0   \n",
      "TNR=SPC: (Specificity)                         1          1          1   \n",
      "PPV: Pos Pred Value (Precision)              NaN        NaN        NaN   \n",
      "NPV: Neg Pred Value                     0.951613   0.977419   0.970968   \n",
      "FPR: False-out                                 0          0          0   \n",
      "FDR: False Discovery Rate                    NaN        NaN        NaN   \n",
      "FNR: Miss Rate                                 1          1          1   \n",
      "ACC: Accuracy                           0.951613   0.977419   0.970968   \n",
      "F1 score                                       0          0          0   \n",
      "MCC: Matthews correlation coefficient        NaN        NaN        NaN   \n",
      "Informedness                                   0          0          0   \n",
      "Markedness                                   NaN        NaN        NaN   \n",
      "Prevalence                             0.0483871  0.0225806  0.0290323   \n",
      "LR+: Positive likelihood ratio               NaN        NaN        NaN   \n",
      "LR-: Negative likelihood ratio                 1          1          1   \n",
      "DOR: Diagnostic odds ratio                   NaN        NaN        NaN   \n",
      "FOR: False omission rate               0.0483871  0.0225806  0.0290323   \n",
      "\n",
      "Classes                                       预订  \n",
      "Population                                   310  \n",
      "P: Condition positive                         38  \n",
      "N: Condition negative                        272  \n",
      "Test outcome positive                         55  \n",
      "Test outcome negative                        255  \n",
      "TP: True Positive                             26  \n",
      "TN: True Negative                            243  \n",
      "FP: False Positive                            29  \n",
      "FN: False Negative                            12  \n",
      "TPR: (Sensitivity, hit rate, recall)    0.684211  \n",
      "TNR=SPC: (Specificity)                  0.893382  \n",
      "PPV: Pos Pred Value (Precision)         0.472727  \n",
      "NPV: Neg Pred Value                     0.952941  \n",
      "FPR: False-out                          0.106618  \n",
      "FDR: False Discovery Rate               0.527273  \n",
      "FNR: Miss Rate                          0.315789  \n",
      "ACC: Accuracy                           0.867742  \n",
      "F1 score                                 0.55914  \n",
      "MCC: Matthews correlation coefficient   0.495846  \n",
      "Informedness                            0.577593  \n",
      "Markedness                              0.425668  \n",
      "Prevalence                              0.122581  \n",
      "LR+: Positive likelihood ratio           6.41742  \n",
      "LR-: Negative likelihood ratio          0.353476  \n",
      "DOR: Diagnostic odds ratio               18.1552  \n",
      "FOR: False omission rate               0.0470588  \n"
     ]
    }
   ],
   "source": [
    "# evaluate performance\n",
    "w2v.evaluate_performance(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1472, 1000) (1472, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:114: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1472 samples, validate on 310 samples\n",
      "Epoch 1/10\n",
      "1472/1472 [==============================] - 34s 23ms/step - loss: 2.1866 - acc: 0.1787 - val_loss: 2.1457 - val_acc: 0.1903\n",
      "Epoch 2/10\n",
      "1472/1472 [==============================] - 34s 23ms/step - loss: 2.0263 - acc: 0.2480 - val_loss: 2.1061 - val_acc: 0.1774\n",
      "Epoch 3/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.8239 - acc: 0.3696 - val_loss: 2.0873 - val_acc: 0.2581\n",
      "Epoch 4/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.5745 - acc: 0.4402 - val_loss: 1.8648 - val_acc: 0.3548\n",
      "Epoch 5/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.4550 - acc: 0.5034 - val_loss: 1.6944 - val_acc: 0.4484\n",
      "Epoch 6/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.2740 - acc: 0.5781 - val_loss: 1.8601 - val_acc: 0.3742\n",
      "Epoch 7/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.1756 - acc: 0.6012 - val_loss: 1.6974 - val_acc: 0.4323\n",
      "Epoch 8/10\n",
      "1472/1472 [==============================] - 32s 22ms/step - loss: 1.1093 - acc: 0.6168 - val_loss: 1.6140 - val_acc: 0.4452\n",
      "Epoch 9/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 0.9199 - acc: 0.6814 - val_loss: 1.5918 - val_acc: 0.4613\n",
      "Epoch 10/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 0.8903 - acc: 0.6997 - val_loss: 2.0732 - val_acc: 0.3581\n",
      "acc: 35.81%\n"
     ]
    }
   ],
   "source": [
    "# implement oversampling\n",
    "predicted_label_list_os = w2v.over_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'incorporate_pred_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-afd9fd4c082b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincorporate_pred_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_df_os\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted_label_list_os\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_df_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'incorporate_pred_label' is not defined"
     ]
    }
   ],
   "source": [
    "val_df = w2v.incorporate_pred_label()\n",
    "val_df_os = w2v.map_label(val_df,predicted_label_list_os)\n",
    "val_df_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  中转  出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                    \n",
      "中转          3   5   0   2   0   3   0  10   0   3       26\n",
      "出发          5  16  10   4   1   6   0  19   0  14       75\n",
      "到达          0   2  11   0   0   4   0  17   0   0       34\n",
      "售后          0   2   0  10   3   1   1   2   0   8       27\n",
      "性能          0   1   0   0   8   1   0   3   0   9       22\n",
      "机上          0   4   4   1   2  34   1   9   0   1       56\n",
      "行程          0   0   0   0   3   0   0   2   0   8       13\n",
      "计划          0   0   0   0   3   0   0   5   0   1        9\n",
      "设计          0   0   0   0   3   0   0   0   1   1        5\n",
      "预订          0   2   0   2   9   0   0   7   0  23       43\n",
      "__all__     8  32  25  19  32  49   2  74   1  68      310\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.3580645161290323\n",
      "95% CI: (0.304666114521708, 0.4142047918295947)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.6248443439288728e-06\n",
      "Kappa: 0.27474723724429817\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       中转         出发         到达  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         26         75         34   \n",
      "N: Condition negative                        284        235        276   \n",
      "Test outcome positive                          8         32         25   \n",
      "Test outcome negative                        302        278        285   \n",
      "TP: True Positive                              3         16         11   \n",
      "TN: True Negative                            279        219        262   \n",
      "FP: False Positive                             5         16         14   \n",
      "FN: False Negative                            23         59         23   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.115385   0.213333   0.323529   \n",
      "TNR=SPC: (Specificity)                  0.982394   0.931915   0.949275   \n",
      "PPV: Pos Pred Value (Precision)            0.375        0.5       0.44   \n",
      "NPV: Neg Pred Value                     0.923841    0.78777   0.919298   \n",
      "FPR: False-out                         0.0176056  0.0680851  0.0507246   \n",
      "FDR: False Discovery Rate                  0.625        0.5       0.56   \n",
      "FNR: Miss Rate                          0.884615   0.786667   0.676471   \n",
      "ACC: Accuracy                           0.909677   0.758065   0.880645   \n",
      "F1 score                                0.176471   0.299065   0.372881   \n",
      "MCC: Matthews correlation coefficient    0.17094   0.204446   0.313079   \n",
      "Informedness                            0.097779   0.145248   0.272805   \n",
      "Markedness                              0.298841    0.28777   0.359298   \n",
      "Prevalence                              0.083871   0.241935   0.109677   \n",
      "LR+: Positive likelihood ratio           6.55385    3.13333    6.37815   \n",
      "LR-: Negative likelihood ratio          0.900469    0.84414   0.712618   \n",
      "DOR: Diagnostic odds ratio               7.27826    3.71186    8.95031   \n",
      "FOR: False omission rate               0.0761589    0.21223  0.0807018   \n",
      "\n",
      "Classes                                       售后         性能         机上  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         27         22         56   \n",
      "N: Condition negative                        283        288        254   \n",
      "Test outcome positive                         19         32         49   \n",
      "Test outcome negative                        291        278        261   \n",
      "TP: True Positive                             10          8         34   \n",
      "TN: True Negative                            274        264        239   \n",
      "FP: False Positive                             9         24         15   \n",
      "FN: False Negative                            17         14         22   \n",
      "TPR: (Sensitivity, hit rate, recall)     0.37037   0.363636   0.607143   \n",
      "TNR=SPC: (Specificity)                  0.968198   0.916667   0.940945   \n",
      "PPV: Pos Pred Value (Precision)         0.526316       0.25   0.693878   \n",
      "NPV: Neg Pred Value                     0.941581    0.94964   0.915709   \n",
      "FPR: False-out                         0.0318021  0.0833333  0.0590551   \n",
      "FDR: False Discovery Rate               0.473684       0.75   0.306122   \n",
      "FNR: Miss Rate                           0.62963   0.636364   0.392857   \n",
      "ACC: Accuracy                           0.916129   0.877419   0.880645   \n",
      "F1 score                                0.434783   0.296296   0.647619   \n",
      "MCC: Matthews correlation coefficient   0.398014   0.236558    0.57802   \n",
      "Informedness                            0.338568   0.280303   0.548088   \n",
      "Markedness                              0.467897    0.19964   0.609586   \n",
      "Prevalence                             0.0870968  0.0709677   0.180645   \n",
      "LR+: Positive likelihood ratio           11.6461    4.36364     10.281   \n",
      "LR-: Negative likelihood ratio          0.650311   0.694215   0.417513   \n",
      "DOR: Diagnostic odds ratio               17.9085    6.28571    24.6242   \n",
      "FOR: False omission rate               0.0584192  0.0503597  0.0842912   \n",
      "\n",
      "Classes                                        行程         计划        设计  \\\n",
      "Population                                    310        310       310   \n",
      "P: Condition positive                          13          9         5   \n",
      "N: Condition negative                         297        301       305   \n",
      "Test outcome positive                           2         74         1   \n",
      "Test outcome negative                         308        236       309   \n",
      "TP: True Positive                               0          5         1   \n",
      "TN: True Negative                             295        232       305   \n",
      "FP: False Positive                              2         69         0   \n",
      "FN: False Negative                             13          4         4   \n",
      "TPR: (Sensitivity, hit rate, recall)            0   0.555556       0.2   \n",
      "TNR=SPC: (Specificity)                   0.993266   0.770764         1   \n",
      "PPV: Pos Pred Value (Precision)                 0  0.0675676         1   \n",
      "NPV: Neg Pred Value                      0.957792   0.983051  0.987055   \n",
      "FPR: False-out                         0.00673401   0.229236         0   \n",
      "FDR: False Discovery Rate                       1   0.932432         0   \n",
      "FNR: Miss Rate                                  1   0.444444       0.8   \n",
      "ACC: Accuracy                            0.951613   0.764516  0.987097   \n",
      "F1 score                                        0   0.120482  0.333333   \n",
      "MCC: Matthews correlation coefficient   -0.016859   0.128522   0.44431   \n",
      "Informedness                          -0.00673401    0.32632       0.2   \n",
      "Markedness                             -0.0422078  0.0506184  0.987055   \n",
      "Prevalence                              0.0419355  0.0290323  0.016129   \n",
      "LR+: Positive likelihood ratio                  0    2.42351       inf   \n",
      "LR-: Negative likelihood ratio            1.00678   0.576628       0.8   \n",
      "DOR: Diagnostic odds ratio                      0     4.2029       inf   \n",
      "FOR: False omission rate                0.0422078  0.0169492  0.012945   \n",
      "\n",
      "Classes                                       预订  \n",
      "Population                                   310  \n",
      "P: Condition positive                         43  \n",
      "N: Condition negative                        267  \n",
      "Test outcome positive                         68  \n",
      "Test outcome negative                        242  \n",
      "TP: True Positive                             23  \n",
      "TN: True Negative                            222  \n",
      "FP: False Positive                            45  \n",
      "FN: False Negative                            20  \n",
      "TPR: (Sensitivity, hit rate, recall)    0.534884  \n",
      "TNR=SPC: (Specificity)                  0.831461  \n",
      "PPV: Pos Pred Value (Precision)         0.338235  \n",
      "NPV: Neg Pred Value                     0.917355  \n",
      "FPR: False-out                          0.168539  \n",
      "FDR: False Discovery Rate               0.661765  \n",
      "FNR: Miss Rate                          0.465116  \n",
      "ACC: Accuracy                           0.790323  \n",
      "F1 score                                0.414414  \n",
      "MCC: Matthews correlation coefficient   0.305997  \n",
      "Informedness                            0.366344  \n",
      "Markedness                              0.255591  \n",
      "Prevalence                               0.13871  \n",
      "LR+: Positive likelihood ratio           3.17364  \n",
      "LR-: Negative likelihood ratio          0.559397  \n",
      "DOR: Diagnostic odds ratio               5.67333  \n",
      "FOR: False omission rate               0.0826446  \n"
     ]
    }
   ],
   "source": [
    "# evaluate performance after over sampling\n",
    "w2v.evaluate_performance(val_df_os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary: oversampling vs. non-oversampling has very similar result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking: y_train, y_val are prediction results already one-hot encoding\n",
    "y_train\n",
    "y_val # this is 'y_val_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output => probability of each review concerning each class label\n",
    "output = w2v.output\n",
    "# construct a result matrix, based on the output matrix (contain probability info)\n",
    "# pick the index of class(with highest proba) for each review\n",
    "picked_label_indices = [w2v.output[i].argmax(axis=-1) for i in range(len(output))]\n",
    "# print('labels picked for each review:', picked_label_indices)\n",
    "\n",
    "# initialize a res list\n",
    "res = []\n",
    "for i in range(len(output)):\n",
    "    # initialize a list with 0, e.g., [0,0,...0]\n",
    "    init = [0] * output.shape[1]\n",
    "    # set the picked label index to be 1, while the rest as 0\n",
    "    init[picked_label_indices[i]] = 1\n",
    "    res.append(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = np.array(res)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC score: 0.6479587034113676\n"
     ]
    }
   ],
   "source": [
    "# plot ROC_AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "score = roc_auc_score(y_val, y_val_pred)\n",
    "print('ROC_AUC score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-fc71b00765a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    520\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    521\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    395\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    396\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
     ]
    }
   ],
   "source": [
    "# TODO: plot precision and recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision_recall_curve(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
