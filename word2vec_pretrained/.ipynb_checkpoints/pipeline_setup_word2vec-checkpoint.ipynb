{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "README: The scripts below used to build the basic pipeline of classification modeling. More to try include: <br>\n",
    " - embedding: try pretrained models\n",
    " - add: tf-idf processing\n",
    " - modeling: try other modeling methods except for naive bayes; hyperparameter tuning\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the whole dataset include 1623 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>沿途 停靠 理解 延误 小时</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>飞机 无故 延误 小时 脸</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>行李 延误   重大损失</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>确认 航班 延误   订 票   显示 确认</td>\n",
       "      <td>出发</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       review_tokens label\n",
       "0   11 月 15 日 提前 预订 2018 年 11 月 27 日 长沙 飞往 沈阳 cz3...    出发\n",
       "1               航班 延误 登机口 升舱 活动 以原 航班 起飞时间 为准 办理 理解     出发\n",
       "2                重庆 乌鲁木齐 南航 航班 天气 原因 延误 和田 乘坐 天津 航班     出发\n",
       "3                                    沿途 停靠 理解 延误 小时     出发\n",
       "4                                     飞机 无故 延误 小时 脸     出发\n",
       "5  延误 五个 小时 算上 值机 时间 机场 八个 小时 早上 晚上 解释 解决方案 机长 人影...    出发\n",
       "6  cz3842 航班 延误 投诉无门 十点 五十 起飞 下午 三点 弄 飞机 两个 小时 告知...    出发\n",
       "7  南航 航班 延误 发 短信 太 严谨 回复 改 航班 用户名 密码 我要 变更 航班 做 延...    出发\n",
       "8                                      行李 延误   重大损失     出发\n",
       "9                            确认 航班 延误   订 票   显示 确认     出发"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "combine dataset (multiple categories) into one single category;\n",
    "add a column called 'label'\n",
    "'''\n",
    "\n",
    "files= glob.glob('../output_data/*.txt')\n",
    "\n",
    "df_lst = []\n",
    "for f in files:\n",
    "    label = f.split('/')[-1][:2]\n",
    "    df = pd.read_csv(f,header=None)\n",
    "    df['label'] = label\n",
    "    df_lst.append(df)\n",
    "\n",
    "all_df = pd.concat(df_lst)\n",
    "print('the whole dataset include %d reviews'%len(all_df))\n",
    "all_df = all_df.rename(columns = {0:'review_tokens'})\n",
    "all_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'出发': 352, '到达': 147, '性能': 148, '售后': 166, '设计': 47, '计划': 38, '机上': 299, '预订': 218, '中转': 147, '行程': 61}\n"
     ]
    }
   ],
   "source": [
    "# get the data size for each label\n",
    "labels = all_df.label.unique().tolist()\n",
    "label_size = {}\n",
    "for label in labels:\n",
    "    label_size[label] = len(all_df[all_df.label == label])\n",
    "\n",
    "print(label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try bag-of-words for now\n",
    "def get_bag_of_words(training_df):\n",
    "    '''\n",
    "    input: a training set df that contains all data\n",
    "    output: a bag-of-words embedding of training data \n",
    "    '''\n",
    "    training = []\n",
    "    all_reviews = ''\n",
    "    for review in training_df['review_tokens'].values:\n",
    "        all_reviews+=review\n",
    "        all_reviews = re.sub(r'\\d+','',all_reviews)  # remove digits\n",
    "\n",
    "    # a list of all unique words ever appear in user reviews\n",
    "    word_lst = list(set(all_reviews.split()))\n",
    "\n",
    "    for idx in range(len(training_df)):\n",
    "        review = training_df.iloc[idx]['review_tokens']\n",
    "        review = re.sub(r'\\d+','',review)\n",
    "        tokens = review.split()\n",
    "\n",
    "        bag = [0]*len(word_lst)  \n",
    "        for token in tokens:\n",
    "            bag[word_lst.index(token)] = 1\n",
    "        training.append(np.array(bag))    \n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features are the X for all data; \n",
    "# since we cannot separate implementing bag-of-words on train and test, \n",
    "# because it would result in different lenthg of input\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "features = get_bag_of_words(all_df)\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(all_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of features and target\n",
    "X = np.array(features)\n",
    "y = np.array(targets).reshape((1623,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data has 1087 examples\n",
      "test data has 536 examples\n"
     ]
    }
   ],
   "source": [
    "### train test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "print('training data has %d examples' %len(X_train))\n",
    "print('test data has %d examples' %len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_model_performance(model, X,y):\n",
    "    '''\n",
    "    input: the modeling methods, the entire data split into features(X) and target(y)\n",
    "    output: the accuracy score on test data\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "    print('training data has %d examples' %len(X_train))\n",
    "    print('test data has %d examples' %len(X_test))\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    model = model\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    # since accuracy cannot handle imbalance dataset, may cause Accuracy Paradox; using accuracy only get accuracy score\n",
    "    # over all classes;\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # sklearn \"classification_report\" returns precision, recall, f1-score for each target classes\n",
    "    result = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('model classification report', result)\n",
    "    # print(\"model accuracy score on test data: \"+\"{:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes performance:\n",
      "training data has 1087 examples\n",
      "test data has 536 examples\n",
      "model classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33        39\n",
      "           1       0.38      0.43      0.40       116\n",
      "           2       0.40      0.29      0.33        59\n",
      "           3       0.36      0.36      0.36        53\n",
      "           4       0.22      0.16      0.19        56\n",
      "           5       0.53      0.45      0.49        93\n",
      "           6       0.31      0.38      0.34        21\n",
      "           7       0.05      0.12      0.07         8\n",
      "           8       0.17      0.38      0.24        13\n",
      "           9       0.38      0.36      0.37        78\n",
      "\n",
      "   micro avg       0.36      0.36      0.36       536\n",
      "   macro avg       0.31      0.33      0.31       536\n",
      "weighted avg       0.37      0.36      0.36       536\n",
      "\n",
      "================================\n",
      "logistic regression performance:\n",
      "training data has 1087 examples\n",
      "test data has 536 examples\n",
      "model classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59        39\n",
      "           1       0.56      0.56      0.56       116\n",
      "           2       0.63      0.53      0.57        59\n",
      "           3       0.63      0.62      0.63        53\n",
      "           4       0.47      0.25      0.33        56\n",
      "           5       0.55      0.78      0.65        93\n",
      "           6       0.73      0.52      0.61        21\n",
      "           7       0.33      0.12      0.18         8\n",
      "           8       0.33      0.23      0.27        13\n",
      "           9       0.62      0.68      0.65        78\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       536\n",
      "   macro avg       0.54      0.49      0.50       536\n",
      "weighted avg       0.57      0.57      0.56       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Naive bayes performance:')\n",
    "get_model_performance(GaussianNB(),X,y)\n",
    "print('================================')\n",
    "\n",
    "print('logistic regression performance:')\n",
    "get_model_performance(LogisticRegression(),X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.33936652 0.31506849 0.3853211  0.31627907 0.3271028 ]\n",
      "average accuracy score:0.34\n"
     ]
    }
   ],
   "source": [
    "# implement cross validation on training data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "# implement 5-fold cross validation\n",
    "# TODO: cross validation for hyperparameter tuning\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print('scores:',scores)\n",
    "print('average accuracy score:'+ '{:.2f}'.format(np.average(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# find the best parameter by grid search for cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'penalty':('l1', 'l2'), 'C':[0.1, 1, 10]}\n",
    "model = LogisticRegression()\n",
    "\n",
    "# use \"f1_weightes\" as evaluation metrics (see below more explanation)\n",
    "clf = GridSearchCV(model, parameters, cv=5, scoring = 'f1_weighted')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). \n",
    "This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall. <br>\n",
    "reference: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score <br>\n",
    "other scoring metrics in sklearn: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression performance:\n",
      "training data has 1087 examples\n",
      "test data has 536 examples\n",
      "model classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60        39\n",
      "           1       0.60      0.56      0.58       116\n",
      "           2       0.62      0.58      0.60        59\n",
      "           3       0.63      0.49      0.55        53\n",
      "           4       0.47      0.27      0.34        56\n",
      "           5       0.53      0.77      0.63        93\n",
      "           6       0.70      0.67      0.68        21\n",
      "           7       0.40      0.25      0.31         8\n",
      "           8       0.38      0.38      0.38        13\n",
      "           9       0.63      0.62      0.62        78\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       536\n",
      "   macro avg       0.55      0.53      0.53       536\n",
      "weighted avg       0.57      0.57      0.56       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('logistic regression performance:')\n",
    "get_model_performance(LogisticRegression(C=1, penalty='l1'),X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next step:\n",
    " - do hyper-parameter tuning\n",
    " - may "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
