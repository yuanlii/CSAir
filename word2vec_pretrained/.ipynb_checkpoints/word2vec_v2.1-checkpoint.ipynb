{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### readme: \n",
    "* reference: [在Keras模型中使用预训练的词向量](https://keras-cn-docs.readthedocs.io/zh_CN/latest/blog/word_embedding/)\n",
    "* summary: \n",
    "    - method: use pretrained word2vec 百度百科 + CNN\n",
    "    - performance: not good, based on metrics of [accuracy] and [confusion matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from word2vec_v2 import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2vec():\n",
    "    def __init__(self):\n",
    "        self.embeddings_index = {}\n",
    "        self.MAX_SEQUENCE_LENGTH = 1000\n",
    "        self.MAX_NUM_WORDS = 20000\n",
    "        self.EMBEDDING_DIM = 300\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "        self.all_labeled_data = pd.DataFrame()\n",
    "        self.labels_index = {}\n",
    "        self.word_index  = {}\n",
    "        self.texts = np.array([])\n",
    "        self.labels = np.array([])\n",
    "        self.data = np.array([])\n",
    "        self.X_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "        self.X_val = np.array([])\n",
    "        self.y_val = np.array([])\n",
    "        self.embedding_matrix = np.array([])\n",
    "\n",
    "    def load_pretrained_vectors(self, file_path):\n",
    "        f = open(file_path)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            self.embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        print('Found %s word vectors.' % len(self.embeddings_index))\n",
    "        return self.embeddings_index \n",
    "\n",
    "    def prepare_data(self,data_file_path):\n",
    "        self.all_labeled_data = pd.read_csv(data_file_path)\n",
    "        self.texts = self.all_labeled_data.review_tokens.astype('str').values\n",
    "        self.labels = self.all_labeled_data.label_encoded.values\n",
    "        \n",
    "        # get a dictionary that map each original label to its encoded label, e.g., {'中转': 0,...}\n",
    "        for label in self.all_labeled_data.label.unique().tolist():\n",
    "            self.labels_index[label] = self.all_labeled_data[self.all_labeled_data['label'] == label]['label_encoded'].unique()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(nb_words=self.MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(self.texts)\n",
    "        sequences = tokenizer.texts_to_sequences(self.texts)\n",
    "\n",
    "        self.word_index = tokenizer.word_index\n",
    "        print('Found %s unique tokens.' % len(self.word_index))\n",
    "\n",
    "        self.data = pad_sequences(sequences, maxlen=self.MAX_SEQUENCE_LENGTH)\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "        \n",
    "        # Converts a class vector (integers) to binary class matrix\n",
    "        self.labels = to_categorical(np.asarray(self.labels))\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "\n",
    "        # split the data into a training set and a validation set\n",
    "        self.indices = np.arange(self.data.shape[0])\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.data = self.data[self.indices]\n",
    "        self.labels = self.labels[self.indices]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "\n",
    "        self.X_train = self.data[:-nb_validation_samples]\n",
    "        self.y_train = self.labels[:-nb_validation_samples]\n",
    "        self.X_val = self.data[-nb_validation_samples:]\n",
    "        self.y_val = self.labels[-nb_validation_samples:]\n",
    "        return  self.X_train, self.y_train, self.X_val, self.y_val\n",
    "    \n",
    "    \n",
    "    def get_embedding_matrix(self):\n",
    "        # 据得到的字典生成上文所定义的词向量矩阵\n",
    "        embedding_matrix = np.zeros((len(self.word_index) + 1, self.EMBEDDING_DIM))\n",
    "        for word, i in self.word_index.items():\n",
    "            embedding_vector = self.embeddings_index.get(word)\n",
    "            # updated:\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    \n",
    "    def setup_neural_net(self):\n",
    "        # get word embedding matrix\n",
    "        self.embedding_matrix = self.get_embedding_matrix()\n",
    "\n",
    "        # 将这个词向量矩阵加载到Embedding层\n",
    "        embedding_layer = Embedding(len(self.word_index) + 1,\n",
    "                                    self.EMBEDDING_DIM,\n",
    "                                    weights=[self.embedding_matrix],\n",
    "                                    input_length=self.MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False)\n",
    "        \n",
    "        # 使用一个小型的1D卷积解决分类问题\n",
    "        sequence_input = Input(shape=(self.MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "        embedded_sequences = embedding_layer(sequence_input)\n",
    "        x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(35)(x)  # global max pooling\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        preds = Dense(len(self.labels_index), activation='softmax')(x)\n",
    "        return sequence_input,preds\n",
    "    \n",
    "    \n",
    "    def train_data(self,X_train,y_train,X_val,y_val):\n",
    "        sequence_input,preds = self.setup_neural_net()\n",
    "        model = Model(sequence_input, preds)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['acc'])\n",
    "        # can change the number of epoch accordingly\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  nb_epoch=50, batch_size=128)  \n",
    "        \n",
    "        # evaluate model using model.evaluate()\n",
    "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "        # get predicted class label\n",
    "        output = model.predict(X_val)\n",
    "        predicted_label_list = self.get_pred_label(output)\n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def get_pred_label(self,output):\n",
    "        '''get predicted class label based on prediction output'''\n",
    "        predicted_label_list = []\n",
    "        for i in range(len(output)):\n",
    "            predicted_label = output[i].argmax(axis=-1)\n",
    "            predicted_label_list.append(predicted_label)        \n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def incorporate_pred_label(self):\n",
    "        '''return prediction results back to df'''\n",
    "        # indices is a numpy array, need to convert to a list of indices before feed into df to get sub df \n",
    "        # recreate df based on the shuffled indices\n",
    "        indices = self.indices\n",
    "        all_labeled_data = w2v.all_labeled_data.iloc[list(self.indices)]\n",
    "        nb_validation_samples = int(w2v.VALIDATION_SPLIT * w2v.data.shape[0])\n",
    "        print(nb_validation_samples)\n",
    "        # need to get the indices of the validation data\n",
    "        train_val_bound = w2v.data.shape[0] - nb_validation_samples\n",
    "        # get validation dataset\n",
    "        val_df = all_labeled_data[train_val_bound:]\n",
    "        return val_df\n",
    "\n",
    "    def map_label(self,df,predicted_label_list):\n",
    "        '''map predicted labels to original class'''\n",
    "        # print(predicted_label_list[:10])\n",
    "        label_dct = self.labels_index\n",
    "        df['pred_label_encodes'] = predicted_label_list\n",
    "        # get reversed labels_index dictionary\n",
    "        reversed_label_dct = {}\n",
    "        for i in range(len(label_dct)):\n",
    "            reversed_label_dct[list(label_dct.values())[i]] = list(label_dct.keys())[i]\n",
    "\n",
    "        # map predicted labels\n",
    "        pred_label = [reversed_label_dct.get(label) for label in predicted_label_list]\n",
    "        df['pred_label'] = pred_label\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def evaluate_performance(self,val_df):\n",
    "        # evaluate performance\n",
    "        y_val_true = val_df.label.values\n",
    "        y_val_pred = val_df.pred_label.values\n",
    "        self.get_confusion_matrix(y_val_true,y_val_pred) \n",
    "        \n",
    "    \n",
    "    def get_confusion_matrix(self,y_test,y_pred):\n",
    "        '''get tp,tn,fp,fn for each class'''\n",
    "        cm = ConfusionMatrix(y_test, y_pred)\n",
    "        cm.print_stats()\n",
    "        \n",
    "        \n",
    "    def over_sampling(self):\n",
    "        '''modeling after over sampling'''\n",
    "        smote = SMOTE('minority')\n",
    "        X_train_sm, y_train_sm = smote.fit_sample(self.X_train,self.y_train)\n",
    "        print(X_train_sm.shape, y_train_sm.shape)\n",
    "        \n",
    "        # fit model based on new data set\n",
    "        predicted_label_list = self.train_data(X_train_sm,y_train_sm,X_val,y_val)\n",
    "        return predicted_label_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 635922 word vectors.\n",
      "Found 4747 unique tokens.\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551,)\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551, 10)\n",
      "Train on 1241 samples, validate on 310 samples\n",
      "Epoch 1/10\n",
      "1241/1241 [==============================] - 29s 23ms/step - loss: 2.1820 - acc: 0.2047 - val_loss: 2.0602 - val_acc: 0.2903\n",
      "Epoch 2/10\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 2.0148 - acc: 0.2869 - val_loss: 1.8924 - val_acc: 0.4161\n",
      "Epoch 3/10\n",
      "1241/1241 [==============================] - 29s 23ms/step - loss: 1.8575 - acc: 0.3924 - val_loss: 1.9512 - val_acc: 0.2613\n",
      "Epoch 4/10\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 1.5734 - acc: 0.4424 - val_loss: 2.1272 - val_acc: 0.2677\n",
      "Epoch 5/10\n",
      "1241/1241 [==============================] - 29s 23ms/step - loss: 1.4889 - acc: 0.4883 - val_loss: 1.5468 - val_acc: 0.4710\n",
      "Epoch 6/10\n",
      "1241/1241 [==============================] - 29s 23ms/step - loss: 1.2811 - acc: 0.5552 - val_loss: 1.5846 - val_acc: 0.4581\n",
      "Epoch 7/10\n",
      "1241/1241 [==============================] - 28s 23ms/step - loss: 1.2451 - acc: 0.5641 - val_loss: 1.4144 - val_acc: 0.5161\n",
      "Epoch 8/10\n",
      "1241/1241 [==============================] - 28s 22ms/step - loss: 1.0925 - acc: 0.6124 - val_loss: 1.6152 - val_acc: 0.4387\n",
      "Epoch 9/10\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 1.0659 - acc: 0.6382 - val_loss: 1.6439 - val_acc: 0.4742\n",
      "Epoch 10/10\n",
      "1241/1241 [==============================] - 27s 21ms/step - loss: 0.9485 - acc: 0.6720 - val_loss: 1.4358 - val_acc: 0.5355\n",
      "acc: 53.55%\n"
     ]
    }
   ],
   "source": [
    "w2v = word2vec()\n",
    "embeddings_index = w2v.load_pretrained_vectors('../Source_Data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5')\n",
    "# X_train, y_train, X_val, y_val = w2v.prepare_data('./res/all_labeled_data_v3.csv')\n",
    "X_train, y_train, X_val, y_val = w2v.prepare_data('../res/labeled_data_with_without_tk.csv')\n",
    "predicted_label_list = w2v.train_data(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding dictionary: {'计划': 7, '机上': 5, '中转': 0, '售后': 3, '预订': 9, '设计': 8, '出发': 1, '性能': 4, '行程': 6, '到达': 2}\n"
     ]
    }
   ],
   "source": [
    "# check label index\n",
    "print('label encoding dictionary:', w2v.labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'计划': 7, '机上': 5, '中转': 0, '售后': 3, '预订': 9, '设计': 8, '出发': 1, '性能': 4, '行程': 6, '到达': 2}\n",
      "{7: '计划', 5: '机上', 0: '中转', 3: '售后', 9: '预订', 8: '设计', 1: '出发', 4: '性能', 6: '行程', 2: '到达'}\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "def map_label(w2v,df,predicted_label_list):\n",
    "    '''map predicted labels to original class'''\n",
    "    # print(predicted_label_list[:10])\n",
    "    label_dct = w2v.labels_index\n",
    "    df['pred_label_encodes'] = predicted_label_list\n",
    "    \n",
    "    # get reversed labels_index dictionary\n",
    "    reversed_label_dct = {}\n",
    "    for i in range(len(label_dct)):\n",
    "        reversed_label_dct[list(label_dct.values())[i]] = list(label_dct.keys())[i]\n",
    "\n",
    "    # map predicted labels\n",
    "    pred_label = [reversed_label_dct.get(label) for label in predicted_label_list]\n",
    "    df['pred_label'] = pred_label\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>托运行李等待1小时才取到。无语。</td>\n",
       "      <td>托运 行李 等待 小时 取到 语</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>飞机延误时间太长。</td>\n",
       "      <td>飞机 延误 时间 太 长</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>注册登陆使用繁琐，辣鸡</td>\n",
       "      <td>注册 登陆 繁琐 辣鸡</td>\n",
       "      <td>预订</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1. 济南机场2舱休息室也就是形同虚设，没有泡面，差评，咖啡机坏了，水桶的水发黄，2.空乘服...</td>\n",
       "      <td>济南 机场 舱 休息室 形同虚设 泡面 差评 咖啡机 坏 水桶 水 发黄 空乘 服务 算 热...</td>\n",
       "      <td>机上</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>11月24日从杭州到重庆的CZ8180航班因雾晚点，其他登机口各航空公司都有工作人员服务，南...</td>\n",
       "      <td>月 日 杭州 重庆 航班 因雾 晚点 登机口 航空公司 工作人员 服务 南航 登机口 上午 ...</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  \\\n",
       "1117                                   托运行李等待1小时才取到。无语。   \n",
       "1034                                          飞机延误时间太长。   \n",
       "751                                         注册登陆使用繁琐，辣鸡   \n",
       "304   1. 济南机场2舱休息室也就是形同虚设，没有泡面，差评，咖啡机坏了，水桶的水发黄，2.空乘服...   \n",
       "918   11月24日从杭州到重庆的CZ8180航班因雾晚点，其他登机口各航空公司都有工作人员服务，南...   \n",
       "\n",
       "                                          review_tokens label  label_encoded  \n",
       "1117                                   托运 行李 等待 小时 取到 语    出发              1  \n",
       "1034                                       飞机 延误 时间 太 长    出发              1  \n",
       "751                                         注册 登陆 繁琐 辣鸡    预订              9  \n",
       "304   济南 机场 舱 休息室 形同虚设 泡面 差评 咖啡机 坏 水桶 水 发黄 空乘 服务 算 热...    机上              5  \n",
       "918   月 日 杭州 重庆 航班 因雾 晚点 登机口 航空公司 工作人员 服务 南航 登机口 上午 ...    出发              1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = w2v.incorporate_pred_label()\n",
    "val_df = w2v.map_label(val_df,predicted_label_list)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  中转  出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                    \n",
      "中转          3   5   0   2   0   3   0  10   0   3       26\n",
      "出发          5  16  10   4   1   6   0  19   0  14       75\n",
      "到达          0   2  11   0   0   4   0  17   0   0       34\n",
      "售后          0   2   0  10   3   1   1   2   0   8       27\n",
      "性能          0   1   0   0   8   1   0   3   0   9       22\n",
      "机上          0   4   4   1   2  34   1   9   0   1       56\n",
      "行程          0   0   0   0   3   0   0   2   0   8       13\n",
      "计划          0   0   0   0   3   0   0   5   0   1        9\n",
      "设计          0   0   0   0   3   0   0   0   1   1        5\n",
      "预订          0   2   0   2   9   0   0   7   0  23       43\n",
      "__all__     8  32  25  19  32  49   2  74   1  68      310\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.3580645161290323\n",
      "95% CI: (0.304666114521708, 0.4142047918295947)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.6248443439288728e-06\n",
      "Kappa: 0.27474723724429817\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       中转         出发         到达  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         26         75         34   \n",
      "N: Condition negative                        284        235        276   \n",
      "Test outcome positive                          8         32         25   \n",
      "Test outcome negative                        302        278        285   \n",
      "TP: True Positive                              3         16         11   \n",
      "TN: True Negative                            279        219        262   \n",
      "FP: False Positive                             5         16         14   \n",
      "FN: False Negative                            23         59         23   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.115385   0.213333   0.323529   \n",
      "TNR=SPC: (Specificity)                  0.982394   0.931915   0.949275   \n",
      "PPV: Pos Pred Value (Precision)            0.375        0.5       0.44   \n",
      "NPV: Neg Pred Value                     0.923841    0.78777   0.919298   \n",
      "FPR: False-out                         0.0176056  0.0680851  0.0507246   \n",
      "FDR: False Discovery Rate                  0.625        0.5       0.56   \n",
      "FNR: Miss Rate                          0.884615   0.786667   0.676471   \n",
      "ACC: Accuracy                           0.909677   0.758065   0.880645   \n",
      "F1 score                                0.176471   0.299065   0.372881   \n",
      "MCC: Matthews correlation coefficient    0.17094   0.204446   0.313079   \n",
      "Informedness                            0.097779   0.145248   0.272805   \n",
      "Markedness                              0.298841    0.28777   0.359298   \n",
      "Prevalence                              0.083871   0.241935   0.109677   \n",
      "LR+: Positive likelihood ratio           6.55385    3.13333    6.37815   \n",
      "LR-: Negative likelihood ratio          0.900469    0.84414   0.712618   \n",
      "DOR: Diagnostic odds ratio               7.27826    3.71186    8.95031   \n",
      "FOR: False omission rate               0.0761589    0.21223  0.0807018   \n",
      "\n",
      "Classes                                       售后         性能         机上  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         27         22         56   \n",
      "N: Condition negative                        283        288        254   \n",
      "Test outcome positive                         19         32         49   \n",
      "Test outcome negative                        291        278        261   \n",
      "TP: True Positive                             10          8         34   \n",
      "TN: True Negative                            274        264        239   \n",
      "FP: False Positive                             9         24         15   \n",
      "FN: False Negative                            17         14         22   \n",
      "TPR: (Sensitivity, hit rate, recall)     0.37037   0.363636   0.607143   \n",
      "TNR=SPC: (Specificity)                  0.968198   0.916667   0.940945   \n",
      "PPV: Pos Pred Value (Precision)         0.526316       0.25   0.693878   \n",
      "NPV: Neg Pred Value                     0.941581    0.94964   0.915709   \n",
      "FPR: False-out                         0.0318021  0.0833333  0.0590551   \n",
      "FDR: False Discovery Rate               0.473684       0.75   0.306122   \n",
      "FNR: Miss Rate                           0.62963   0.636364   0.392857   \n",
      "ACC: Accuracy                           0.916129   0.877419   0.880645   \n",
      "F1 score                                0.434783   0.296296   0.647619   \n",
      "MCC: Matthews correlation coefficient   0.398014   0.236558    0.57802   \n",
      "Informedness                            0.338568   0.280303   0.548088   \n",
      "Markedness                              0.467897    0.19964   0.609586   \n",
      "Prevalence                             0.0870968  0.0709677   0.180645   \n",
      "LR+: Positive likelihood ratio           11.6461    4.36364     10.281   \n",
      "LR-: Negative likelihood ratio          0.650311   0.694215   0.417513   \n",
      "DOR: Diagnostic odds ratio               17.9085    6.28571    24.6242   \n",
      "FOR: False omission rate               0.0584192  0.0503597  0.0842912   \n",
      "\n",
      "Classes                                        行程         计划        设计  \\\n",
      "Population                                    310        310       310   \n",
      "P: Condition positive                          13          9         5   \n",
      "N: Condition negative                         297        301       305   \n",
      "Test outcome positive                           2         74         1   \n",
      "Test outcome negative                         308        236       309   \n",
      "TP: True Positive                               0          5         1   \n",
      "TN: True Negative                             295        232       305   \n",
      "FP: False Positive                              2         69         0   \n",
      "FN: False Negative                             13          4         4   \n",
      "TPR: (Sensitivity, hit rate, recall)            0   0.555556       0.2   \n",
      "TNR=SPC: (Specificity)                   0.993266   0.770764         1   \n",
      "PPV: Pos Pred Value (Precision)                 0  0.0675676         1   \n",
      "NPV: Neg Pred Value                      0.957792   0.983051  0.987055   \n",
      "FPR: False-out                         0.00673401   0.229236         0   \n",
      "FDR: False Discovery Rate                       1   0.932432         0   \n",
      "FNR: Miss Rate                                  1   0.444444       0.8   \n",
      "ACC: Accuracy                            0.951613   0.764516  0.987097   \n",
      "F1 score                                        0   0.120482  0.333333   \n",
      "MCC: Matthews correlation coefficient   -0.016859   0.128522   0.44431   \n",
      "Informedness                          -0.00673401    0.32632       0.2   \n",
      "Markedness                             -0.0422078  0.0506184  0.987055   \n",
      "Prevalence                              0.0419355  0.0290323  0.016129   \n",
      "LR+: Positive likelihood ratio                  0    2.42351       inf   \n",
      "LR-: Negative likelihood ratio            1.00678   0.576628       0.8   \n",
      "DOR: Diagnostic odds ratio                      0     4.2029       inf   \n",
      "FOR: False omission rate                0.0422078  0.0169492  0.012945   \n",
      "\n",
      "Classes                                       预订  \n",
      "Population                                   310  \n",
      "P: Condition positive                         43  \n",
      "N: Condition negative                        267  \n",
      "Test outcome positive                         68  \n",
      "Test outcome negative                        242  \n",
      "TP: True Positive                             23  \n",
      "TN: True Negative                            222  \n",
      "FP: False Positive                            45  \n",
      "FN: False Negative                            20  \n",
      "TPR: (Sensitivity, hit rate, recall)    0.534884  \n",
      "TNR=SPC: (Specificity)                  0.831461  \n",
      "PPV: Pos Pred Value (Precision)         0.338235  \n",
      "NPV: Neg Pred Value                     0.917355  \n",
      "FPR: False-out                          0.168539  \n",
      "FDR: False Discovery Rate               0.661765  \n",
      "FNR: Miss Rate                          0.465116  \n",
      "ACC: Accuracy                           0.790323  \n",
      "F1 score                                0.414414  \n",
      "MCC: Matthews correlation coefficient   0.305997  \n",
      "Informedness                            0.366344  \n",
      "Markedness                              0.255591  \n",
      "Prevalence                               0.13871  \n",
      "LR+: Positive likelihood ratio           3.17364  \n",
      "LR-: Negative likelihood ratio          0.559397  \n",
      "DOR: Diagnostic odds ratio               5.67333  \n",
      "FOR: False omission rate               0.0826446  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:330: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return(np.float64(self.TPR) / self.FPR)\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance\n",
    "w2v.evaluate_performance(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1472, 1000) (1472, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:114: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1472 samples, validate on 310 samples\n",
      "Epoch 1/10\n",
      "1472/1472 [==============================] - 34s 23ms/step - loss: 2.1866 - acc: 0.1787 - val_loss: 2.1457 - val_acc: 0.1903\n",
      "Epoch 2/10\n",
      "1472/1472 [==============================] - 34s 23ms/step - loss: 2.0263 - acc: 0.2480 - val_loss: 2.1061 - val_acc: 0.1774\n",
      "Epoch 3/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.8239 - acc: 0.3696 - val_loss: 2.0873 - val_acc: 0.2581\n",
      "Epoch 4/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.5745 - acc: 0.4402 - val_loss: 1.8648 - val_acc: 0.3548\n",
      "Epoch 5/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.4550 - acc: 0.5034 - val_loss: 1.6944 - val_acc: 0.4484\n",
      "Epoch 6/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.2740 - acc: 0.5781 - val_loss: 1.8601 - val_acc: 0.3742\n",
      "Epoch 7/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 1.1756 - acc: 0.6012 - val_loss: 1.6974 - val_acc: 0.4323\n",
      "Epoch 8/10\n",
      "1472/1472 [==============================] - 32s 22ms/step - loss: 1.1093 - acc: 0.6168 - val_loss: 1.6140 - val_acc: 0.4452\n",
      "Epoch 9/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 0.9199 - acc: 0.6814 - val_loss: 1.5918 - val_acc: 0.4613\n",
      "Epoch 10/10\n",
      "1472/1472 [==============================] - 31s 21ms/step - loss: 0.8903 - acc: 0.6997 - val_loss: 2.0732 - val_acc: 0.3581\n",
      "acc: 35.81%\n"
     ]
    }
   ],
   "source": [
    "# implement oversampling\n",
    "predicted_label_list_os = w2v.over_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>我投诉南航大连机场行李查询工作人员就坐在办公室玩手机不给客人解决问题</td>\n",
       "      <td>投诉 南航 大连 机场 行李 查询 工作人员 坐在 办公室 玩 手机 客人 解决问题</td>\n",
       "      <td>到达</td>\n",
       "      <td>2</td>\n",
       "      <td>计划</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>食物的新鲜度令人质疑，我吃的在飞机上上吐下泻，我伴侣也闹肚子了。非常不愉快的旅行经历...</td>\n",
       "      <td>食物 新鲜度 令人 质疑 吃 飞机 上吐下泻 伴侣 闹肚子 愉快 旅行 经历</td>\n",
       "      <td>机上</td>\n",
       "      <td>5</td>\n",
       "      <td>机上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>在北京中转办理托运行李希望改进 ，不要客户在服务大厅等托运行李，希望要改进</td>\n",
       "      <td>北京 中转 办理 托运 行李 希望 改进 客户 服务 大厅 托运 行李 希望 改进</td>\n",
       "      <td>到达</td>\n",
       "      <td>2</td>\n",
       "      <td>计划</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>很完美。。就是我申请了WiFi这个机舱竟然没有</td>\n",
       "      <td>完美 申请 机舱</td>\n",
       "      <td>性能</td>\n",
       "      <td>4</td>\n",
       "      <td>性能</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>进休息室才知道，真行啊你们南航！</td>\n",
       "      <td>进 休息室 真行 南航</td>\n",
       "      <td>出发</td>\n",
       "      <td>1</td>\n",
       "      <td>机上</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review  \\\n",
       "1419             我投诉南航大连机场行李查询工作人员就坐在办公室玩手机不给客人解决问题   \n",
       "214   食物的新鲜度令人质疑，我吃的在飞机上上吐下泻，我伴侣也闹肚子了。非常不愉快的旅行经历...   \n",
       "1513          在北京中转办理托运行李希望改进 ，不要客户在服务大厅等托运行李，希望要改进   \n",
       "1234                        很完美。。就是我申请了WiFi这个机舱竟然没有   \n",
       "1106                               进休息室才知道，真行啊你们南航！   \n",
       "\n",
       "                                   review_tokens label  label_encoded  \\\n",
       "1419  投诉 南航 大连 机场 行李 查询 工作人员 坐在 办公室 玩 手机 客人 解决问题    到达              2   \n",
       "214       食物 新鲜度 令人 质疑 吃 飞机 上吐下泻 伴侣 闹肚子 愉快 旅行 经历    机上              5   \n",
       "1513   北京 中转 办理 托运 行李 希望 改进 客户 服务 大厅 托运 行李 希望 改进    到达              2   \n",
       "1234                                    完美 申请 机舱    性能              4   \n",
       "1106                                 进 休息室 真行 南航    出发              1   \n",
       "\n",
       "     pred_label  \n",
       "1419         计划  \n",
       "214          机上  \n",
       "1513         计划  \n",
       "1234         性能  \n",
       "1106         机上  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = incorporate_pred_label(w2v)\n",
    "val_df_os = map_label(w2v,val_df,predicted_label_list_os)\n",
    "val_df_os.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  中转  出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                    \n",
      "中转          3   5   0   2   0   3   0  10   0   3       26\n",
      "出发          5  16  10   4   1   6   0  19   0  14       75\n",
      "到达          0   2  11   0   0   4   0  17   0   0       34\n",
      "售后          0   2   0  10   3   1   1   2   0   8       27\n",
      "性能          0   1   0   0   8   1   0   3   0   9       22\n",
      "机上          0   4   4   1   2  34   1   9   0   1       56\n",
      "行程          0   0   0   0   3   0   0   2   0   8       13\n",
      "计划          0   0   0   0   3   0   0   5   0   1        9\n",
      "设计          0   0   0   0   3   0   0   0   1   1        5\n",
      "预订          0   2   0   2   9   0   0   7   0  23       43\n",
      "__all__     8  32  25  19  32  49   2  74   1  68      310\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.3580645161290323\n",
      "95% CI: (0.304666114521708, 0.4142047918295947)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.6248443439288728e-06\n",
      "Kappa: 0.27474723724429817\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                       中转         出发         到达  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         26         75         34   \n",
      "N: Condition negative                        284        235        276   \n",
      "Test outcome positive                          8         32         25   \n",
      "Test outcome negative                        302        278        285   \n",
      "TP: True Positive                              3         16         11   \n",
      "TN: True Negative                            279        219        262   \n",
      "FP: False Positive                             5         16         14   \n",
      "FN: False Negative                            23         59         23   \n",
      "TPR: (Sensitivity, hit rate, recall)    0.115385   0.213333   0.323529   \n",
      "TNR=SPC: (Specificity)                  0.982394   0.931915   0.949275   \n",
      "PPV: Pos Pred Value (Precision)            0.375        0.5       0.44   \n",
      "NPV: Neg Pred Value                     0.923841    0.78777   0.919298   \n",
      "FPR: False-out                         0.0176056  0.0680851  0.0507246   \n",
      "FDR: False Discovery Rate                  0.625        0.5       0.56   \n",
      "FNR: Miss Rate                          0.884615   0.786667   0.676471   \n",
      "ACC: Accuracy                           0.909677   0.758065   0.880645   \n",
      "F1 score                                0.176471   0.299065   0.372881   \n",
      "MCC: Matthews correlation coefficient    0.17094   0.204446   0.313079   \n",
      "Informedness                            0.097779   0.145248   0.272805   \n",
      "Markedness                              0.298841    0.28777   0.359298   \n",
      "Prevalence                              0.083871   0.241935   0.109677   \n",
      "LR+: Positive likelihood ratio           6.55385    3.13333    6.37815   \n",
      "LR-: Negative likelihood ratio          0.900469    0.84414   0.712618   \n",
      "DOR: Diagnostic odds ratio               7.27826    3.71186    8.95031   \n",
      "FOR: False omission rate               0.0761589    0.21223  0.0807018   \n",
      "\n",
      "Classes                                       售后         性能         机上  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         27         22         56   \n",
      "N: Condition negative                        283        288        254   \n",
      "Test outcome positive                         19         32         49   \n",
      "Test outcome negative                        291        278        261   \n",
      "TP: True Positive                             10          8         34   \n",
      "TN: True Negative                            274        264        239   \n",
      "FP: False Positive                             9         24         15   \n",
      "FN: False Negative                            17         14         22   \n",
      "TPR: (Sensitivity, hit rate, recall)     0.37037   0.363636   0.607143   \n",
      "TNR=SPC: (Specificity)                  0.968198   0.916667   0.940945   \n",
      "PPV: Pos Pred Value (Precision)         0.526316       0.25   0.693878   \n",
      "NPV: Neg Pred Value                     0.941581    0.94964   0.915709   \n",
      "FPR: False-out                         0.0318021  0.0833333  0.0590551   \n",
      "FDR: False Discovery Rate               0.473684       0.75   0.306122   \n",
      "FNR: Miss Rate                           0.62963   0.636364   0.392857   \n",
      "ACC: Accuracy                           0.916129   0.877419   0.880645   \n",
      "F1 score                                0.434783   0.296296   0.647619   \n",
      "MCC: Matthews correlation coefficient   0.398014   0.236558    0.57802   \n",
      "Informedness                            0.338568   0.280303   0.548088   \n",
      "Markedness                              0.467897    0.19964   0.609586   \n",
      "Prevalence                             0.0870968  0.0709677   0.180645   \n",
      "LR+: Positive likelihood ratio           11.6461    4.36364     10.281   \n",
      "LR-: Negative likelihood ratio          0.650311   0.694215   0.417513   \n",
      "DOR: Diagnostic odds ratio               17.9085    6.28571    24.6242   \n",
      "FOR: False omission rate               0.0584192  0.0503597  0.0842912   \n",
      "\n",
      "Classes                                        行程         计划        设计  \\\n",
      "Population                                    310        310       310   \n",
      "P: Condition positive                          13          9         5   \n",
      "N: Condition negative                         297        301       305   \n",
      "Test outcome positive                           2         74         1   \n",
      "Test outcome negative                         308        236       309   \n",
      "TP: True Positive                               0          5         1   \n",
      "TN: True Negative                             295        232       305   \n",
      "FP: False Positive                              2         69         0   \n",
      "FN: False Negative                             13          4         4   \n",
      "TPR: (Sensitivity, hit rate, recall)            0   0.555556       0.2   \n",
      "TNR=SPC: (Specificity)                   0.993266   0.770764         1   \n",
      "PPV: Pos Pred Value (Precision)                 0  0.0675676         1   \n",
      "NPV: Neg Pred Value                      0.957792   0.983051  0.987055   \n",
      "FPR: False-out                         0.00673401   0.229236         0   \n",
      "FDR: False Discovery Rate                       1   0.932432         0   \n",
      "FNR: Miss Rate                                  1   0.444444       0.8   \n",
      "ACC: Accuracy                            0.951613   0.764516  0.987097   \n",
      "F1 score                                        0   0.120482  0.333333   \n",
      "MCC: Matthews correlation coefficient   -0.016859   0.128522   0.44431   \n",
      "Informedness                          -0.00673401    0.32632       0.2   \n",
      "Markedness                             -0.0422078  0.0506184  0.987055   \n",
      "Prevalence                              0.0419355  0.0290323  0.016129   \n",
      "LR+: Positive likelihood ratio                  0    2.42351       inf   \n",
      "LR-: Negative likelihood ratio            1.00678   0.576628       0.8   \n",
      "DOR: Diagnostic odds ratio                      0     4.2029       inf   \n",
      "FOR: False omission rate                0.0422078  0.0169492  0.012945   \n",
      "\n",
      "Classes                                       预订  \n",
      "Population                                   310  \n",
      "P: Condition positive                         43  \n",
      "N: Condition negative                        267  \n",
      "Test outcome positive                         68  \n",
      "Test outcome negative                        242  \n",
      "TP: True Positive                             23  \n",
      "TN: True Negative                            222  \n",
      "FP: False Positive                            45  \n",
      "FN: False Negative                            20  \n",
      "TPR: (Sensitivity, hit rate, recall)    0.534884  \n",
      "TNR=SPC: (Specificity)                  0.831461  \n",
      "PPV: Pos Pred Value (Precision)         0.338235  \n",
      "NPV: Neg Pred Value                     0.917355  \n",
      "FPR: False-out                          0.168539  \n",
      "FDR: False Discovery Rate               0.661765  \n",
      "FNR: Miss Rate                          0.465116  \n",
      "ACC: Accuracy                           0.790323  \n",
      "F1 score                                0.414414  \n",
      "MCC: Matthews correlation coefficient   0.305997  \n",
      "Informedness                            0.366344  \n",
      "Markedness                              0.255591  \n",
      "Prevalence                               0.13871  \n",
      "LR+: Positive likelihood ratio           3.17364  \n",
      "LR-: Negative likelihood ratio          0.559397  \n",
      "DOR: Diagnostic odds ratio               5.67333  \n",
      "FOR: False omission rate               0.0826446  \n"
     ]
    }
   ],
   "source": [
    "# evaluate performance after over sampling\n",
    "w2v.evaluate_performance(val_df_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary: oversampling vs. non-oversampling has very similar result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-b6a75eb85d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mevaluate_ROC_AUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df_os\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-b6a75eb85d87>\u001b[0m in \u001b[0;36mevaluate_ROC_AUC\u001b[0;34m(val_df)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_val_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# evaluate_ROC_AUC\n",
    "y_val_true = val_df.label.values\n",
    "y_val_pred = val_df.pred_label.values\n",
    "score = roc_auc_score(y_val_true, y_val_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
