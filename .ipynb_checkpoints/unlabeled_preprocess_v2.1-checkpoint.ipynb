{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**readme**: <br>\n",
    "scripts below are used to sample unlabeled data (5000) and tokenized text; <br>\n",
    "output tokenized unlabeled data is stored under res/tokenized_sampled_unlabeled_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "import glob\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from tokenization import Tokenization\n",
    "from unlabeled_preprocess import unlabeled_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反馈数据 in total has 24233 reviews\n",
      "反馈数据举3例： ['今天的CZ3539航班的毛毯质量很差，下来发现裤子上掉落很多毛。', '最近经常出现提前很久打电话预留前排靠过道位置，到机场就没有，一直道歉，作为高端客户，感觉很不好。', '最近航班服务经常出问题，提前很久打电话预留前排靠过道位置，到机场就没有物流，作为高端客户，对这样的服务很不满意。']\n"
     ]
    }
   ],
   "source": [
    "pu = unlabeled_preprocess()\n",
    "fk_reviews = pu.load_unlabeled_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output all 反馈数据 to txt file\n",
    "with open('../res/unlabeled_reviews_反馈数据.txt','w',newline='') as output_file:\n",
    "    for line in fk_reviews:\n",
    "        output_file.write(line + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/_d/b3chzbkx5vgg1wtjm942qj4m0000gn/T/jieba.cache\n",
      "Loading model cost 0.932 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# rewrite preprocessing into function\n",
    "def preprocess_review(reviews):\n",
    "    '''reviews => a list of reviews, including all reviews of unlabeled 反馈data'''\n",
    "    sents_tok_lst = []\n",
    "    stopwords = [line.strip() for line in open('../Source_Data/stopwords.txt', 'r', encoding='utf-8').readlines()]   \n",
    "    sents = reviews\n",
    "    for sent in sents:\n",
    "        tokenized_sent = ' '.join(word for word in jieba.cut(sent.strip()) if word not in stopwords)\n",
    "        # remove digit\n",
    "        tokenized_sent = re.sub(r'\\d+','',tokenized_sent)\n",
    "        # remove float\n",
    "        tokenized_sent = re.sub(r\"(\\d+\\.\\d+)\", '', tokenized_sent)\n",
    "        tokenized_sent = re.sub(r'[^\\w\\s]','', tokenized_sent)\n",
    "        # remove non-chinese characters\n",
    "        re_words = re.compile(u\"[\\u4e00-\\u9fa5]+\")\n",
    "        res = re.findall(re_words, tokenized_sent)\n",
    "        if res:\n",
    "            tokenized_sent = ' '.join([r for r in res])\n",
    "        sents_tok_lst.append(tokenized_sent)\n",
    "    return sents_tok_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess 反馈数据\n",
    "sents_tok_lst = preprocess_review(fk_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of tokenized unlabeled user review 24233\n",
      "take a look at the first 10 tokenized unlabeled data ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['航班 毛毯 质量 很差 发现 裤子 掉落 毛',\n",
       " '经常出现 提前 久 打电话 预留 前排 道 位置 机场 道歉 高端 客户 感觉 不好',\n",
       " '航班 服务 提前 久 打电话 预留 前排 道 位置 机场 物流 高端 客户 服务 满意',\n",
       " '买 明天 机票 航班 有效期',\n",
       " '南航 垃圾 航空公司 垃圾 程度 爆炸 坐火车 南航 交际',\n",
       " '预订 月 日晚 深圳 飞 沈阳 机票 贵航 机械故障 原因 单方面 取消 航班 全然不顾 我国 合同法 民用航空 法 国家民航总局 改签 第二天 航班 拒绝 经济 补偿 改动 被动 出差 在外 巨大损失 包括 承担 晚 住宿 餐饮 耽误 日 上午 沈阳 会议 贵航 单方面 拒绝 补偿 违法 详见 上传 照片 动用 微信 网络 推广 媒体 投诉 民航总局 维权',\n",
       " '我办 一张 招商银行 南航 明珠 信用卡 卡上 显示 会员号 输入 会员号 提示 账号',\n",
       " '机票 已订 发现 护照 号 错',\n",
       " '我订 月 号 月 号 广州 伦敦 双程 机票 订单 中 一位 护照 号 错 正确 姓名 叶苇 护照 号',\n",
       " '时间 标注 错误 小时 分钟 小时 分钟']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total length of tokenized unlabeled user review %d'%len(sents_tok_lst))\n",
    "print('take a look at the first 10 tokenized unlabeled data ...')\n",
    "sents_tok_lst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_reviews(reviews,sents_tok_lst, output_file_path):\n",
    "    '''format unlabeled data into df and output as csv file'''\n",
    "    # format unlabeled into a df\n",
    "    data = {}\n",
    "    data['reviews'] = reviews\n",
    "    data['review_tokens'] = sents_tok_lst\n",
    "    unlabeled_df = pd.DataFrame(data)\n",
    "\n",
    "    # output to csv file\n",
    "    unlabeled_df.to_csv(output_file_path, index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_reviews(fk_reviews,sents_tok_lst, '../res/unlabeled_review_反馈数据.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
