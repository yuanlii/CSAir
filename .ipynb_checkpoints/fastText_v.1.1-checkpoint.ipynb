{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readme: \n",
    "* TODO: used smaller amount of text to train fasttext\n",
    "* reference: \n",
    "  * [Using FastText models (not vectors) for robust embeddings](https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings)\n",
    "  * [Medium - Build your own Text classification with less than 25 lines of code using fasttext](https://medium.com/@ravindraprasad/build-your-own-text-classification-in-less-than-25-lines-of-code-using-fasttext-dae7229f80f9)\n",
    "  * [Medium - Learning FastText](https://towardsdatascience.com/fasttext-ea9009dba0e8)\n",
    "  * [Text Classification & Word Representations using FastText (An NLP library by Facebook)](https://www.analyticsvidhya.com/blog/2017/07/word-representations-text-classification-using-fasttext-nlp-facebook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "import fastText \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from semi_supervise import Semi_Supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1550 examples in labeled dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyuan/Desktop/CSAir/codes/semi_supervise.py:53: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  self.data_concat = pd.concat([self.labeled_data, self.unlabeled_data],ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>机票 改签 在线 申请 邮寄 行程 操作</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>购买 机票 优惠 劵</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>网上 选 座位</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>开具 电子 发票 程序 自动 去掉 正确 应为 劳动保护 杂志社</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我到现时用南方的app订票付款方式不能用到微信或支付宝，巳经多次找你们都解决不了问题？</td>\n",
       "      <td>现时 南方 订票 付款 方式 用到 微信 支付宝 巳 找 解决不了</td>\n",
       "      <td>预订</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4  我到现时用南方的app订票付款方式不能用到微信或支付宝，巳经多次找你们都解决不了问题？   \n",
       "\n",
       "                       review_tokens label  label_encoded  \n",
       "0               机票 改签 在线 申请 邮寄 行程 操作   N/A            NaN  \n",
       "1                         购买 机票 优惠 劵   N/A            NaN  \n",
       "2                            网上 选 座位   N/A            NaN  \n",
       "3   开具 电子 发票 程序 自动 去掉 正确 应为 劳动保护 杂志社   N/A            NaN  \n",
       "4  现时 南方 订票 付款 方式 用到 微信 支付宝 巳 找 解决不了    预订            9.0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- prepare data from user reviews to train FastText model ----\n",
    "# load data\n",
    "ss = Semi_Supervise()\n",
    "labeled_data = ss.load_labeled_data('../res/labeled_data_with_without_tk.csv')\n",
    "# load unlabeled data\n",
    "# unlabeled_data = ss.load_unlabeled_data_csv('../res/unlabeled_review_5000.csv')\n",
    "\n",
    "# load more unlabeled data ..\n",
    "unlabeled_data = ss.load_unlabeled_data_csv('../res/unlabeled_review_反馈数据.csv')\n",
    "# concatenate labeled and unlabeled data\n",
    "data_concat = ss.concat_data()\n",
    "data_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data to txt file => data would be feed into fasttext\n",
    "train_data = data_concat.review_tokens\n",
    "train_data.to_csv('../res/sampled_data_fasttext.txt', index = False)\n",
    "\n",
    "# Finished: locally train fasttext using labeled + unlabeled data (5000)\n",
    "# use command below to locally train skip-gram fasttext model: \n",
    "# ./fasttext skipgram -input ../fasttext_train_data/sampled_data_fasttext.txt -output ../fasttext_train_data/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fasttext():\n",
    "    def __init__(self):\n",
    "        self.embeddings_index = {}\n",
    "        self.MAX_SEQUENCE_LENGTH = 1000\n",
    "        self.MAX_NUM_WORDS = 20000\n",
    "        self.EMBEDDING_DIM = 300\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "        self.labels_index = {}\n",
    "        self.word_index  = {}\n",
    "    \n",
    "    def load_pretrained_model(self, model_path):\n",
    "        model_pretrained = fastText.load_model(model_path) \n",
    "        return model_pretrained\n",
    "    \n",
    "    def prepare_data(self,data_file_path):\n",
    "        self.all_labeled_data = pd.read_csv(data_file_path)\n",
    "        self.texts = self.all_labeled_data.review_tokens.astype('str').values\n",
    "        self.labels = self.all_labeled_data.label_encoded.values\n",
    "        \n",
    "        # get a dictionary that map each original label to its encoded label, e.g., {'中转': 0,...}\n",
    "        for label in self.all_labeled_data.label.unique().tolist():\n",
    "            self.labels_index[label] = self.all_labeled_data[self.all_labeled_data['label'] == label]['label_encoded'].unique()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(nb_words=self.MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(self.texts)\n",
    "        sequences = tokenizer.texts_to_sequences(self.texts)\n",
    "\n",
    "        self.word_index = tokenizer.word_index\n",
    "        print('Found %s unique tokens.' % len(self.word_index))\n",
    "\n",
    "        self.data = pad_sequences(sequences, maxlen=self.MAX_SEQUENCE_LENGTH)\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "        \n",
    "        # Converts a class vector (integers) to binary class matrix\n",
    "        self.labels = to_categorical(np.asarray(self.labels))\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "\n",
    "        # split the data into a training set and a validation set\n",
    "        self.indices = np.arange(self.data.shape[0])\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.data = self.data[self.indices]\n",
    "        self.labels = self.labels[self.indices]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "\n",
    "        self.X_train = self.data[:-nb_validation_samples]\n",
    "        self.y_train = self.labels[:-nb_validation_samples]\n",
    "        self.X_val = self.data[-nb_validation_samples:]\n",
    "        self.y_val = self.labels[-nb_validation_samples:]\n",
    "        return  self.X_train, self.y_train, self.X_val, self.y_val\n",
    "    \n",
    "    def get_embedding_matrix(self):\n",
    "        # 据得到的字典生成上文所定义的词向量矩阵\n",
    "        embedding_matrix = np.zeros((len(self.word_index) + 1, self.EMBEDDING_DIM))\n",
    "        for word, i in self.word_index.items():\n",
    "            embedding_vector = self.embeddings_index.get(word)\n",
    "            # updated:\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    \n",
    "    def setup_neural_net(self):\n",
    "        # get word embedding matrix\n",
    "        self.embedding_matrix = self.get_embedding_matrix()\n",
    "\n",
    "        # 将这个词向量矩阵加载到Embedding层\n",
    "        embedding_layer = Embedding(len(self.word_index) + 1,\n",
    "                                    self.EMBEDDING_DIM,\n",
    "                                    weights=[self.embedding_matrix],\n",
    "                                    input_length=self.MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False)\n",
    "        \n",
    "        # 使用一个小型的1D卷积解决分类问题\n",
    "        sequence_input = Input(shape=(self.MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "        embedded_sequences = embedding_layer(sequence_input)\n",
    "        x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(35)(x)  # global max pooling\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        preds = Dense(len(self.labels_index), activation='softmax')(x)\n",
    "        return sequence_input,preds\n",
    "    \n",
    "    \n",
    "    def train_data(self,X_train,y_train,X_val,y_val):\n",
    "        sequence_input,preds = self.setup_neural_net()\n",
    "        model = Model(sequence_input, preds)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['acc'])\n",
    "        # can change the number of epoch accordingly\n",
    "        # 7 generates the best performance\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  nb_epoch=7, batch_size=128)  \n",
    "        \n",
    "        # evaluate model using model.evaluate()\n",
    "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "        # get predicted class label\n",
    "        self.output = model.predict(X_val)\n",
    "        predicted_label_list = self.get_pred_label(self.output)\n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def get_pred_label(self,output):\n",
    "        '''get predicted class label based on prediction output'''\n",
    "        predicted_label_list = []\n",
    "        for i in range(len(output)):\n",
    "            predicted_label = output[i].argmax(axis=-1)\n",
    "            predicted_label_list.append(predicted_label)        \n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def incorporate_pred_label(self):\n",
    "        '''return prediction results back to df'''\n",
    "        # indices is a numpy array, need to convert to a list of indices before feed into df to get sub df \n",
    "        # recreate df based on the shuffled indices\n",
    "        indices = self.indices\n",
    "        all_labeled_data = self.all_labeled_data.iloc[list(self.indices)]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "        print(nb_validation_samples)\n",
    "        # need to get the indices of the validation data\n",
    "        train_val_bound = self.data.shape[0] - nb_validation_samples\n",
    "        # get validation dataset\n",
    "        val_df = all_labeled_data[train_val_bound:]\n",
    "        return val_df\n",
    "\n",
    "    def map_label(self,df,predicted_label_list):\n",
    "        '''map predicted labels to original class'''\n",
    "        # print(predicted_label_list[:10])\n",
    "        label_dct = self.labels_index\n",
    "        df['pred_label_encodes'] = predicted_label_list\n",
    "        # get reversed labels_index dictionary\n",
    "        reversed_label_dct = {}\n",
    "        for i in range(len(label_dct)):\n",
    "            reversed_label_dct[list(label_dct.values())[i]] = list(label_dct.keys())[i]\n",
    "\n",
    "        # map predicted labels\n",
    "        pred_label = [reversed_label_dct.get(label) for label in predicted_label_list]\n",
    "        df['pred_label'] = pred_label\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def evaluate_performance(self,val_df):\n",
    "        # evaluate performance\n",
    "        y_val_true = val_df.label.values\n",
    "        y_val_pred = val_df.pred_label.values\n",
    "        self.get_confusion_matrix(y_val_true,y_val_pred) \n",
    "        \n",
    "    \n",
    "    def get_confusion_matrix(self,y_test,y_pred):\n",
    "        '''get tp,tn,fp,fn for each class'''\n",
    "        cm = ConfusionMatrix(y_test, y_pred)\n",
    "        cm.print_stats()\n",
    "        \n",
    "        \n",
    "    def over_sampling(self):\n",
    "        '''modeling after over sampling'''\n",
    "        smote = SMOTE('minority')\n",
    "        X_train_sm, y_train_sm = smote.fit_sample(self.X_train,self.y_train)\n",
    "        print(X_train_sm.shape, y_train_sm.shape)\n",
    "        \n",
    "        # fit model based on new data set\n",
    "        predicted_label_list = self.train_data(X_train_sm,y_train_sm,X_val,y_val)\n",
    "        return predicted_label_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext()\n",
    "model = ft.load_pretrained_model('fasttext_train_data/model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimention of word vector: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.07510141,  0.34539855, -0.04847794, -0.00599669,  0.08026265,\n",
       "        0.17255239,  0.06303003,  0.16753493,  0.26827294,  0.24050438,\n",
       "        0.10935862, -0.05695121, -0.1612111 , -0.1254698 , -0.14411566,\n",
       "        0.1671324 , -0.09211409, -0.08527946,  0.07678948, -0.00543677,\n",
       "       -0.12030143,  0.13826734, -0.06652036, -0.22822875, -0.01887627,\n",
       "        0.00094851, -0.0210128 , -0.04052201, -0.07755461,  0.14083461,\n",
       "       -0.02262247,  0.05274943, -0.12807177, -0.10997214, -0.18952328,\n",
       "       -0.02350366,  0.2577952 , -0.2513076 , -0.15192115,  0.10377252,\n",
       "        0.14529383,  0.12857807, -0.13611504, -0.02255148,  0.3416287 ,\n",
       "       -0.12241936,  0.13015959,  0.11399453, -0.05882082,  0.11640163,\n",
       "        0.08050135, -0.07715302,  0.01431637, -0.13527611, -0.07535661,\n",
       "       -0.07706072, -0.02880922,  0.4216739 ,  0.09358777,  0.07875614,\n",
       "        0.17708524,  0.12715451,  0.03065475,  0.02836023,  0.10281598,\n",
       "       -0.06090513,  0.07658396,  0.17984973, -0.0974253 , -0.01285458,\n",
       "       -0.17587005,  0.0740779 , -0.01954268, -0.0369027 , -0.21346194,\n",
       "       -0.07796012,  0.15358968,  0.21927392, -0.01555008,  0.10152558,\n",
       "        0.14325912, -0.1450496 ,  0.10351609, -0.03536751, -0.09584553,\n",
       "       -0.1321252 ,  0.08872717,  0.16196701,  0.0489408 ,  0.03071725,\n",
       "        0.23057672,  0.12721165,  0.52103347, -0.13791195,  0.02442563,\n",
       "       -0.44769627,  0.02728627,  0.00585644,  0.04959832,  0.03868417],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get more model methods\n",
    "print('dimention of word vector:',model.get_dimension())\n",
    "# load word vector\n",
    "model.get_word_vector('航班').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4747 unique tokens.\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551,)\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = ft.prepare_data('../res/labeled_data_with_without_tk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:99: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1241 samples, validate on 310 samples\n",
      "Epoch 1/7\n",
      "1241/1241 [==============================] - 29s 24ms/step - loss: 2.2988 - acc: 0.1426 - val_loss: 2.2963 - val_acc: 0.1742\n",
      "Epoch 2/7\n",
      "1241/1241 [==============================] - 28s 23ms/step - loss: 2.2931 - acc: 0.2256 - val_loss: 2.2922 - val_acc: 0.1742\n",
      "Epoch 3/7\n",
      "1241/1241 [==============================] - 28s 22ms/step - loss: 2.2885 - acc: 0.2256 - val_loss: 2.2885 - val_acc: 0.1742\n",
      "Epoch 4/7\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 2.2842 - acc: 0.2256 - val_loss: 2.2849 - val_acc: 0.1742\n",
      "Epoch 5/7\n",
      "1241/1241 [==============================] - 28s 22ms/step - loss: 2.2800 - acc: 0.2256 - val_loss: 2.2815 - val_acc: 0.1742\n",
      "Epoch 6/7\n",
      "1241/1241 [==============================] - 27s 22ms/step - loss: 2.2760 - acc: 0.2256 - val_loss: 2.2781 - val_acc: 0.1742\n",
      "Epoch 7/7\n",
      "1241/1241 [==============================] - 30s 24ms/step - loss: 2.2720 - acc: 0.2256 - val_loss: 2.2747 - val_acc: 0.1742\n",
      "acc: 17.42%\n"
     ]
    }
   ],
   "source": [
    "predicted_label_list = ft.train_data(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding dictionary: {'计划': 7, '机上': 5, '中转': 0, '售后': 3, '预订': 9, '设计': 8, '出发': 1, '性能': 4, '行程': 6, '到达': 2}\n",
      "310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/abstract.py:66: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  df = df.loc[idx, idx.copy()].fillna(0)  # if some columns or rows are missing\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:236: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.PositiveTest)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FP) / self.PositiveTest)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  * (self.TN + self.FP) * (self.TN + self.FN)))\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:330: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TPR) / self.FPR)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TN) / self.NegativeTest)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:337: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FNR) / self.TNR)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FN) / self.NegativeTest)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  中转   出发  到达  售后  性能  机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                     \n",
      "中转          0   32   0   0   0   0   0   0   0   0       32\n",
      "出发          0   54   0   0   0   0   0   0   0   0       54\n",
      "到达          0   27   0   0   0   0   0   0   0   0       27\n",
      "售后          0   31   0   0   0   0   0   0   0   0       31\n",
      "性能          0   35   0   0   0   0   0   0   0   0       35\n",
      "机上          0   59   0   0   0   0   0   0   0   0       59\n",
      "行程          0   15   0   0   0   0   0   0   0   0       15\n",
      "计划          0    6   0   0   0   0   0   0   0   0        6\n",
      "设计          0    8   0   0   0   0   0   0   0   0        8\n",
      "预订          0   43   0   0   0   0   0   0   0   0       43\n",
      "__all__     0  310   0   0   0   0   0   0   0   0      310\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.17419354838709677\n",
      "95% CI: (0.1336524786679323, 0.22108957039409816)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.0\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                      中转        出发         到达   售后  \\\n",
      "Population                                  310       310        310  310   \n",
      "P: Condition positive                        32        54         27   31   \n",
      "N: Condition negative                       278       256        283  279   \n",
      "Test outcome positive                         0       310          0    0   \n",
      "Test outcome negative                       310         0        310  310   \n",
      "TP: True Positive                             0        54          0    0   \n",
      "TN: True Negative                           278         0        283  279   \n",
      "FP: False Positive                            0       256          0    0   \n",
      "FN: False Negative                           32         0         27   31   \n",
      "TPR: (Sensitivity, hit rate, recall)          0         1          0    0   \n",
      "TNR=SPC: (Specificity)                        1         0          1    1   \n",
      "PPV: Pos Pred Value (Precision)             NaN  0.174194        NaN  NaN   \n",
      "NPV: Neg Pred Value                    0.896774       NaN   0.912903  0.9   \n",
      "FPR: False-out                                0         1          0    0   \n",
      "FDR: False Discovery Rate                   NaN  0.825806        NaN  NaN   \n",
      "FNR: Miss Rate                                1         0          1    1   \n",
      "ACC: Accuracy                          0.896774  0.174194   0.912903  0.9   \n",
      "F1 score                                      0  0.296703          0    0   \n",
      "MCC: Matthews correlation coefficient       NaN       NaN        NaN  NaN   \n",
      "Informedness                                  0         0          0    0   \n",
      "Markedness                                  NaN       NaN        NaN  NaN   \n",
      "Prevalence                             0.103226  0.174194  0.0870968  0.1   \n",
      "LR+: Positive likelihood ratio              NaN         1        NaN  NaN   \n",
      "LR-: Negative likelihood ratio                1       NaN          1    1   \n",
      "DOR: Diagnostic odds ratio                  NaN       NaN        NaN  NaN   \n",
      "FOR: False omission rate               0.103226       NaN  0.0870968  0.1   \n",
      "\n",
      "Classes                                      性能        机上         行程  \\\n",
      "Population                                  310       310        310   \n",
      "P: Condition positive                        35        59         15   \n",
      "N: Condition negative                       275       251        295   \n",
      "Test outcome positive                         0         0          0   \n",
      "Test outcome negative                       310       310        310   \n",
      "TP: True Positive                             0         0          0   \n",
      "TN: True Negative                           275       251        295   \n",
      "FP: False Positive                            0         0          0   \n",
      "FN: False Negative                           35        59         15   \n",
      "TPR: (Sensitivity, hit rate, recall)          0         0          0   \n",
      "TNR=SPC: (Specificity)                        1         1          1   \n",
      "PPV: Pos Pred Value (Precision)             NaN       NaN        NaN   \n",
      "NPV: Neg Pred Value                    0.887097  0.809677   0.951613   \n",
      "FPR: False-out                                0         0          0   \n",
      "FDR: False Discovery Rate                   NaN       NaN        NaN   \n",
      "FNR: Miss Rate                                1         1          1   \n",
      "ACC: Accuracy                          0.887097  0.809677   0.951613   \n",
      "F1 score                                      0         0          0   \n",
      "MCC: Matthews correlation coefficient       NaN       NaN        NaN   \n",
      "Informedness                                  0         0          0   \n",
      "Markedness                                  NaN       NaN        NaN   \n",
      "Prevalence                             0.112903  0.190323  0.0483871   \n",
      "LR+: Positive likelihood ratio              NaN       NaN        NaN   \n",
      "LR-: Negative likelihood ratio                1         1          1   \n",
      "DOR: Diagnostic odds ratio                  NaN       NaN        NaN   \n",
      "FOR: False omission rate               0.112903  0.190323  0.0483871   \n",
      "\n",
      "Classes                                       计划         设计       预订  \n",
      "Population                                   310        310      310  \n",
      "P: Condition positive                          6          8       43  \n",
      "N: Condition negative                        304        302      267  \n",
      "Test outcome positive                          0          0        0  \n",
      "Test outcome negative                        310        310      310  \n",
      "TP: True Positive                              0          0        0  \n",
      "TN: True Negative                            304        302      267  \n",
      "FP: False Positive                             0          0        0  \n",
      "FN: False Negative                             6          8       43  \n",
      "TPR: (Sensitivity, hit rate, recall)           0          0        0  \n",
      "TNR=SPC: (Specificity)                         1          1        1  \n",
      "PPV: Pos Pred Value (Precision)              NaN        NaN      NaN  \n",
      "NPV: Neg Pred Value                     0.980645   0.974194  0.86129  \n",
      "FPR: False-out                                 0          0        0  \n",
      "FDR: False Discovery Rate                    NaN        NaN      NaN  \n",
      "FNR: Miss Rate                                 1          1        1  \n",
      "ACC: Accuracy                           0.980645   0.974194  0.86129  \n",
      "F1 score                                       0          0        0  \n",
      "MCC: Matthews correlation coefficient        NaN        NaN      NaN  \n",
      "Informedness                                   0          0        0  \n",
      "Markedness                                   NaN        NaN      NaN  \n",
      "Prevalence                             0.0193548  0.0258065  0.13871  \n",
      "LR+: Positive likelihood ratio               NaN        NaN      NaN  \n",
      "LR-: Negative likelihood ratio                 1          1        1  \n",
      "DOR: Diagnostic odds ratio                   NaN        NaN      NaN  \n",
      "FOR: False omission rate               0.0193548  0.0258065  0.13871  \n"
     ]
    }
   ],
   "source": [
    "# check label index\n",
    "print('label encoding dictionary:', ft.labels_index)\n",
    "\n",
    "val_df = ft.incorporate_pred_label()\n",
    "val_df = ft.map_label(val_df,predicted_label_list)\n",
    "val_df.head()\n",
    "\n",
    "# evaluate performance\n",
    "ft.evaluate_performance(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary: using labeled and unlabeled data (~6400 reviews) => poorly predict, by only predicting 出发 （the majority class label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
