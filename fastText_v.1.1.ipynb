{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readme: \n",
    "* reference: \n",
    "  * [Using FastText models (not vectors) for robust embeddings](https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings)\n",
    "  * [Medium - Build your own Text classification with less than 25 lines of code using fasttext](https://medium.com/@ravindraprasad/build-your-own-text-classification-in-less-than-25-lines-of-code-using-fasttext-dae7229f80f9)\n",
    "  * [Medium - Learning FastText](https://towardsdatascience.com/fasttext-ea9009dba0e8)\n",
    "  * [Text Classification & Word Representations using FastText (An NLP library by Facebook)](https://www.analyticsvidhya.com/blog/2017/07/word-representations-text-classification-using-fasttext-nlp-facebook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/CSAir/codes')\n",
    "import fastText \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from semi_supervise import Semi_Supervise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1550 examples in labeled dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyuan/Desktop/CSAir/codes/semi_supervise.py:53: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  self.data_concat = pd.concat([self.labeled_data, self.unlabeled_data],ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>机票 改签 在线 申请 邮寄 行程 操作</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>购买 机票 优惠 劵</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>网上 选 座位</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>开具 电子 发票 程序 自动 去掉 正确 应为 劳动保护 杂志社</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我到现时用南方的app订票付款方式不能用到微信或支付宝，巳经多次找你们都解决不了问题？</td>\n",
       "      <td>现时 南方 订票 付款 方式 用到 微信 支付宝 巳 找 解决不了</td>\n",
       "      <td>预订</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4  我到现时用南方的app订票付款方式不能用到微信或支付宝，巳经多次找你们都解决不了问题？   \n",
       "\n",
       "                       review_tokens label  label_encoded  \n",
       "0               机票 改签 在线 申请 邮寄 行程 操作   N/A            NaN  \n",
       "1                         购买 机票 优惠 劵   N/A            NaN  \n",
       "2                            网上 选 座位   N/A            NaN  \n",
       "3   开具 电子 发票 程序 自动 去掉 正确 应为 劳动保护 杂志社   N/A            NaN  \n",
       "4  现时 南方 订票 付款 方式 用到 微信 支付宝 巳 找 解决不了    预订            9.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- prepare data from user reviews to train FastText model ----\n",
    "# load data\n",
    "ss = Semi_Supervise()\n",
    "labeled_data = ss.load_labeled_data('../res/labeled_data_with_without_tk.csv')\n",
    "# load unlabeled data\n",
    "# unlabeled_data = ss.load_unlabeled_data_csv('../res/unlabeled_review_5000.csv')\n",
    "\n",
    "# load more unlabeled data ..\n",
    "unlabeled_data = ss.load_unlabeled_data_csv('../res/unlabeled_review_反馈数据.csv')\n",
    "# concatenate labeled and unlabeled data\n",
    "data_concat = ss.concat_data()\n",
    "data_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data to txt file => data would be feed into fasttext\n",
    "train_data = data_concat.review_tokens\n",
    "train_data.to_csv('../res/sampled_data_fasttext.txt', index = False)\n",
    "\n",
    "# Finished: locally train fasttext using labeled + unlabeled data (5000)\n",
    "# use command below to locally train skip-gram fasttext model: \n",
    "# ./fasttext skipgram -input ../fasttext_train_data/sampled_data_fasttext.txt -output ../fasttext_train_data/model\n",
    "\n",
    "# train cbow version:\n",
    "# ./fasttext cbow -input ../fasttext_train_data/sampled_data_fasttext.txt -output ../fasttext_train_data/model_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fasttext():\n",
    "    def __init__(self):\n",
    "        self.embeddings_index = {}\n",
    "        self.MAX_SEQUENCE_LENGTH = 1000\n",
    "        self.MAX_NUM_WORDS = 20000\n",
    "        self.EMBEDDING_DIM = 300\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "        self.labels_index = {}\n",
    "        self.word_index  = {}\n",
    "    \n",
    "    def load_pretrained_model(self, model_path):\n",
    "        model_pretrained = fastText.load_model(model_path) \n",
    "        return model_pretrained\n",
    "    \n",
    "    def prepare_data(self,data_file_path):\n",
    "        self.all_labeled_data = pd.read_csv(data_file_path)\n",
    "        self.texts = self.all_labeled_data.review_tokens.astype('str').values\n",
    "        self.labels = self.all_labeled_data.label_encoded.values\n",
    "        \n",
    "        # get a dictionary that map each original label to its encoded label, e.g., {'中转': 0,...}\n",
    "        for label in self.all_labeled_data.label.unique().tolist():\n",
    "            self.labels_index[label] = self.all_labeled_data[self.all_labeled_data['label'] == label]['label_encoded'].unique()[0]\n",
    "\n",
    "        tokenizer = Tokenizer(nb_words=self.MAX_NUM_WORDS)\n",
    "        tokenizer.fit_on_texts(self.texts)\n",
    "        sequences = tokenizer.texts_to_sequences(self.texts)\n",
    "\n",
    "        self.word_index = tokenizer.word_index\n",
    "        print('Found %s unique tokens.' % len(self.word_index))\n",
    "\n",
    "        self.data = pad_sequences(sequences, maxlen=self.MAX_SEQUENCE_LENGTH)\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "        \n",
    "        # Converts a class vector (integers) to binary class matrix\n",
    "        self.labels = to_categorical(np.asarray(self.labels))\n",
    "        print('Shape of data tensor:', self.data.shape)\n",
    "        print('Shape of label tensor:', self.labels.shape)\n",
    "\n",
    "        # split the data into a training set and a validation set\n",
    "        self.indices = np.arange(self.data.shape[0])\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.data = self.data[self.indices]\n",
    "        self.labels = self.labels[self.indices]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "\n",
    "        self.X_train = self.data[:-nb_validation_samples]\n",
    "        self.y_train = self.labels[:-nb_validation_samples]\n",
    "        self.X_val = self.data[-nb_validation_samples:]\n",
    "        self.y_val = self.labels[-nb_validation_samples:]\n",
    "        return  self.X_train, self.y_train, self.X_val, self.y_val\n",
    "    \n",
    "    def get_embedding_matrix(self):\n",
    "        # 据得到的字典生成上文所定义的词向量矩阵\n",
    "        embedding_matrix = np.zeros((len(self.word_index) + 1, self.EMBEDDING_DIM))\n",
    "        for word, i in self.word_index.items():\n",
    "            embedding_vector = self.embeddings_index.get(word)\n",
    "            # updated:\n",
    "            if embedding_vector is not None:\n",
    "                # words not found in embedding index will be all-zeros.\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        return embedding_matrix\n",
    "    \n",
    "    def setup_neural_net(self):\n",
    "        # get word embedding matrix\n",
    "        self.embedding_matrix = self.get_embedding_matrix()\n",
    "\n",
    "        # 将这个词向量矩阵加载到Embedding层\n",
    "        embedding_layer = Embedding(len(self.word_index) + 1,\n",
    "                                    self.EMBEDDING_DIM,\n",
    "                                    weights=[self.embedding_matrix],\n",
    "                                    input_length=self.MAX_SEQUENCE_LENGTH,\n",
    "                                    trainable=False)\n",
    "        \n",
    "        # 使用一个小型的1D卷积解决分类问题\n",
    "        sequence_input = Input(shape=(self.MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "        embedded_sequences = embedding_layer(sequence_input)\n",
    "        x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(5)(x)\n",
    "        x = Conv1D(128, 5, activation='relu')(x)\n",
    "        x = MaxPooling1D(35)(x)  # global max pooling\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        preds = Dense(len(self.labels_index), activation='softmax')(x)\n",
    "        return sequence_input,preds\n",
    "    \n",
    "    \n",
    "    def train_data(self,X_train,y_train,X_val,y_val):\n",
    "        sequence_input,preds = self.setup_neural_net()\n",
    "        model = Model(sequence_input, preds)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['acc'])\n",
    "        # can change the number of epoch accordingly\n",
    "        # 7 generates the best performance\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                  nb_epoch=7, batch_size=128)  \n",
    "        \n",
    "        # evaluate model using model.evaluate()\n",
    "        scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "        # get predicted class label\n",
    "        self.output = model.predict(X_val)\n",
    "        predicted_label_list = self.get_pred_label(self.output)\n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def get_pred_label(self,output):\n",
    "        '''get predicted class label based on prediction output'''\n",
    "        predicted_label_list = []\n",
    "        for i in range(len(output)):\n",
    "            predicted_label = output[i].argmax(axis=-1)\n",
    "            predicted_label_list.append(predicted_label)        \n",
    "        return predicted_label_list\n",
    "    \n",
    "    \n",
    "    def incorporate_pred_label(self):\n",
    "        '''return prediction results back to df'''\n",
    "        # indices is a numpy array, need to convert to a list of indices before feed into df to get sub df \n",
    "        # recreate df based on the shuffled indices\n",
    "        indices = self.indices\n",
    "        all_labeled_data = self.all_labeled_data.iloc[list(self.indices)]\n",
    "        nb_validation_samples = int(self.VALIDATION_SPLIT * self.data.shape[0])\n",
    "        print(nb_validation_samples)\n",
    "        # need to get the indices of the validation data\n",
    "        train_val_bound = self.data.shape[0] - nb_validation_samples\n",
    "        # get validation dataset\n",
    "        val_df = all_labeled_data[train_val_bound:]\n",
    "        return val_df\n",
    "\n",
    "    def map_label(self,df,predicted_label_list):\n",
    "        '''map predicted labels to original class'''\n",
    "        # print(predicted_label_list[:10])\n",
    "        label_dct = self.labels_index\n",
    "        df['pred_label_encodes'] = predicted_label_list\n",
    "        # get reversed labels_index dictionary\n",
    "        reversed_label_dct = {}\n",
    "        for i in range(len(label_dct)):\n",
    "            reversed_label_dct[list(label_dct.values())[i]] = list(label_dct.keys())[i]\n",
    "\n",
    "        # map predicted labels\n",
    "        pred_label = [reversed_label_dct.get(label) for label in predicted_label_list]\n",
    "        df['pred_label'] = pred_label\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def evaluate_performance(self,val_df):\n",
    "        # evaluate performance\n",
    "        y_val_true = val_df.label.values\n",
    "        y_val_pred = val_df.pred_label.values\n",
    "        self.get_confusion_matrix(y_val_true,y_val_pred) \n",
    "        \n",
    "    \n",
    "    def get_confusion_matrix(self,y_test,y_pred):\n",
    "        '''get tp,tn,fp,fn for each class'''\n",
    "        cm = ConfusionMatrix(y_test, y_pred)\n",
    "        cm.print_stats()\n",
    "        \n",
    "        \n",
    "    def over_sampling(self):\n",
    "        '''modeling after over sampling'''\n",
    "        smote = SMOTE('minority')\n",
    "        X_train_sm, y_train_sm = smote.fit_sample(self.X_train,self.y_train)\n",
    "        print(X_train_sm.shape, y_train_sm.shape)\n",
    "        \n",
    "        # fit model based on new data set\n",
    "        predicted_label_list = self.train_data(X_train_sm,y_train_sm,X_val,y_val)\n",
    "        return predicted_label_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext()\n",
    "# model = ft.load_pretrained_model('fasttext_train_data/model.bin')\n",
    "# model = ft.load_pretrained_model('fasttext_train_data/model_cbow.bin')\n",
    "\n",
    "# load pretrained from official site ..\n",
    "model = ft.load_pretrained_model('../Source_Data/cc.zh.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimention of word vector: 300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-9.74254776e-03,  2.12122593e-02,  4.88131315e-01, -6.32701069e-02,\n",
       "       -7.33671244e-03, -2.18946919e-01, -1.77119195e-01,  2.03831811e-02,\n",
       "       -2.26945549e-01,  1.36024758e-01, -1.81659728e-01,  1.12053066e-01,\n",
       "        1.12769455e-01,  8.50891769e-02,  2.61089087e-01,  1.55254016e-02,\n",
       "       -8.70296210e-02,  1.53820127e-01,  1.77355576e-02,  1.37629956e-01,\n",
       "       -6.68650493e-02, -3.91467549e-02,  7.03171268e-02, -1.34001851e-01,\n",
       "       -5.05742505e-02, -1.98219940e-01,  5.21637499e-02,  2.09236205e-01,\n",
       "        3.95330228e-02,  9.62841138e-02,  7.60198310e-02, -5.18575832e-02,\n",
       "        1.30827308e-01, -1.79477498e-01,  9.56601351e-02, -2.05786884e-01,\n",
       "        2.56274760e-01, -1.52252838e-01,  1.57351568e-01, -2.99355295e-02,\n",
       "        1.20841317e-01, -6.54572770e-02, -2.32028976e-01,  1.31989181e-01,\n",
       "        2.59281192e-02,  3.18626165e-01, -8.46268050e-03,  1.44843146e-01,\n",
       "        9.82890576e-02, -7.24061728e-02,  1.34834737e-01,  2.83483323e-02,\n",
       "        2.68899530e-01,  6.26302063e-01, -6.57798499e-02,  2.56059617e-01,\n",
       "        7.81859234e-02, -2.11684898e-01, -8.15476403e-02,  1.16642036e-01,\n",
       "        7.60054961e-02,  7.15737842e-05, -2.71687247e-02, -3.33236046e-02,\n",
       "        9.77963433e-02, -1.74559921e-01, -7.35815940e-03,  2.67416779e-02,\n",
       "        9.53678787e-02, -2.56393105e-02, -1.16510153e-01,  2.16790199e-01,\n",
       "       -2.15621694e-04, -1.46976322e-01,  4.07626987e-01, -5.15324101e-02,\n",
       "        8.81300792e-02, -1.96723804e-01,  1.52761444e-01, -9.12940726e-02,\n",
       "       -2.83461064e-02, -2.68079601e-02, -7.20624849e-02, -1.63633093e-01,\n",
       "       -7.16413483e-02, -2.37882793e-01, -5.12843067e-03, -1.19652219e-01,\n",
       "        1.44929022e-01,  2.50073701e-01,  2.88750261e-01, -4.72689886e-03,\n",
       "        9.47760940e-02,  8.36910028e-03,  2.27730587e-01,  1.00909598e-01,\n",
       "       -6.35527745e-02,  1.95519939e-01, -1.24251388e-01,  6.37723580e-02,\n",
       "       -2.49386877e-01,  6.72621205e-02,  2.70293057e-02,  1.11124720e-02,\n",
       "        1.44545645e-01, -1.94729164e-01,  1.25612915e-01, -2.32749149e-01,\n",
       "        1.62661254e-01, -4.91299480e-02,  4.36093807e-01, -6.60208985e-02,\n",
       "        9.04959142e-02, -3.53883430e-02, -5.59969507e-02, -8.26479569e-02,\n",
       "        8.76057670e-02, -1.26826271e-01,  1.55980408e-01,  3.78836840e-01,\n",
       "        2.11225495e-01, -7.07613602e-02,  1.60213292e-01,  8.75855163e-02,\n",
       "       -2.22459193e-02, -1.00066595e-01,  6.34634420e-02, -1.57186896e-01,\n",
       "       -3.26866880e-02,  9.54653770e-02, -6.47302806e-01,  4.89319831e-01,\n",
       "        2.22924784e-01, -2.66985953e-01, -4.47631022e-03, -2.49641702e-01,\n",
       "        2.69390404e-01, -7.25443885e-02,  1.04652017e-01,  3.14709187e-01,\n",
       "        4.28828001e-02,  1.23894624e-01, -2.15358272e-01, -2.09820911e-01,\n",
       "        1.32996768e-01,  2.75737494e-01,  1.67523641e-02, -2.93903917e-01,\n",
       "       -6.41280189e-02, -5.41057847e-02, -1.90607347e-02,  4.89271013e-03,\n",
       "        2.11512178e-01,  3.54563557e-02,  1.72288328e-01,  1.06041238e-01,\n",
       "        2.20253542e-01,  4.09692496e-01,  1.43436909e-01, -2.28762373e-01,\n",
       "       -3.10977578e-01, -3.25569600e-01, -6.29355107e-03, -1.66421205e-01,\n",
       "        4.19585615e-01,  1.29104763e-01, -1.12400636e-01, -1.29234761e-01,\n",
       "       -3.57282385e-02,  1.17790028e-01, -2.12545648e-01, -2.62261610e-02,\n",
       "        1.63493454e-01,  1.32660270e-01, -1.08869135e-01, -8.38887021e-02,\n",
       "        4.47962247e-02, -2.49588415e-02,  1.99344352e-01,  2.72745252e-01,\n",
       "       -9.67301801e-02, -4.13762510e-01,  6.47825599e-02, -3.93993676e-01,\n",
       "        4.32433607e-03,  1.39295638e-01, -1.59986883e-01, -1.63634107e-01,\n",
       "        2.00569943e-01,  4.23623413e-01,  1.21424444e-01, -3.32876556e-02,\n",
       "       -8.73878002e-02,  8.05672631e-02, -3.69245075e-02,  1.32781565e-01,\n",
       "       -1.76094592e-01,  4.81309742e-02,  6.19699322e-02, -4.67287302e-02,\n",
       "       -1.97800826e-02, -1.77340269e-01, -1.24688692e-01,  8.67963359e-02,\n",
       "       -2.27748370e-03,  2.38259271e-01, -2.21357539e-01,  1.50334641e-01,\n",
       "        1.34202257e-01,  8.66550878e-02, -1.98057532e-01, -7.57897943e-02,\n",
       "        3.98884304e-02,  2.91800983e-02,  1.79198027e-01, -1.57529414e-01,\n",
       "        1.39771745e-01, -3.17510776e-02,  1.85163021e-02, -7.15607032e-02,\n",
       "       -6.98086917e-02,  1.39922395e-01,  2.47085318e-01, -4.73777056e-02,\n",
       "       -1.03829950e-01,  8.25057402e-02,  4.24902514e-02, -1.92209676e-01,\n",
       "        2.25648820e-01,  3.45228970e-01, -2.52989918e-01,  9.89194334e-01,\n",
       "        1.30374715e-01, -8.12588036e-02, -1.88564315e-01, -3.55407037e-02,\n",
       "        1.96145952e-01,  9.74535719e-02,  9.39389467e-02, -3.27787787e-01,\n",
       "       -2.28686884e-01,  1.53108582e-01, -6.03101663e-02,  2.65374690e-01,\n",
       "        1.37956738e-01,  1.27274543e-01,  6.29445836e-02, -1.32592052e-01,\n",
       "       -9.66214314e-02,  1.38783306e-01, -1.45738453e-01,  9.01173577e-02,\n",
       "       -1.63244188e-01, -8.10386091e-02, -1.08277522e-01, -7.52678588e-02,\n",
       "       -1.99501440e-01,  1.14352778e-01, -1.80445343e-01, -1.55542726e-02,\n",
       "        1.14308111e-01,  1.04886070e-01, -7.42151365e-02,  1.76728472e-01,\n",
       "       -9.24594849e-02, -2.13302940e-01,  2.51280457e-01,  2.17615790e-03,\n",
       "       -2.20819801e-01, -3.36094350e-01, -2.27626845e-01,  1.87891927e-02,\n",
       "        2.47503445e-01,  1.00150891e-01,  1.63744856e-02,  1.81506202e-01,\n",
       "        2.79703792e-02, -4.48182404e-01, -7.19624758e-02, -1.28608704e-01,\n",
       "       -4.53159779e-01, -3.33089270e-02,  2.42959112e-02, -1.14475876e-01,\n",
       "       -1.54950488e-02, -1.88687935e-01,  5.21890000e-02, -1.62927434e-01,\n",
       "       -5.50585650e-02, -1.83012616e-02, -9.12665427e-02,  1.40681311e-01,\n",
       "        8.65038559e-02,  7.97658041e-03, -2.41333097e-01,  1.68492526e-01,\n",
       "        5.67011461e-02,  4.31948662e-01,  1.99698180e-01, -1.22806899e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get more model methods\n",
    "print('dimention of word vector:',model.get_dimension())\n",
    "# load word vector\n",
    "model.get_word_vector('航班').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/keras_preprocessing/text.py:177: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4747 unique tokens.\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551,)\n",
      "Shape of data tensor: (1551, 1000)\n",
      "Shape of label tensor: (1551, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = ft.prepare_data('../res/labeled_data_with_without_tk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:99: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1241 samples, validate on 310 samples\n",
      "Epoch 1/7\n",
      "1241/1241 [==============================] - 37s 30ms/step - loss: 2.2986 - acc: 0.1813 - val_loss: 2.2958 - val_acc: 0.2258\n",
      "Epoch 2/7\n",
      "1241/1241 [==============================] - 28s 23ms/step - loss: 2.2927 - acc: 0.1990 - val_loss: 2.2916 - val_acc: 0.1581\n",
      "Epoch 3/7\n",
      "1241/1241 [==============================] - 28s 23ms/step - loss: 2.2881 - acc: 0.1934 - val_loss: 2.2877 - val_acc: 0.1581\n",
      "Epoch 4/7\n",
      "1241/1241 [==============================] - 27s 22ms/step - loss: 2.2838 - acc: 0.1934 - val_loss: 2.2841 - val_acc: 0.1581\n",
      "Epoch 5/7\n",
      "1241/1241 [==============================] - 29s 23ms/step - loss: 2.2796 - acc: 0.1934 - val_loss: 2.2806 - val_acc: 0.1581\n",
      "Epoch 6/7\n",
      "1241/1241 [==============================] - 28s 22ms/step - loss: 2.2755 - acc: 0.1829 - val_loss: 2.2771 - val_acc: 0.1581\n",
      "Epoch 7/7\n",
      "1241/1241 [==============================] - 29s 24ms/step - loss: 2.2715 - acc: 0.1942 - val_loss: 2.2738 - val_acc: 0.1581\n",
      "acc: 15.81%\n"
     ]
    }
   ],
   "source": [
    "predicted_label_list = ft.train_data(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encoding dictionary: {'计划': 7, '机上': 5, '中转': 0, '售后': 3, '预订': 9, '设计': 8, '出发': 1, '性能': 4, '行程': 6, '到达': 2}\n",
      "310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/abstract.py:66: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  df = df.loc[idx, idx.copy()].fillna(0)  # if some columns or rows are missing\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:236: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.PositiveTest)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FP) / self.PositiveTest)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  * (self.TN + self.FP) * (self.TN + self.FN)))\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:330: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TPR) / self.FPR)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted  中转  出发  到达  售后  性能   机上  行程  计划  设计  预订  __all__\n",
      "Actual                                                     \n",
      "中转          0   0   0   0   0   32   0   0   0   0       32\n",
      "出发          0   0   0   0   0   70   0   0   0   0       70\n",
      "到达          0   0   0   0   0   29   0   0   0   0       29\n",
      "售后          0   0   0   0   0   25   0   0   0   0       25\n",
      "性能          0   0   0   0   0   26   0   0   0   0       26\n",
      "机上          0   0   0   0   0   49   0   0   0   0       49\n",
      "行程          0   0   0   0   0   12   0   0   0   0       12\n",
      "计划          0   0   0   0   0    8   0   0   0   0        8\n",
      "设计          0   0   0   0   0   17   0   0   0   0       17\n",
      "预订          0   0   0   0   0   42   0   0   0   0       42\n",
      "__all__     0   0   0   0   0  310   0   0   0   0      310\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.15806451612903225\n",
      "95% CI: (0.11928240540905369, 0.2035282629919941)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.0\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                      中转        出发         到达  \\\n",
      "Population                                  310       310        310   \n",
      "P: Condition positive                        32        70         29   \n",
      "N: Condition negative                       278       240        281   \n",
      "Test outcome positive                         0         0          0   \n",
      "Test outcome negative                       310       310        310   \n",
      "TP: True Positive                             0         0          0   \n",
      "TN: True Negative                           278       240        281   \n",
      "FP: False Positive                            0         0          0   \n",
      "FN: False Negative                           32        70         29   \n",
      "TPR: (Sensitivity, hit rate, recall)          0         0          0   \n",
      "TNR=SPC: (Specificity)                        1         1          1   \n",
      "PPV: Pos Pred Value (Precision)             NaN       NaN        NaN   \n",
      "NPV: Neg Pred Value                    0.896774  0.774194   0.906452   \n",
      "FPR: False-out                                0         0          0   \n",
      "FDR: False Discovery Rate                   NaN       NaN        NaN   \n",
      "FNR: Miss Rate                                1         1          1   \n",
      "ACC: Accuracy                          0.896774  0.774194   0.906452   \n",
      "F1 score                                      0         0          0   \n",
      "MCC: Matthews correlation coefficient       NaN       NaN        NaN   \n",
      "Informedness                                  0         0          0   \n",
      "Markedness                                  NaN       NaN        NaN   \n",
      "Prevalence                             0.103226  0.225806  0.0935484   \n",
      "LR+: Positive likelihood ratio              NaN       NaN        NaN   \n",
      "LR-: Negative likelihood ratio                1         1          1   \n",
      "DOR: Diagnostic odds ratio                  NaN       NaN        NaN   \n",
      "FOR: False omission rate               0.103226  0.225806  0.0935484   \n",
      "\n",
      "Classes                                       售后        性能        机上  \\\n",
      "Population                                   310       310       310   \n",
      "P: Condition positive                         25        26        49   \n",
      "N: Condition negative                        285       284       261   \n",
      "Test outcome positive                          0         0       310   \n",
      "Test outcome negative                        310       310         0   \n",
      "TP: True Positive                              0         0        49   \n",
      "TN: True Negative                            285       284         0   \n",
      "FP: False Positive                             0         0       261   \n",
      "FN: False Negative                            25        26         0   \n",
      "TPR: (Sensitivity, hit rate, recall)           0         0         1   \n",
      "TNR=SPC: (Specificity)                         1         1         0   \n",
      "PPV: Pos Pred Value (Precision)              NaN       NaN  0.158065   \n",
      "NPV: Neg Pred Value                     0.919355  0.916129       NaN   \n",
      "FPR: False-out                                 0         0         1   \n",
      "FDR: False Discovery Rate                    NaN       NaN  0.841935   \n",
      "FNR: Miss Rate                                 1         1         0   \n",
      "ACC: Accuracy                           0.919355  0.916129  0.158065   \n",
      "F1 score                                       0         0  0.272981   \n",
      "MCC: Matthews correlation coefficient        NaN       NaN       NaN   \n",
      "Informedness                                   0         0         0   \n",
      "Markedness                                   NaN       NaN       NaN   \n",
      "Prevalence                             0.0806452  0.083871  0.158065   \n",
      "LR+: Positive likelihood ratio               NaN       NaN         1   \n",
      "LR-: Negative likelihood ratio                 1         1       NaN   \n",
      "DOR: Diagnostic odds ratio                   NaN       NaN       NaN   \n",
      "FOR: False omission rate               0.0806452  0.083871       NaN   \n",
      "\n",
      "Classes                                       行程         计划         设计  \\\n",
      "Population                                   310        310        310   \n",
      "P: Condition positive                         12          8         17   \n",
      "N: Condition negative                        298        302        293   \n",
      "Test outcome positive                          0          0          0   \n",
      "Test outcome negative                        310        310        310   \n",
      "TP: True Positive                              0          0          0   \n",
      "TN: True Negative                            298        302        293   \n",
      "FP: False Positive                             0          0          0   \n",
      "FN: False Negative                            12          8         17   \n",
      "TPR: (Sensitivity, hit rate, recall)           0          0          0   \n",
      "TNR=SPC: (Specificity)                         1          1          1   \n",
      "PPV: Pos Pred Value (Precision)              NaN        NaN        NaN   \n",
      "NPV: Neg Pred Value                      0.96129   0.974194   0.945161   \n",
      "FPR: False-out                                 0          0          0   \n",
      "FDR: False Discovery Rate                    NaN        NaN        NaN   \n",
      "FNR: Miss Rate                                 1          1          1   \n",
      "ACC: Accuracy                            0.96129   0.974194   0.945161   \n",
      "F1 score                                       0          0          0   \n",
      "MCC: Matthews correlation coefficient        NaN        NaN        NaN   \n",
      "Informedness                                   0          0          0   \n",
      "Markedness                                   NaN        NaN        NaN   \n",
      "Prevalence                             0.0387097  0.0258065  0.0548387   \n",
      "LR+: Positive likelihood ratio               NaN        NaN        NaN   \n",
      "LR-: Negative likelihood ratio                 1          1          1   \n",
      "DOR: Diagnostic odds ratio                   NaN        NaN        NaN   \n",
      "FOR: False omission rate               0.0387097  0.0258065  0.0548387   \n",
      "\n",
      "Classes                                      预订  \n",
      "Population                                  310  \n",
      "P: Condition positive                        42  \n",
      "N: Condition negative                       268  \n",
      "Test outcome positive                         0  \n",
      "Test outcome negative                       310  \n",
      "TP: True Positive                             0  \n",
      "TN: True Negative                           268  \n",
      "FP: False Positive                            0  \n",
      "FN: False Negative                           42  \n",
      "TPR: (Sensitivity, hit rate, recall)          0  \n",
      "TNR=SPC: (Specificity)                        1  \n",
      "PPV: Pos Pred Value (Precision)             NaN  \n",
      "NPV: Neg Pred Value                    0.864516  \n",
      "FPR: False-out                                0  \n",
      "FDR: False Discovery Rate                   NaN  \n",
      "FNR: Miss Rate                                1  \n",
      "ACC: Accuracy                          0.864516  \n",
      "F1 score                                      0  \n",
      "MCC: Matthews correlation coefficient       NaN  \n",
      "Informedness                                  0  \n",
      "Markedness                                  NaN  \n",
      "Prevalence                             0.135484  \n",
      "LR+: Positive likelihood ratio              NaN  \n",
      "LR-: Negative likelihood ratio                1  \n",
      "DOR: Diagnostic odds ratio                  NaN  \n",
      "FOR: False omission rate               0.135484  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TN) / self.NegativeTest)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:337: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FNR) / self.TNR)\n",
      "/anaconda3/envs/nlp/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FN) / self.NegativeTest)\n"
     ]
    }
   ],
   "source": [
    "# check label index\n",
    "print('label encoding dictionary:', ft.labels_index)\n",
    "\n",
    "val_df = ft.incorporate_pred_label()\n",
    "val_df = ft.map_label(val_df,predicted_label_list)\n",
    "val_df.head()\n",
    "\n",
    "# evaluate performance\n",
    "ft.evaluate_performance(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary: using labeled and unlabeled data (~25000 reviews) => poorly predict, by only predicting 出发 （the majority class label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
